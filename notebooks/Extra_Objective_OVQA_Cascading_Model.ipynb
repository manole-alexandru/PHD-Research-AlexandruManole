{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1721105229385,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"},"user_tz":-180},"id":"99-dcUqELaqH","outputId":"114c75b8-df26-4962-fc88-5a416bb0a517"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import os\n","import pandas as pd\n","import argparse\n","import shutil\n","import numpy as np\n","import copy\n","import random\n","import math\n","import time\n","import re\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n","from torchvision import transforms, utils\n","from skimage import io, transform\n","import torch.nn.functional as F\n","from PIL import Image\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate import bleu_score\n","from nltk.translate.bleu_score import corpus_bleu\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torch.optim.lr_scheduler import _LRScheduler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","import torch\n","import torchvision.models as models\n","import torchvision\n","from transformers import BertTokenizer\n","from transformers import BertModel\n","import nltk\n","nltk.download('punkt')\n","from collections import defaultdict\n","import collections\n","import pickle\n","from tqdm import tqdm\n","\n","import torchvision.transforms as transforms\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","plt.ion()   # interactive mode\n","\n","ROOT_PATH = '/content/drive/MyDrive/VQA/Datasets/OVQA_publish/'"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xJjJ8isEHRW","executionInfo":{"status":"ok","timestamp":1721105008525,"user_tz":-180,"elapsed":42315,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"65710651-0285-4e75-9f1c-bb549df0a16c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2090,"status":"ok","timestamp":1721105033394,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"},"user_tz":-180},"id":"86eO7YmSUd7D","outputId":"bdec15c7-ff78-4dc0-9430-1d8d500b64a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1067\n","6\n","2\n","5\n"]}],"source":["ANS_LABLE_DICT = {}\n","Q_TYPE_LABLE_DICT = {}\n","ANS_TYPE_LABLE_DICT = {}\n","IMG_ORGAN_LABLE_DICT = {}\n","with open(f\"{ROOT_PATH}valset.json\") as f_val:\n","    data_val = json.load(f_val)\n","\n","with open(f\"{ROOT_PATH}trainset.json\") as f_train:\n","    data_train = json.load(f_train)\n","\n","with open(f\"{ROOT_PATH}testset.json\") as f_test:\n","    data_test = json.load(f_test)\n","\n","data = data_val + data_train + data_test\n","i = 0\n","j = 0\n","k = 0\n","l = 0\n","for elem in data:\n","  if elem[\"answer\"] not in ANS_LABLE_DICT.keys():\n","    # remove special characters and make it all lower\n","    ANS_LABLE_DICT[elem[\"answer\"]] = i\n","    i += 1\n","\n","  if elem[\"question_type\"] not in Q_TYPE_LABLE_DICT.keys():\n","    Q_TYPE_LABLE_DICT[elem[\"question_type\"]] = j\n","    j += 1\n","\n","  if elem[\"answer_type\"] not in ANS_TYPE_LABLE_DICT.keys():\n","    ANS_TYPE_LABLE_DICT[elem[\"answer_type\"]] = k\n","    k += 1\n","\n","  if elem[\"image_organ\"] not in IMG_ORGAN_LABLE_DICT.keys():\n","    IMG_ORGAN_LABLE_DICT[elem[\"image_organ\"]] = l\n","    l += 1\n","\n","print(len(ANS_LABLE_DICT))\n","print(len(Q_TYPE_LABLE_DICT))\n","print(len(ANS_TYPE_LABLE_DICT))\n","print(len(IMG_ORGAN_LABLE_DICT))"]},{"cell_type":"code","source":["ANS_TYPE_LABLE_DICT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22bIlJbrXYNk","executionInfo":{"status":"ok","timestamp":1721076401380,"user_tz":-180,"elapsed":456,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"2f7c3fe8-caa9-4d64-ac48-378162dbf912"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'OPEN': 0, 'CLOSED': 1}"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cMuKy1Fw67pa","executionInfo":{"status":"ok","timestamp":1721105054063,"user_tz":-180,"elapsed":316,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"outputs":[],"source":["class OVQADataset(Dataset):\n","    \"\"\"OVQA images and questions dataset.\"\"\"\n","\n","    def __init__(self, json_file, root_dir, phase, transform=None):\n","        \"\"\"\n","        Arguments:\n","            json_file (string): Path to the json file with questions.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        with open(json_file) as f:\n","          self.question_data = json.load(f)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.phase = phase\n","        self.img_feat_vqa = np.load(f\"{ROOT_PATH}features.pkl\", allow_pickle=True )\n","\n","    def __len__(self):\n","        return len(self.question_data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_feat_vqa = self.img_feat_vqa\n","        img_name = os.path.join(self.root_dir,\n","                                self.question_data[idx][\"image_name\"])\n","\n","        image_feat = torch.Tensor(img_feat_vqa[img_name.split('/')[-1]])\n","\n","        question = self.question_data[idx][\"question\"]\n","        answer =  self.question_data[idx][\"answer\"]\n","        question_type = self.question_data[idx][\"question_type\"]\n","        answer_type =  self.question_data[idx][\"answer_type\"]\n","        image_organ = self.question_data[idx][\"image_organ\"]\n","        qid = self.question_data[idx][\"qid\"]\n","\n","        #print(image.size())\n","\n","        sample = {'image': image_feat,\n","                  'question': question,\n","                  'answer_label':F.one_hot(torch.tensor([[ANS_LABLE_DICT[answer]]]), len(ANS_LABLE_DICT)),\n","                  'question_type_label':F.one_hot(torch.tensor([[Q_TYPE_LABLE_DICT[question_type]]]), len(Q_TYPE_LABLE_DICT)),\n","                  'answer_text': answer,\n","                  'answer_type_label':F.one_hot(torch.tensor([[ANS_TYPE_LABLE_DICT[answer_type]]]), len(ANS_TYPE_LABLE_DICT)),\n","                  'qid': qid,\n","                  'image_organ_label': F.one_hot(torch.tensor([[IMG_ORGAN_LABLE_DICT[image_organ]]]), len(IMG_ORGAN_LABLE_DICT))}\n","\n","        return sample"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2SscgDaLeS_j","executionInfo":{"status":"ok","timestamp":1721105071412,"user_tz":-180,"elapsed":302,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"outputs":[],"source":["def get_loader(batch_size, num_workers,size=228):\n","    '''\n","        Load our dataset with dataloader for the train and valid data\n","    '''\n","\n","    vqa_dataset = {\n","        'train': OVQADataset(json_file=f'{ROOT_PATH}trainset.json',\n","                                    root_dir=f'{ROOT_PATH}img/', phase='train', transform=transform),\n","        'valid': OVQADataset(json_file=f'{ROOT_PATH}valset.json',\n","                                    root_dir=f'{ROOT_PATH}/img/', phase='valid', transform=transform)}\n","\n","\n","    data_loader = {\n","        phase: torch.utils.data.DataLoader(\n","            dataset=vqa_dataset[phase],\n","            batch_size=batch_size,\n","            shuffle=True,\n","            num_workers=num_workers,\n","            )\n","        for phase in ['train','valid']}\n","\n","    return data_loader"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"DhlWUvytbtVI","executionInfo":{"status":"ok","timestamp":1721105077357,"user_tz":-180,"elapsed":300,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"outputs":[],"source":["import argparse\n","\n","def parse_opt():\n","    parser = argparse.ArgumentParser()\n","\n","    # Data input settings\n","    parser.add_argument('--SEED', type=int, default=97)\n","    parser.add_argument('--BATCH_SIZE', type=int, default=64)\n","    parser.add_argument('--VAL_BATCH_SIZE', type=int, default=64)\n","    parser.add_argument('--NUM_OUTPUT_UNITS', type=int, default=len(ANS_LABLE_DICT))\n","    parser.add_argument('--MAX_QUESTION_LEN', type=int, default=17) # double check this\n","    parser.add_argument('--IMAGE_CHANNEL', type=int, default=1472)\n","    parser.add_argument('--INIT_LERARNING_RATE', type=float, default=1e-4)\n","    parser.add_argument('--LAMNDA', type=float, default=0.0001)\n","    parser.add_argument('--MFB_FACTOR_NUM', type=int, default=5)\n","    parser.add_argument('--MFB_OUT_DIM', type=int, default=1024)\n","    parser.add_argument('--BERT_UNIT_NUM', type=int, default=768)\n","    parser.add_argument('--BERT_DROPOUT_RATIO', type=float, default=0.3)\n","    parser.add_argument('--MFB_DROPOUT_RATIO', type=float, default=0.1)\n","    parser.add_argument('--NUM_IMG_GLIMPSE', type=int, default=2)\n","    parser.add_argument('--NUM_QUESTION_GLIMPSE', type=int, default=2)\n","    parser.add_argument('--IMG_FEAT_SIZE', type=int, default=1)\n","    parser.add_argument('--IMG_INPUT_SIZE', type=int, default=224)\n","    parser.add_argument('--NUM_EPOCHS', type=int, default=200)\n","    args = parser.parse_args(args=[])\n","    return args\n","\n","opt = parse_opt()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"-uexaxe0jpOr","executionInfo":{"status":"ok","timestamp":1721105100882,"user_tz":-180,"elapsed":332,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"outputs":[],"source":["answer_classes = ANS_LABLE_DICT\n","\n","\n","class BERTokenizer():\n","\n","    def __init__(self,opt):\n","        # Load the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","        self.opt = opt\n","    #pre-process the text data\n","    def text_preprocessing(self, text):\n","\n","        # Remove trailing whitespace\n","        text = re.sub(r'\\s+', ' ', text).strip()\n","\n","        return text\n","\n","\n","    # Create a function to tokenize a set of texts\n","    def preprocessing_for_bert(self, data):\n","        \"\"\"Perform required preprocessing steps for pretrained BERT.\n","        @param    data (np.array): Array of texts to be processed.\n","        @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n","        @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n","                    tokens should be attended to by the model.\n","        \"\"\"\n","        # Create empty lists to store outputs\n","        input_ids = []\n","        attention_masks = []\n","        MAX_LEN = self.opt.MAX_QUESTION_LEN\n","        # For every sentence...\n","        for sent in data:\n","\n","            encoded_sent = self.tokenizer.encode_plus(\n","                text=self.text_preprocessing(sent),  # Preprocess sentence\n","                add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n","                max_length=MAX_LEN,                  # Max length to truncate/pad\n","                pad_to_max_length=True,         # Pad sentence to max length\n","                #return_tensors='pt',           # Return PyTorch tensor\n","                truncation=True,\n","                return_attention_mask=True      # Return attention mask\n","                )\n","\n","            # Add the outputs to the lists\n","            input_ids.append(encoded_sent.get('input_ids'))\n","            attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","        # Convert lists to tensors\n","        input_ids = torch.tensor(input_ids)\n","        attention_masks = torch.tensor(attention_masks)\n","\n","        return input_ids, attention_masks\n","\n","\n","# Create the question encoder base on  BertClassfier\n","class BertQstEncoder(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, opt,freeze_bert=True):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        @param    opt: for configuration parameter\n","        \"\"\"\n","        super(BertQstEncoder, self).__init__()\n","        self.opt = opt\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in= self.opt.BERT_UNIT_NUM\n","\n","        # Instantiate BERT model\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.bert.eval()\n","        self.bert_emb = self.bert.embeddings\n","        self.bert_encode_layer1 = (self.bert.encoder.layer)[0]\n","        self.bert_encode_layer2 = (self.bert.encoder.layer)[1]\n","        self.bert_encode_layer3 = (self.bert.encoder.layer)[2]\n","        self.bert_encode_layer4 = (self.bert.encoder.layer)[3]\n","        self.bert_encode_layer5 = (self.bert.encoder.layer)[4]\n","        self.bert_encode_layer6 = (self.bert.encoder.layer)[5]\n","        self.bert_encode_layer7 = (self.bert.encoder.layer)[6]\n","        self.bert_encode_layer8 = (self.bert.encoder.layer)[7]\n","        self.bert_encode_layer9 = (self.bert.encoder.layer)[8]\n","        self.bert_encode_layer10 = (self.bert.encoder.layer)[9]\n","        self.bert_encode_layer11 = (self.bert.encoder.layer)[10]\n","        self.bert_encode_layer12 = (self.bert.encoder.layer)[11]\n","\n","\n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","\n","\n","        # Feed input to BERT\n","\n","        with torch.no_grad():\n","            emb_out = self.bert_emb(input_ids, attention_mask)\n","            layer1= self.bert_encode_layer1(emb_out)\n","            layer2= self.bert_encode_layer2(layer1[0])\n","            layer3= self.bert_encode_layer3(layer2[0])\n","            layer4= self.bert_encode_layer4(layer3[0])\n","            layer5= self.bert_encode_layer5(layer4[0])\n","            layer6= self.bert_encode_layer6(layer5[0])\n","            layer7= self.bert_encode_layer7(layer6[0])\n","            layer8= self.bert_encode_layer8(layer7[0])\n","            layer9= self.bert_encode_layer9(layer8[0])\n","            layer10= self.bert_encode_layer10(layer9[0])\n","            layer11= self.bert_encode_layer11(layer10[0])\n","            layer12= self.bert_encode_layer12(layer11[0])\n","\n","        word_question_representation = (layer11[0] +layer12[0])/2\n","\n","        return word_question_representation\n","\n","\n","#Extract the question feature with co-attention\n","class QuestionFeatureExtractionAtt(nn.Module):\n","    '''\n","        Extract the question with co-attention, get from https://github.com/asdf0982/vqa-mfb.pytorch\n","    '''\n","\n","    def __init__(self,opt):\n","\n","        super(QuestionFeatureExtractionAtt, self).__init__()\n","\n","        self.opt = opt\n","        self.NUM_QUESTION_GLIMPSE = self.opt.NUM_QUESTION_GLIMPSE\n","\n","        self.JOINT_EMB_SIZE = self.opt.MFB_FACTOR_NUM * self.opt.MFB_OUT_DIM\n","        self.Softmax = nn.Softmax(dim=-1)\n","\n","        self.Linear1_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM* self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n","        self.Linear2_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM*self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n","\n","        self.Dropout_M = nn.Dropout(p=self.opt.MFB_DROPOUT_RATIO)\n","        self.dropout = nn.Dropout(self.opt.BERT_DROPOUT_RATIO)\n","        self.Conv1_Qatt = nn.Conv2d(self.opt.BERT_UNIT_NUM, self.opt.IMAGE_CHANNEL, 1)\n","        self.Conv2_Qatt = nn.Conv2d(self.opt.IMAGE_CHANNEL, self.opt.NUM_QUESTION_GLIMPSE, 1)\n","\n","    def forward(self,qst_encoding):\n","\n","        '''\n","        Question Attention\n","        '''\n","        self.batch_size = qst_encoding.shape[0]\n","        qst_encoding = self.dropout(qst_encoding)\n","        qst_encoding_resh =  torch.unsqueeze(qst_encoding, 3)       # N=4 x 768 x T=14 x 1\n","        qatt_conv1 = self.Conv1_Qatt(qst_encoding_resh)                   # N x 512 x T x 1\n","        qatt_relu = F.relu(qatt_conv1)\n","        qatt_conv2 = self.Conv2_Qatt(qatt_relu)                          # N x 2 x T x 1\n","        qatt_conv2 = qatt_conv2.contiguous().view(self.batch_size*2,-1)\n","        qatt_softmax = self.Softmax(qatt_conv2)\n","        qatt_softmax = qatt_softmax.view(self.batch_size, 2, -1, 1)\n","        qatt_feature_list = []\n","        for i in range(self.NUM_QUESTION_GLIMPSE):\n","            t_qatt_mask = qatt_softmax.narrow(1, i, 1)              # N x 1 x T x 1\n","            t_qatt_mask = t_qatt_mask * qst_encoding_resh           # N x 768 x T x 1\n","            t_qatt_mask = torch.sum(t_qatt_mask, 2, keepdim=True)   # N x 768 x 1 x 1\n","            qatt_feature_list.append(t_qatt_mask)\n","        qatt_feature_concat = torch.cat(qatt_feature_list, 1)       # N x 1536 x 1 x 1\n","\n","        return qatt_feature_concat\n","\n","\n","#Extract the image feature with MFB and co-attention\n","class ImageFeatureExtractionAtt(nn.Module):\n","\n","    '''\n","        Extract the image with co-attention, get from https://github.com/asdf0982/vqa-mfb.pytorch\n","    '''\n","\n","    def __init__(self,opt):\n","        super(ImageFeatureExtractionAtt, self).__init__()\n","        self.opt = opt\n","        self.MFB_FACTOR_NUM = self.opt.MFB_FACTOR_NUM\n","        self.MFB_OUT_DIM = self.opt.MFB_OUT_DIM\n","        self.NUM_IMG_GLIMPSE =self.opt.NUM_IMG_GLIMPSE\n","        self.IMG_FEAT_SIZE = self.opt.IMG_FEAT_SIZE\n","\n","        self.JOINT_EMB_SIZE = self.opt.MFB_FACTOR_NUM * self.opt.MFB_OUT_DIM\n","        self.Softmax = nn.Softmax(dim=-1)\n","\n","        self.Linear1_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM* self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n","        self.Linear_i_proj = nn.Linear(self.opt.IMAGE_CHANNEL*self.opt.NUM_IMG_GLIMPSE, self.JOINT_EMB_SIZE)\n","        self.Conv_i_proj = nn.Conv2d(self.opt.IMAGE_CHANNEL, self.JOINT_EMB_SIZE, 1)\n","\n","\n","        self.Dropout_M = nn.Dropout(p=self.opt.MFB_DROPOUT_RATIO)\n","\n","        self.Conv1_Iatt = nn.Conv2d(self.opt.MFB_OUT_DIM, self.opt.IMAGE_CHANNEL, 1) # (1000, 512, 1)\n","        self.Conv2_Iatt = nn.Conv2d(self.opt.IMAGE_CHANNEL, self.NUM_IMG_GLIMPSE, 1)\n","\n","    def forward(self, img_feature, qstatt_feature):\n","\n","        '''\n","        Image Attention with MFB\n","        '''\n","        self.batch_size = img_feature.shape[0]\n","        q_feat_resh = torch.squeeze(qstatt_feature)                              # N x 1536\n","        i_feat_resh = img_feature.unsqueeze(3)                                   # N x 512 x 196 x 1\n","        #print(i_feat_resh.shape)\n","        iatt_q_proj = self.Linear1_q_proj(q_feat_resh)                                  # N x 5000\n","        iatt_q_resh = iatt_q_proj.view(self.batch_size, self.JOINT_EMB_SIZE, 1, 1)      # N x 5000 x 1 x 1\n","        iatt_i_conv = self.Conv_i_proj(i_feat_resh)                                     # N x 5000 x 196 x 1\n","        iatt_iq_eltwise = iatt_q_resh * iatt_i_conv\n","        iatt_iq_droped = self.Dropout_M(iatt_iq_eltwise)                                # N x 5000 x 196 x 1\n","        iatt_iq_permute1 = iatt_iq_droped.permute(0,2,1,3).contiguous()                 # N x 196 x 5000 x 1\n","        iatt_iq_resh = iatt_iq_permute1.view(self.batch_size, self.IMG_FEAT_SIZE, self.MFB_OUT_DIM, self.MFB_FACTOR_NUM)\n","        iatt_iq_sumpool = torch.sum(iatt_iq_resh, 3, keepdim=True)                      # N x 196 x 1000 x 1\n","        iatt_iq_permute2 = iatt_iq_sumpool.permute(0,2,1,3)                             # N x 1000 x 196 x 1\n","        iatt_iq_sqrt = torch.sqrt(F.relu(iatt_iq_permute2)) - torch.sqrt(F.relu(-iatt_iq_permute2))\n","        iatt_iq_sqrt = iatt_iq_sqrt.reshape(self.batch_size, -1)                           # N x 196000\n","        iatt_iq_l2 = F.normalize(iatt_iq_sqrt)\n","        iatt_iq_l2 = iatt_iq_l2.view(self.batch_size, self.MFB_OUT_DIM, self.IMG_FEAT_SIZE, 1)  # N x 1000 x 196 x 1\n","\n","        iatt_conv1 = self.Conv1_Iatt(iatt_iq_l2)                    # N x 512 x 196 x 1\n","        iatt_relu = F.relu(iatt_conv1)\n","        iatt_conv2 = self.Conv2_Iatt(iatt_relu)                     # N x 2 x 196 x 1\n","        iatt_conv2 = iatt_conv2.view(self.batch_size*self.NUM_IMG_GLIMPSE, -1)\n","        iatt_softmax = self.Softmax(iatt_conv2)\n","        iatt_softmax = iatt_softmax.view(self.batch_size, self.NUM_IMG_GLIMPSE, -1, 1)\n","        iatt_feature_list = []\n","        for i in range(self.NUM_IMG_GLIMPSE):\n","            t_iatt_mask = iatt_softmax.narrow(1, i, 1)              # N x 1 x 196 x 1\n","            t_iatt_mask = t_iatt_mask * i_feat_resh                 # N x 512 x 196 x 1\n","            t_iatt_mask = torch.sum(t_iatt_mask, 2, keepdim=True)   # N x 512 x 1 x 1\n","            iatt_feature_list.append(t_iatt_mask)\n","        iatt_feature_concat = torch.cat(iatt_feature_list, 1)       # N x 1024 x 1 x 1\n","        iatt_feature_concat = torch.squeeze(iatt_feature_concat)    # N x 1024\n","        return iatt_feature_concat\n","\n","\n","\n","class VqaClassifierModel(nn.Module):\n","    '''\n","        Fusion with MFB,  get from https://github.com/asdf0982/vqa-mfb.pytorch\n","    '''\n","\n","    def __init__(self, opt):\n","        super(VqaClassifierModel, self).__init__()\n","        self.opt = opt\n","\n","        self.JOINT_EMB_SIZE = self.opt.MFB_FACTOR_NUM * self.opt.MFB_OUT_DIM\n","\n","        self.MFB_OUT_DIM = self.opt.MFB_OUT_DIM\n","        self.MFB_FACTOR_NUM = self.opt.MFB_FACTOR_NUM\n","        NUM_OUTPUT_UNITS = self.opt.NUM_OUTPUT_UNITS\n","\n","\n","        self.tokenizer = BERTokenizer(self.opt)\n","        self.bert_model = BertQstEncoder(self.opt)\n","\n","\n","        self.qst_feature_att = QuestionFeatureExtractionAtt(self.opt)\n","        self.img_feature_att = ImageFeatureExtractionAtt(self.opt)\n","\n","        self.Linear2_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM*self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n","        self.Linear_i_proj = nn.Linear(self.opt.IMAGE_CHANNEL*self.opt.NUM_IMG_GLIMPSE, self.JOINT_EMB_SIZE)\n","\n","        self.Dropout_M = nn.Dropout(p=self.opt.MFB_DROPOUT_RATIO)\n","\n","        self.Linear_predict_1 = nn.Linear(self.opt.MFB_OUT_DIM + len(Q_TYPE_LABLE_DICT) + len(ANS_TYPE_LABLE_DICT) + len(IMG_ORGAN_LABLE_DICT), NUM_OUTPUT_UNITS)\n","        self.Linear_predict_2 = nn.Linear(self.opt.MFB_OUT_DIM, len(Q_TYPE_LABLE_DICT))\n","        self.Linear_predict_3 = nn.Linear(self.opt.MFB_OUT_DIM, len(ANS_TYPE_LABLE_DICT))\n","        self.Linear_predict_4 = nn.Linear(self.opt.MFB_OUT_DIM, len(IMG_ORGAN_LABLE_DICT))\n","\n","\n","    def forward(self, img, qst):\n","\n","        self.batch_size = img.shape[0]\n","        image_feature = img\n","        input_ids, attention_mask = self.tokenizer.preprocessing_for_bert(qst)\n","        question_feature = self.bert_model(input_ids.to(device), attention_mask.to(device))\n","        question_feature = question_feature.transpose(1, 2)      # N=4 x 768 x T=14\n","\n","        q_featatt = self.qst_feature_att(question_feature)      # N x 1536\n","\n","        iatt_feature_concat = self.img_feature_att(image_feature,q_featatt)          # N x 1024\n","\n","        '''\n","        Fine-grained Image-Question MFB fusion\n","        '''\n","        q_feat_resh = torch.squeeze(q_featatt)\n","        mfb_q_proj = self.Linear2_q_proj(q_feat_resh)               # N x 5000\n","        mfb_i_proj = self.Linear_i_proj(iatt_feature_concat)        # N x 5000\n","        mfb_iq_eltwise = torch.mul(mfb_q_proj, mfb_i_proj)          # N x 5000\n","        mfb_iq_drop = self.Dropout_M(mfb_iq_eltwise)\n","        mfb_iq_resh = mfb_iq_drop.view(self.batch_size, 1, self.MFB_OUT_DIM, self.MFB_FACTOR_NUM)   # N x 1 x 1000 x 5\n","        mfb_iq_sumpool = torch.sum(mfb_iq_resh, 3, keepdim=True)    # N x 1 x 1000 x 1\n","        mfb_out = torch.squeeze(mfb_iq_sumpool)                     # N x 1000\n","        mfb_sign_sqrt = torch.sqrt(F.relu(mfb_out)) - torch.sqrt(F.relu(-mfb_out))\n","        mfb_l2 = F.normalize(mfb_sign_sqrt)\n","        prediction_2 = self.Linear_predict_2(mfb_l2)\n","        prediction_3 = self.Linear_predict_3(mfb_l2)\n","        prediction_4 = self.Linear_predict_4(mfb_l2)\n","        #print(f\"first two predictions {torch.cat((prediction_2, prediction_3, mfb_l2), dim=1).shape}\")\n","        #print(f\"pred + image {(prediction_1 + prediction_2 + image_feature).shape}\")\n","        prediction_1 = self.Linear_predict_1(torch.cat((prediction_2, prediction_3, prediction_4, mfb_l2), dim=1))\n","        prediction = [F.log_softmax(prediction_1, -1), F.log_softmax(prediction_2, -1), F.log_softmax(prediction_3, -1), F.log_softmax(prediction_4, -1) ]# N x num_class\n","        #prediction = [F.log_softmax(prediction_1, -1), F.log_softmax(prediction_2, -1)]\n","        return prediction"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uaWObLrA6EkG","executionInfo":{"status":"ok","timestamp":1721084842552,"user_tz":-180,"elapsed":8168379,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"250f3abd-5664-41f2-ffdf-cf9cc4f41a82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/199\n","----------\n","train Loss: 8.7577 Top 1 Acc: 0.3623 Top 5 Acc: 0.7089 Acc Quest: 0.8504 Acc Ans: 0.9106\n","valid Loss: 7.5285 Top 1 Acc: 0.3646 Top 5 Acc: 0.6128 Acc Quest: 0.9300 Acc Ans: 0.9446\n","Epoch 1/199\n","----------\n","train Loss: 5.7724 Top 1 Acc: 0.4462 Top 5 Acc: 0.7245 Acc Quest: 0.9372 Acc Ans: 0.9320\n","valid Loss: 5.5872 Top 1 Acc: 0.3544 Top 5 Acc: 0.6378 Acc Quest: 0.9401 Acc Ans: 0.9449\n","Epoch 2/199\n","----------\n","train Loss: 4.2677 Top 1 Acc: 0.4573 Top 5 Acc: 0.7522 Acc Quest: 0.9487 Acc Ans: 0.9905\n","valid Loss: 4.6429 Top 1 Acc: 0.3705 Top 5 Acc: 0.6582 Acc Quest: 0.9579 Acc Ans: 1.0095\n","Epoch 3/199\n","----------\n","train Loss: 3.4598 Top 1 Acc: 0.4902 Top 5 Acc: 0.7704 Acc Quest: 0.9639 Acc Ans: 1.0004\n","valid Loss: 4.0538 Top 1 Acc: 0.4229 Top 5 Acc: 0.6670 Acc Quest: 0.9795 Acc Ans: 1.0095\n","Epoch 4/199\n","----------\n","train Loss: 2.9281 Top 1 Acc: 0.5724 Top 5 Acc: 0.7798 Acc Quest: 0.9798 Acc Ans: 1.0009\n","valid Loss: 3.6345 Top 1 Acc: 0.4789 Top 5 Acc: 0.6751 Acc Quest: 0.9926 Acc Ans: 1.0095\n","Epoch 5/199\n","----------\n","train Loss: 2.5519 Top 1 Acc: 0.6428 Top 5 Acc: 0.7866 Acc Quest: 0.9909 Acc Ans: 1.0010\n","valid Loss: 3.3136 Top 1 Acc: 0.5322 Top 5 Acc: 0.6821 Acc Quest: 1.0032 Acc Ans: 1.0095\n","Epoch 6/199\n","----------\n","train Loss: 2.2766 Top 1 Acc: 0.6700 Top 5 Acc: 0.7930 Acc Quest: 0.9966 Acc Ans: 1.0011\n","valid Loss: 3.0947 Top 1 Acc: 0.5277 Top 5 Acc: 0.6883 Acc Quest: 1.0053 Acc Ans: 1.0095\n","Epoch 7/199\n","----------\n","train Loss: 2.0728 Top 1 Acc: 0.6806 Top 5 Acc: 0.7990 Acc Quest: 0.9988 Acc Ans: 1.0011\n","valid Loss: 2.9298 Top 1 Acc: 0.5343 Top 5 Acc: 0.6912 Acc Quest: 1.0084 Acc Ans: 1.0095\n","Epoch 8/199\n","----------\n","train Loss: 1.9233 Top 1 Acc: 0.6899 Top 5 Acc: 0.8037 Acc Quest: 1.0000 Acc Ans: 1.0011\n","valid Loss: 2.8222 Top 1 Acc: 0.5403 Top 5 Acc: 0.6933 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 9/199\n","----------\n","train Loss: 1.8042 Top 1 Acc: 0.6962 Top 5 Acc: 0.8083 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.7093 Top 1 Acc: 0.5361 Top 5 Acc: 0.6999 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 10/199\n","----------\n","train Loss: 1.7130 Top 1 Acc: 0.7023 Top 5 Acc: 0.8120 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.6383 Top 1 Acc: 0.5502 Top 5 Acc: 0.7022 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 11/199\n","----------\n","train Loss: 1.6431 Top 1 Acc: 0.7087 Top 5 Acc: 0.8137 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.5868 Top 1 Acc: 0.5446 Top 5 Acc: 0.7087 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 12/199\n","----------\n","train Loss: 1.5870 Top 1 Acc: 0.7118 Top 5 Acc: 0.8172 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.5557 Top 1 Acc: 0.5475 Top 5 Acc: 0.7081 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 13/199\n","----------\n","train Loss: 1.5385 Top 1 Acc: 0.7154 Top 5 Acc: 0.8191 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.5040 Top 1 Acc: 0.5536 Top 5 Acc: 0.7105 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 14/199\n","----------\n","train Loss: 1.5008 Top 1 Acc: 0.7168 Top 5 Acc: 0.8212 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.4927 Top 1 Acc: 0.5542 Top 5 Acc: 0.7094 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 15/199\n","----------\n","train Loss: 1.4644 Top 1 Acc: 0.7214 Top 5 Acc: 0.8227 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.4750 Top 1 Acc: 0.5481 Top 5 Acc: 0.7135 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 16/199\n","----------\n","train Loss: 1.4345 Top 1 Acc: 0.7242 Top 5 Acc: 0.8240 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.4450 Top 1 Acc: 0.5535 Top 5 Acc: 0.7144 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 17/199\n","----------\n","train Loss: 1.4040 Top 1 Acc: 0.7242 Top 5 Acc: 0.8252 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.4042 Top 1 Acc: 0.5569 Top 5 Acc: 0.7156 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 18/199\n","----------\n","train Loss: 1.3864 Top 1 Acc: 0.7257 Top 5 Acc: 0.8271 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.4228 Top 1 Acc: 0.5540 Top 5 Acc: 0.7129 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 19/199\n","----------\n","train Loss: 1.3626 Top 1 Acc: 0.7287 Top 5 Acc: 0.8295 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.4045 Top 1 Acc: 0.5554 Top 5 Acc: 0.7158 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 20/199\n","----------\n","train Loss: 1.3454 Top 1 Acc: 0.7273 Top 5 Acc: 0.8297 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.3581 Top 1 Acc: 0.5506 Top 5 Acc: 0.7134 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 21/199\n","----------\n","train Loss: 1.3267 Top 1 Acc: 0.7294 Top 5 Acc: 0.8317 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.3510 Top 1 Acc: 0.5536 Top 5 Acc: 0.7172 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 22/199\n","----------\n","train Loss: 1.3096 Top 1 Acc: 0.7336 Top 5 Acc: 0.8316 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.3554 Top 1 Acc: 0.5531 Top 5 Acc: 0.7169 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 23/199\n","----------\n","train Loss: 1.2919 Top 1 Acc: 0.7333 Top 5 Acc: 0.8338 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.3783 Top 1 Acc: 0.5426 Top 5 Acc: 0.7153 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 24/199\n","----------\n","train Loss: 1.2823 Top 1 Acc: 0.7321 Top 5 Acc: 0.8354 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.3407 Top 1 Acc: 0.5440 Top 5 Acc: 0.7173 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 25/199\n","----------\n","train Loss: 1.2673 Top 1 Acc: 0.7340 Top 5 Acc: 0.8368 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.3196 Top 1 Acc: 0.5563 Top 5 Acc: 0.7185 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 26/199\n","----------\n","train Loss: 1.2555 Top 1 Acc: 0.7376 Top 5 Acc: 0.8370 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.2862 Top 1 Acc: 0.5642 Top 5 Acc: 0.7244 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 27/199\n","----------\n","train Loss: 1.2434 Top 1 Acc: 0.7399 Top 5 Acc: 0.8387 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.3019 Top 1 Acc: 0.5571 Top 5 Acc: 0.7251 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 28/199\n","----------\n","train Loss: 1.2322 Top 1 Acc: 0.7416 Top 5 Acc: 0.8410 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.2681 Top 1 Acc: 0.5632 Top 5 Acc: 0.7234 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 29/199\n","----------\n","train Loss: 1.2203 Top 1 Acc: 0.7423 Top 5 Acc: 0.8421 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.2699 Top 1 Acc: 0.5613 Top 5 Acc: 0.7218 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 30/199\n","----------\n","train Loss: 1.2087 Top 1 Acc: 0.7424 Top 5 Acc: 0.8431 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 2.2810 Top 1 Acc: 0.5510 Top 5 Acc: 0.7281 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 31/199\n","----------\n","train Loss: 1.1969 Top 1 Acc: 0.7472 Top 5 Acc: 0.8443 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.2580 Top 1 Acc: 0.5671 Top 5 Acc: 0.7286 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 32/199\n","----------\n","train Loss: 1.1871 Top 1 Acc: 0.7462 Top 5 Acc: 0.8463 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.2676 Top 1 Acc: 0.5645 Top 5 Acc: 0.7289 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 33/199\n","----------\n","train Loss: 1.1791 Top 1 Acc: 0.7484 Top 5 Acc: 0.8490 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.2460 Top 1 Acc: 0.5661 Top 5 Acc: 0.7302 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 34/199\n","----------\n","train Loss: 1.1662 Top 1 Acc: 0.7491 Top 5 Acc: 0.8507 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.2257 Top 1 Acc: 0.5631 Top 5 Acc: 0.7346 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 35/199\n","----------\n","train Loss: 1.1625 Top 1 Acc: 0.7497 Top 5 Acc: 0.8518 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.2139 Top 1 Acc: 0.5669 Top 5 Acc: 0.7346 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 36/199\n","----------\n","train Loss: 1.1466 Top 1 Acc: 0.7507 Top 5 Acc: 0.8534 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.2024 Top 1 Acc: 0.5609 Top 5 Acc: 0.7382 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 37/199\n","----------\n","train Loss: 1.1306 Top 1 Acc: 0.7538 Top 5 Acc: 0.8555 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.1948 Top 1 Acc: 0.5694 Top 5 Acc: 0.7355 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 38/199\n","----------\n","train Loss: 1.1302 Top 1 Acc: 0.7551 Top 5 Acc: 0.8571 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.1804 Top 1 Acc: 0.5743 Top 5 Acc: 0.7360 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 39/199\n","----------\n","train Loss: 1.1172 Top 1 Acc: 0.7560 Top 5 Acc: 0.8575 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 2.1666 Top 1 Acc: 0.5747 Top 5 Acc: 0.7403 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 40/199\n","----------\n","train Loss: 1.1099 Top 1 Acc: 0.7574 Top 5 Acc: 0.8598 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.1827 Top 1 Acc: 0.5757 Top 5 Acc: 0.7390 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 41/199\n","----------\n","train Loss: 1.0966 Top 1 Acc: 0.7581 Top 5 Acc: 0.8619 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.1769 Top 1 Acc: 0.5741 Top 5 Acc: 0.7381 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 42/199\n","----------\n","train Loss: 1.0955 Top 1 Acc: 0.7602 Top 5 Acc: 0.8617 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.1795 Top 1 Acc: 0.5784 Top 5 Acc: 0.7393 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 43/199\n","----------\n","train Loss: 1.0846 Top 1 Acc: 0.7622 Top 5 Acc: 0.8638 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.1526 Top 1 Acc: 0.5671 Top 5 Acc: 0.7431 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 44/199\n","----------\n","train Loss: 1.0740 Top 1 Acc: 0.7637 Top 5 Acc: 0.8653 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.1627 Top 1 Acc: 0.5753 Top 5 Acc: 0.7414 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 45/199\n","----------\n","train Loss: 1.0667 Top 1 Acc: 0.7638 Top 5 Acc: 0.8660 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.1495 Top 1 Acc: 0.5705 Top 5 Acc: 0.7416 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 46/199\n","----------\n","train Loss: 1.0537 Top 1 Acc: 0.7643 Top 5 Acc: 0.8673 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.1355 Top 1 Acc: 0.5686 Top 5 Acc: 0.7446 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 47/199\n","----------\n","train Loss: 1.0545 Top 1 Acc: 0.7643 Top 5 Acc: 0.8682 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.1380 Top 1 Acc: 0.5819 Top 5 Acc: 0.7395 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 48/199\n","----------\n","train Loss: 1.0478 Top 1 Acc: 0.7657 Top 5 Acc: 0.8705 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.1297 Top 1 Acc: 0.5715 Top 5 Acc: 0.7437 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 49/199\n","----------\n","train Loss: 1.0389 Top 1 Acc: 0.7681 Top 5 Acc: 0.8703 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.1039 Top 1 Acc: 0.5837 Top 5 Acc: 0.7484 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 50/199\n","----------\n","train Loss: 1.0310 Top 1 Acc: 0.7693 Top 5 Acc: 0.8722 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.1295 Top 1 Acc: 0.5762 Top 5 Acc: 0.7442 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 51/199\n","----------\n","train Loss: 1.0228 Top 1 Acc: 0.7707 Top 5 Acc: 0.8739 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.1170 Top 1 Acc: 0.5810 Top 5 Acc: 0.7463 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 52/199\n","----------\n","train Loss: 1.0138 Top 1 Acc: 0.7707 Top 5 Acc: 0.8749 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.1426 Top 1 Acc: 0.5825 Top 5 Acc: 0.7432 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 53/199\n","----------\n","train Loss: 1.0039 Top 1 Acc: 0.7716 Top 5 Acc: 0.8749 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 2.1152 Top 1 Acc: 0.5869 Top 5 Acc: 0.7469 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 54/199\n","----------\n","train Loss: 0.9987 Top 1 Acc: 0.7737 Top 5 Acc: 0.8772 Acc Quest: 1.0011 Acc Ans: 1.0010\n","valid Loss: 2.1150 Top 1 Acc: 0.5886 Top 5 Acc: 0.7474 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 55/199\n","----------\n","train Loss: 0.9944 Top 1 Acc: 0.7757 Top 5 Acc: 0.8778 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0945 Top 1 Acc: 0.5873 Top 5 Acc: 0.7526 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 56/199\n","----------\n","train Loss: 0.9906 Top 1 Acc: 0.7754 Top 5 Acc: 0.8793 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 2.0839 Top 1 Acc: 0.5831 Top 5 Acc: 0.7530 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 57/199\n","----------\n","train Loss: 0.9823 Top 1 Acc: 0.7778 Top 5 Acc: 0.8795 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0807 Top 1 Acc: 0.5876 Top 5 Acc: 0.7572 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 58/199\n","----------\n","train Loss: 0.9805 Top 1 Acc: 0.7777 Top 5 Acc: 0.8805 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.0559 Top 1 Acc: 0.5873 Top 5 Acc: 0.7566 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 59/199\n","----------\n","train Loss: 0.9730 Top 1 Acc: 0.7756 Top 5 Acc: 0.8822 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 2.0713 Top 1 Acc: 0.5979 Top 5 Acc: 0.7561 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 60/199\n","----------\n","train Loss: 0.9584 Top 1 Acc: 0.7810 Top 5 Acc: 0.8833 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0661 Top 1 Acc: 0.5818 Top 5 Acc: 0.7600 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 61/199\n","----------\n","train Loss: 0.9598 Top 1 Acc: 0.7781 Top 5 Acc: 0.8840 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.0500 Top 1 Acc: 0.5729 Top 5 Acc: 0.7589 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 62/199\n","----------\n","train Loss: 0.9584 Top 1 Acc: 0.7808 Top 5 Acc: 0.8841 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0473 Top 1 Acc: 0.5838 Top 5 Acc: 0.7538 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 63/199\n","----------\n","train Loss: 0.9457 Top 1 Acc: 0.7807 Top 5 Acc: 0.8860 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0500 Top 1 Acc: 0.5841 Top 5 Acc: 0.7561 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 64/199\n","----------\n","train Loss: 0.9450 Top 1 Acc: 0.7815 Top 5 Acc: 0.8860 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0430 Top 1 Acc: 0.5874 Top 5 Acc: 0.7572 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 65/199\n","----------\n","train Loss: 0.9403 Top 1 Acc: 0.7840 Top 5 Acc: 0.8856 Acc Quest: 1.0006 Acc Ans: 1.0011\n","valid Loss: 2.0426 Top 1 Acc: 0.5851 Top 5 Acc: 0.7531 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 66/199\n","----------\n","train Loss: 0.9314 Top 1 Acc: 0.7845 Top 5 Acc: 0.8889 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0362 Top 1 Acc: 0.5913 Top 5 Acc: 0.7566 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 67/199\n","----------\n","train Loss: 0.9266 Top 1 Acc: 0.7845 Top 5 Acc: 0.8879 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0326 Top 1 Acc: 0.5849 Top 5 Acc: 0.7597 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 68/199\n","----------\n","train Loss: 0.9235 Top 1 Acc: 0.7850 Top 5 Acc: 0.8913 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.0302 Top 1 Acc: 0.5922 Top 5 Acc: 0.7623 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 69/199\n","----------\n","train Loss: 0.9183 Top 1 Acc: 0.7866 Top 5 Acc: 0.8912 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 2.0162 Top 1 Acc: 0.5846 Top 5 Acc: 0.7590 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 70/199\n","----------\n","train Loss: 0.9114 Top 1 Acc: 0.7860 Top 5 Acc: 0.8927 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0182 Top 1 Acc: 0.5842 Top 5 Acc: 0.7591 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 71/199\n","----------\n","train Loss: 0.9159 Top 1 Acc: 0.7871 Top 5 Acc: 0.8920 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 2.0161 Top 1 Acc: 0.5915 Top 5 Acc: 0.7595 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 72/199\n","----------\n","train Loss: 0.9063 Top 1 Acc: 0.7881 Top 5 Acc: 0.8954 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0162 Top 1 Acc: 0.5969 Top 5 Acc: 0.7651 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 73/199\n","----------\n","train Loss: 0.8938 Top 1 Acc: 0.7883 Top 5 Acc: 0.8962 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 2.0154 Top 1 Acc: 0.5919 Top 5 Acc: 0.7631 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 74/199\n","----------\n","train Loss: 0.8916 Top 1 Acc: 0.7914 Top 5 Acc: 0.8967 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.0227 Top 1 Acc: 0.5974 Top 5 Acc: 0.7595 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 75/199\n","----------\n","train Loss: 0.8847 Top 1 Acc: 0.7921 Top 5 Acc: 0.8992 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9799 Top 1 Acc: 0.5919 Top 5 Acc: 0.7692 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 76/199\n","----------\n","train Loss: 0.8822 Top 1 Acc: 0.7917 Top 5 Acc: 0.8987 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 2.0379 Top 1 Acc: 0.6000 Top 5 Acc: 0.7701 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 77/199\n","----------\n","train Loss: 0.8889 Top 1 Acc: 0.7918 Top 5 Acc: 0.8993 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 2.0009 Top 1 Acc: 0.5928 Top 5 Acc: 0.7656 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 78/199\n","----------\n","train Loss: 0.8755 Top 1 Acc: 0.7909 Top 5 Acc: 0.9009 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9970 Top 1 Acc: 0.5990 Top 5 Acc: 0.7712 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 79/199\n","----------\n","train Loss: 0.8705 Top 1 Acc: 0.7927 Top 5 Acc: 0.9016 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9926 Top 1 Acc: 0.6003 Top 5 Acc: 0.7645 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 80/199\n","----------\n","train Loss: 0.8749 Top 1 Acc: 0.7932 Top 5 Acc: 0.9013 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 2.0040 Top 1 Acc: 0.5948 Top 5 Acc: 0.7669 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 81/199\n","----------\n","train Loss: 0.8628 Top 1 Acc: 0.7945 Top 5 Acc: 0.9051 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9817 Top 1 Acc: 0.5943 Top 5 Acc: 0.7726 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 82/199\n","----------\n","train Loss: 0.8653 Top 1 Acc: 0.7942 Top 5 Acc: 0.9052 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9889 Top 1 Acc: 0.5911 Top 5 Acc: 0.7719 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 83/199\n","----------\n","train Loss: 0.8570 Top 1 Acc: 0.7949 Top 5 Acc: 0.9052 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 1.9810 Top 1 Acc: 0.5881 Top 5 Acc: 0.7731 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 84/199\n","----------\n","train Loss: 0.8523 Top 1 Acc: 0.7976 Top 5 Acc: 0.9067 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9813 Top 1 Acc: 0.5960 Top 5 Acc: 0.7743 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 85/199\n","----------\n","train Loss: 0.8530 Top 1 Acc: 0.7952 Top 5 Acc: 0.9075 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9774 Top 1 Acc: 0.5890 Top 5 Acc: 0.7740 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 86/199\n","----------\n","train Loss: 0.8445 Top 1 Acc: 0.7969 Top 5 Acc: 0.9085 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9752 Top 1 Acc: 0.6012 Top 5 Acc: 0.7753 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 87/199\n","----------\n","train Loss: 0.8403 Top 1 Acc: 0.7983 Top 5 Acc: 0.9088 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.9699 Top 1 Acc: 0.5939 Top 5 Acc: 0.7752 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 88/199\n","----------\n","train Loss: 0.8443 Top 1 Acc: 0.7976 Top 5 Acc: 0.9098 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9409 Top 1 Acc: 0.6042 Top 5 Acc: 0.7780 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 89/199\n","----------\n","train Loss: 0.8363 Top 1 Acc: 0.8010 Top 5 Acc: 0.9102 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9522 Top 1 Acc: 0.5946 Top 5 Acc: 0.7743 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 90/199\n","----------\n","train Loss: 0.8312 Top 1 Acc: 0.8015 Top 5 Acc: 0.9123 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9660 Top 1 Acc: 0.5848 Top 5 Acc: 0.7745 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 91/199\n","----------\n","train Loss: 0.8294 Top 1 Acc: 0.7973 Top 5 Acc: 0.9126 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9707 Top 1 Acc: 0.6036 Top 5 Acc: 0.7762 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 92/199\n","----------\n","train Loss: 0.8249 Top 1 Acc: 0.8001 Top 5 Acc: 0.9128 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9371 Top 1 Acc: 0.6054 Top 5 Acc: 0.7785 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 93/199\n","----------\n","train Loss: 0.8193 Top 1 Acc: 0.8026 Top 5 Acc: 0.9138 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 1.9616 Top 1 Acc: 0.5951 Top 5 Acc: 0.7770 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 94/199\n","----------\n","train Loss: 0.8219 Top 1 Acc: 0.8021 Top 5 Acc: 0.9167 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9405 Top 1 Acc: 0.5991 Top 5 Acc: 0.7775 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 95/199\n","----------\n","train Loss: 0.8193 Top 1 Acc: 0.8003 Top 5 Acc: 0.9138 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9703 Top 1 Acc: 0.6090 Top 5 Acc: 0.7817 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 96/199\n","----------\n","train Loss: 0.8139 Top 1 Acc: 0.8035 Top 5 Acc: 0.9154 Acc Quest: 1.0005 Acc Ans: 1.0011\n","valid Loss: 1.9576 Top 1 Acc: 0.5967 Top 5 Acc: 0.7826 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 97/199\n","----------\n","train Loss: 0.8037 Top 1 Acc: 0.8042 Top 5 Acc: 0.9163 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9230 Top 1 Acc: 0.6019 Top 5 Acc: 0.7841 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 98/199\n","----------\n","train Loss: 0.8057 Top 1 Acc: 0.8061 Top 5 Acc: 0.9185 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9447 Top 1 Acc: 0.5970 Top 5 Acc: 0.7845 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 99/199\n","----------\n","train Loss: 0.8058 Top 1 Acc: 0.8051 Top 5 Acc: 0.9178 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9420 Top 1 Acc: 0.6000 Top 5 Acc: 0.7875 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 100/199\n","----------\n","train Loss: 0.7977 Top 1 Acc: 0.8083 Top 5 Acc: 0.9192 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.9244 Top 1 Acc: 0.6080 Top 5 Acc: 0.7832 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 101/199\n","----------\n","train Loss: 0.7954 Top 1 Acc: 0.8081 Top 5 Acc: 0.9207 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 1.9477 Top 1 Acc: 0.6028 Top 5 Acc: 0.7856 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 102/199\n","----------\n","train Loss: 0.7880 Top 1 Acc: 0.8084 Top 5 Acc: 0.9209 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9349 Top 1 Acc: 0.6091 Top 5 Acc: 0.7847 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 103/199\n","----------\n","train Loss: 0.7897 Top 1 Acc: 0.8078 Top 5 Acc: 0.9209 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9666 Top 1 Acc: 0.6035 Top 5 Acc: 0.7897 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 104/199\n","----------\n","train Loss: 0.7891 Top 1 Acc: 0.8070 Top 5 Acc: 0.9226 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9360 Top 1 Acc: 0.6044 Top 5 Acc: 0.7850 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 105/199\n","----------\n","train Loss: 0.7899 Top 1 Acc: 0.8080 Top 5 Acc: 0.9213 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9147 Top 1 Acc: 0.6082 Top 5 Acc: 0.7906 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 106/199\n","----------\n","train Loss: 0.7775 Top 1 Acc: 0.8091 Top 5 Acc: 0.9234 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9339 Top 1 Acc: 0.5998 Top 5 Acc: 0.7887 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 107/199\n","----------\n","train Loss: 0.7722 Top 1 Acc: 0.8119 Top 5 Acc: 0.9240 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9154 Top 1 Acc: 0.6060 Top 5 Acc: 0.7918 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 108/199\n","----------\n","train Loss: 0.7747 Top 1 Acc: 0.8110 Top 5 Acc: 0.9248 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9171 Top 1 Acc: 0.6009 Top 5 Acc: 0.7915 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 109/199\n","----------\n","train Loss: 0.7833 Top 1 Acc: 0.8095 Top 5 Acc: 0.9250 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9422 Top 1 Acc: 0.6052 Top 5 Acc: 0.7912 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 110/199\n","----------\n","train Loss: 0.7683 Top 1 Acc: 0.8107 Top 5 Acc: 0.9250 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9268 Top 1 Acc: 0.6025 Top 5 Acc: 0.7922 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 111/199\n","----------\n","train Loss: 0.7641 Top 1 Acc: 0.8126 Top 5 Acc: 0.9270 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9516 Top 1 Acc: 0.5900 Top 5 Acc: 0.7921 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 112/199\n","----------\n","train Loss: 0.7631 Top 1 Acc: 0.8121 Top 5 Acc: 0.9273 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9104 Top 1 Acc: 0.6061 Top 5 Acc: 0.7952 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 113/199\n","----------\n","train Loss: 0.7556 Top 1 Acc: 0.8157 Top 5 Acc: 0.9278 Acc Quest: 1.0008 Acc Ans: 1.0010\n","valid Loss: 1.9121 Top 1 Acc: 0.6043 Top 5 Acc: 0.7892 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 114/199\n","----------\n","train Loss: 0.7606 Top 1 Acc: 0.8132 Top 5 Acc: 0.9273 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9095 Top 1 Acc: 0.6112 Top 5 Acc: 0.7907 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 115/199\n","----------\n","train Loss: 0.7657 Top 1 Acc: 0.8139 Top 5 Acc: 0.9287 Acc Quest: 1.0002 Acc Ans: 1.0011\n","valid Loss: 1.9381 Top 1 Acc: 0.6061 Top 5 Acc: 0.7899 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 116/199\n","----------\n","train Loss: 0.7502 Top 1 Acc: 0.8158 Top 5 Acc: 0.9303 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.9138 Top 1 Acc: 0.6108 Top 5 Acc: 0.7944 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 117/199\n","----------\n","train Loss: 0.7547 Top 1 Acc: 0.8164 Top 5 Acc: 0.9297 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9014 Top 1 Acc: 0.6065 Top 5 Acc: 0.7917 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 118/199\n","----------\n","train Loss: 0.7454 Top 1 Acc: 0.8160 Top 5 Acc: 0.9315 Acc Quest: 1.0008 Acc Ans: 1.0010\n","valid Loss: 1.9185 Top 1 Acc: 0.6059 Top 5 Acc: 0.7922 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 119/199\n","----------\n","train Loss: 0.7495 Top 1 Acc: 0.8147 Top 5 Acc: 0.9311 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8848 Top 1 Acc: 0.6077 Top 5 Acc: 0.7959 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 120/199\n","----------\n","train Loss: 0.7465 Top 1 Acc: 0.8176 Top 5 Acc: 0.9296 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.9114 Top 1 Acc: 0.6082 Top 5 Acc: 0.7945 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 121/199\n","----------\n","train Loss: 0.7410 Top 1 Acc: 0.8158 Top 5 Acc: 0.9318 Acc Quest: 1.0005 Acc Ans: 1.0010\n","valid Loss: 1.8923 Top 1 Acc: 0.6009 Top 5 Acc: 0.7968 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 122/199\n","----------\n","train Loss: 0.7351 Top 1 Acc: 0.8189 Top 5 Acc: 0.9326 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9519 Top 1 Acc: 0.6025 Top 5 Acc: 0.7979 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 123/199\n","----------\n","train Loss: 0.7338 Top 1 Acc: 0.8187 Top 5 Acc: 0.9329 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.9169 Top 1 Acc: 0.6053 Top 5 Acc: 0.7991 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 124/199\n","----------\n","train Loss: 0.7340 Top 1 Acc: 0.8214 Top 5 Acc: 0.9334 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9085 Top 1 Acc: 0.6136 Top 5 Acc: 0.7975 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 125/199\n","----------\n","train Loss: 0.7302 Top 1 Acc: 0.8197 Top 5 Acc: 0.9351 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.9257 Top 1 Acc: 0.6034 Top 5 Acc: 0.7938 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 126/199\n","----------\n","train Loss: 0.7351 Top 1 Acc: 0.8187 Top 5 Acc: 0.9345 Acc Quest: 1.0006 Acc Ans: 1.0011\n","valid Loss: 1.9044 Top 1 Acc: 0.6136 Top 5 Acc: 0.7989 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 127/199\n","----------\n","train Loss: 0.7257 Top 1 Acc: 0.8199 Top 5 Acc: 0.9357 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8840 Top 1 Acc: 0.6135 Top 5 Acc: 0.8027 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 128/199\n","----------\n","train Loss: 0.7149 Top 1 Acc: 0.8234 Top 5 Acc: 0.9361 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8989 Top 1 Acc: 0.6064 Top 5 Acc: 0.8055 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 129/199\n","----------\n","train Loss: 0.7155 Top 1 Acc: 0.8245 Top 5 Acc: 0.9378 Acc Quest: 1.0007 Acc Ans: 1.0010\n","valid Loss: 1.8896 Top 1 Acc: 0.6068 Top 5 Acc: 0.7998 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 130/199\n","----------\n","train Loss: 0.7136 Top 1 Acc: 0.8244 Top 5 Acc: 0.9373 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9014 Top 1 Acc: 0.5983 Top 5 Acc: 0.7977 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 131/199\n","----------\n","train Loss: 0.7193 Top 1 Acc: 0.8242 Top 5 Acc: 0.9373 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9030 Top 1 Acc: 0.6055 Top 5 Acc: 0.8004 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 132/199\n","----------\n","train Loss: 0.7174 Top 1 Acc: 0.8224 Top 5 Acc: 0.9378 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8934 Top 1 Acc: 0.6090 Top 5 Acc: 0.8013 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 133/199\n","----------\n","train Loss: 0.7082 Top 1 Acc: 0.8243 Top 5 Acc: 0.9376 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8737 Top 1 Acc: 0.6082 Top 5 Acc: 0.8018 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 134/199\n","----------\n","train Loss: 0.7092 Top 1 Acc: 0.8251 Top 5 Acc: 0.9378 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.9025 Top 1 Acc: 0.6064 Top 5 Acc: 0.8017 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 135/199\n","----------\n","train Loss: 0.7055 Top 1 Acc: 0.8260 Top 5 Acc: 0.9384 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8797 Top 1 Acc: 0.6112 Top 5 Acc: 0.8036 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 136/199\n","----------\n","train Loss: 0.7020 Top 1 Acc: 0.8272 Top 5 Acc: 0.9401 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8610 Top 1 Acc: 0.6156 Top 5 Acc: 0.8058 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 137/199\n","----------\n","train Loss: 0.7019 Top 1 Acc: 0.8299 Top 5 Acc: 0.9405 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8826 Top 1 Acc: 0.6055 Top 5 Acc: 0.8024 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 138/199\n","----------\n","train Loss: 0.7001 Top 1 Acc: 0.8268 Top 5 Acc: 0.9400 Acc Quest: 1.0010 Acc Ans: 1.0010\n","valid Loss: 1.9048 Top 1 Acc: 0.6145 Top 5 Acc: 0.8031 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 139/199\n","----------\n","train Loss: 0.6979 Top 1 Acc: 0.8295 Top 5 Acc: 0.9416 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.9103 Top 1 Acc: 0.6190 Top 5 Acc: 0.8070 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 140/199\n","----------\n","train Loss: 0.6935 Top 1 Acc: 0.8283 Top 5 Acc: 0.9417 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.8957 Top 1 Acc: 0.6233 Top 5 Acc: 0.8054 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 141/199\n","----------\n","train Loss: 0.6905 Top 1 Acc: 0.8298 Top 5 Acc: 0.9411 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8910 Top 1 Acc: 0.6145 Top 5 Acc: 0.8056 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 142/199\n","----------\n","train Loss: 0.6902 Top 1 Acc: 0.8298 Top 5 Acc: 0.9419 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8942 Top 1 Acc: 0.6223 Top 5 Acc: 0.8079 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 143/199\n","----------\n","train Loss: 0.6899 Top 1 Acc: 0.8291 Top 5 Acc: 0.9426 Acc Quest: 1.0006 Acc Ans: 1.0011\n","valid Loss: 1.8778 Top 1 Acc: 0.6109 Top 5 Acc: 0.8037 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 144/199\n","----------\n","train Loss: 0.6874 Top 1 Acc: 0.8330 Top 5 Acc: 0.9424 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8694 Top 1 Acc: 0.6104 Top 5 Acc: 0.8061 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 145/199\n","----------\n","train Loss: 0.6797 Top 1 Acc: 0.8322 Top 5 Acc: 0.9430 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8893 Top 1 Acc: 0.6073 Top 5 Acc: 0.8071 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 146/199\n","----------\n","train Loss: 0.6788 Top 1 Acc: 0.8338 Top 5 Acc: 0.9445 Acc Quest: 1.0007 Acc Ans: 1.0010\n","valid Loss: 1.8899 Top 1 Acc: 0.6107 Top 5 Acc: 0.8092 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 147/199\n","----------\n","train Loss: 0.6728 Top 1 Acc: 0.8338 Top 5 Acc: 0.9453 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8611 Top 1 Acc: 0.6162 Top 5 Acc: 0.8075 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 148/199\n","----------\n","train Loss: 0.6732 Top 1 Acc: 0.8352 Top 5 Acc: 0.9456 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8815 Top 1 Acc: 0.6120 Top 5 Acc: 0.8054 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 149/199\n","----------\n","train Loss: 0.6747 Top 1 Acc: 0.8360 Top 5 Acc: 0.9453 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8905 Top 1 Acc: 0.6127 Top 5 Acc: 0.8037 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 150/199\n","----------\n","train Loss: 0.6743 Top 1 Acc: 0.8343 Top 5 Acc: 0.9464 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8633 Top 1 Acc: 0.6216 Top 5 Acc: 0.8085 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 151/199\n","----------\n","train Loss: 0.6741 Top 1 Acc: 0.8322 Top 5 Acc: 0.9455 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8661 Top 1 Acc: 0.6142 Top 5 Acc: 0.8073 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 152/199\n","----------\n","train Loss: 0.6696 Top 1 Acc: 0.8350 Top 5 Acc: 0.9464 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8893 Top 1 Acc: 0.6208 Top 5 Acc: 0.8115 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 153/199\n","----------\n","train Loss: 0.6651 Top 1 Acc: 0.8367 Top 5 Acc: 0.9464 Acc Quest: 1.0011 Acc Ans: 1.0011\n","valid Loss: 1.8573 Top 1 Acc: 0.6097 Top 5 Acc: 0.8076 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 154/199\n","----------\n","train Loss: 0.6612 Top 1 Acc: 0.8375 Top 5 Acc: 0.9466 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8737 Top 1 Acc: 0.6125 Top 5 Acc: 0.8113 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 155/199\n","----------\n","train Loss: 0.6684 Top 1 Acc: 0.8362 Top 5 Acc: 0.9469 Acc Quest: 1.0007 Acc Ans: 1.0010\n","valid Loss: 1.8817 Top 1 Acc: 0.6108 Top 5 Acc: 0.8091 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 156/199\n","----------\n","train Loss: 0.6637 Top 1 Acc: 0.8374 Top 5 Acc: 0.9471 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8671 Top 1 Acc: 0.6102 Top 5 Acc: 0.8028 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 157/199\n","----------\n","train Loss: 0.6615 Top 1 Acc: 0.8369 Top 5 Acc: 0.9476 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8609 Top 1 Acc: 0.6254 Top 5 Acc: 0.8103 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 158/199\n","----------\n","train Loss: 0.6613 Top 1 Acc: 0.8383 Top 5 Acc: 0.9481 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8843 Top 1 Acc: 0.6144 Top 5 Acc: 0.8097 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 159/199\n","----------\n","train Loss: 0.6571 Top 1 Acc: 0.8377 Top 5 Acc: 0.9483 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8722 Top 1 Acc: 0.6230 Top 5 Acc: 0.8111 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 160/199\n","----------\n","train Loss: 0.6514 Top 1 Acc: 0.8407 Top 5 Acc: 0.9496 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8674 Top 1 Acc: 0.6169 Top 5 Acc: 0.8092 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 161/199\n","----------\n","train Loss: 0.6505 Top 1 Acc: 0.8392 Top 5 Acc: 0.9493 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8347 Top 1 Acc: 0.6227 Top 5 Acc: 0.8116 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 162/199\n","----------\n","train Loss: 0.6482 Top 1 Acc: 0.8402 Top 5 Acc: 0.9506 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8751 Top 1 Acc: 0.6190 Top 5 Acc: 0.8075 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 163/199\n","----------\n","train Loss: 0.6519 Top 1 Acc: 0.8402 Top 5 Acc: 0.9480 Acc Quest: 1.0007 Acc Ans: 1.0010\n","valid Loss: 1.8915 Top 1 Acc: 0.6215 Top 5 Acc: 0.8092 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 164/199\n","----------\n","train Loss: 0.6437 Top 1 Acc: 0.8404 Top 5 Acc: 0.9523 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8548 Top 1 Acc: 0.6180 Top 5 Acc: 0.8115 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 165/199\n","----------\n","train Loss: 0.6419 Top 1 Acc: 0.8404 Top 5 Acc: 0.9522 Acc Quest: 1.0008 Acc Ans: 1.0010\n","valid Loss: 1.8432 Top 1 Acc: 0.6181 Top 5 Acc: 0.8195 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 166/199\n","----------\n","train Loss: 0.6366 Top 1 Acc: 0.8430 Top 5 Acc: 0.9529 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8511 Top 1 Acc: 0.6277 Top 5 Acc: 0.8094 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 167/199\n","----------\n","train Loss: 0.6452 Top 1 Acc: 0.8454 Top 5 Acc: 0.9517 Acc Quest: 1.0007 Acc Ans: 1.0009\n","valid Loss: 1.8692 Top 1 Acc: 0.6158 Top 5 Acc: 0.8103 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 168/199\n","----------\n","train Loss: 0.6383 Top 1 Acc: 0.8444 Top 5 Acc: 0.9518 Acc Quest: 1.0006 Acc Ans: 1.0010\n","valid Loss: 1.8397 Top 1 Acc: 0.6266 Top 5 Acc: 0.8148 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 169/199\n","----------\n","train Loss: 0.6347 Top 1 Acc: 0.8429 Top 5 Acc: 0.9530 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8532 Top 1 Acc: 0.6289 Top 5 Acc: 0.8074 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 170/199\n","----------\n","train Loss: 0.6362 Top 1 Acc: 0.8462 Top 5 Acc: 0.9532 Acc Quest: 1.0008 Acc Ans: 1.0010\n","valid Loss: 1.8881 Top 1 Acc: 0.6148 Top 5 Acc: 0.8125 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 171/199\n","----------\n","train Loss: 0.6333 Top 1 Acc: 0.8450 Top 5 Acc: 0.9537 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8622 Top 1 Acc: 0.6207 Top 5 Acc: 0.8162 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 172/199\n","----------\n","train Loss: 0.6294 Top 1 Acc: 0.8438 Top 5 Acc: 0.9537 Acc Quest: 1.0005 Acc Ans: 1.0011\n","valid Loss: 1.8655 Top 1 Acc: 0.6241 Top 5 Acc: 0.8149 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 173/199\n","----------\n","train Loss: 0.6258 Top 1 Acc: 0.8471 Top 5 Acc: 0.9535 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8490 Top 1 Acc: 0.6298 Top 5 Acc: 0.8166 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 174/199\n","----------\n","train Loss: 0.6262 Top 1 Acc: 0.8475 Top 5 Acc: 0.9552 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8594 Top 1 Acc: 0.6221 Top 5 Acc: 0.8152 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 175/199\n","----------\n","train Loss: 0.6292 Top 1 Acc: 0.8468 Top 5 Acc: 0.9538 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8661 Top 1 Acc: 0.6202 Top 5 Acc: 0.8101 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 176/199\n","----------\n","train Loss: 0.6215 Top 1 Acc: 0.8485 Top 5 Acc: 0.9555 Acc Quest: 1.0008 Acc Ans: 1.0010\n","valid Loss: 1.8495 Top 1 Acc: 0.6171 Top 5 Acc: 0.8143 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 177/199\n","----------\n","train Loss: 0.6231 Top 1 Acc: 0.8470 Top 5 Acc: 0.9551 Acc Quest: 1.0005 Acc Ans: 1.0011\n","valid Loss: 1.8415 Top 1 Acc: 0.6258 Top 5 Acc: 0.8165 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 178/199\n","----------\n","train Loss: 0.6194 Top 1 Acc: 0.8498 Top 5 Acc: 0.9559 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8453 Top 1 Acc: 0.6257 Top 5 Acc: 0.8195 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 179/199\n","----------\n","train Loss: 0.6164 Top 1 Acc: 0.8502 Top 5 Acc: 0.9558 Acc Quest: 1.0010 Acc Ans: 1.0011\n","valid Loss: 1.8685 Top 1 Acc: 0.6263 Top 5 Acc: 0.8199 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 180/199\n","----------\n","train Loss: 0.6159 Top 1 Acc: 0.8494 Top 5 Acc: 0.9564 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8550 Top 1 Acc: 0.6194 Top 5 Acc: 0.8157 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 181/199\n","----------\n","train Loss: 0.6175 Top 1 Acc: 0.8498 Top 5 Acc: 0.9550 Acc Quest: 1.0008 Acc Ans: 1.0011\n","valid Loss: 1.8636 Top 1 Acc: 0.6199 Top 5 Acc: 0.8208 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 182/199\n","----------\n","train Loss: 0.6212 Top 1 Acc: 0.8476 Top 5 Acc: 0.9562 Acc Quest: 1.0004 Acc Ans: 1.0011\n","valid Loss: 1.8591 Top 1 Acc: 0.6245 Top 5 Acc: 0.8199 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 183/199\n","----------\n","train Loss: 0.6116 Top 1 Acc: 0.8507 Top 5 Acc: 0.9577 Acc Quest: 1.0008 Acc Ans: 1.0010\n","valid Loss: 1.8613 Top 1 Acc: 0.6248 Top 5 Acc: 0.8149 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 184/199\n","----------\n","train Loss: 0.6109 Top 1 Acc: 0.8494 Top 5 Acc: 0.9571 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8679 Top 1 Acc: 0.6300 Top 5 Acc: 0.8159 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 185/199\n","----------\n","train Loss: 0.6107 Top 1 Acc: 0.8504 Top 5 Acc: 0.9568 Acc Quest: 1.0005 Acc Ans: 1.0011\n","valid Loss: 1.8217 Top 1 Acc: 0.6237 Top 5 Acc: 0.8199 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 186/199\n","----------\n","train Loss: 0.6068 Top 1 Acc: 0.8513 Top 5 Acc: 0.9568 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8452 Top 1 Acc: 0.6204 Top 5 Acc: 0.8155 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 187/199\n","----------\n","train Loss: 0.6037 Top 1 Acc: 0.8521 Top 5 Acc: 0.9581 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8311 Top 1 Acc: 0.6344 Top 5 Acc: 0.8199 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 188/199\n","----------\n","train Loss: 0.6066 Top 1 Acc: 0.8532 Top 5 Acc: 0.9579 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.8513 Top 1 Acc: 0.6258 Top 5 Acc: 0.8187 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 189/199\n","----------\n","train Loss: 0.6011 Top 1 Acc: 0.8530 Top 5 Acc: 0.9585 Acc Quest: 1.0007 Acc Ans: 1.0009\n","valid Loss: 1.8509 Top 1 Acc: 0.6347 Top 5 Acc: 0.8236 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 190/199\n","----------\n","train Loss: 0.5969 Top 1 Acc: 0.8539 Top 5 Acc: 0.9581 Acc Quest: 1.0005 Acc Ans: 1.0010\n","valid Loss: 1.8824 Top 1 Acc: 0.6284 Top 5 Acc: 0.8175 Acc Quest: 1.0074 Acc Ans: 1.0095\n","Epoch 191/199\n","----------\n","train Loss: 0.5984 Top 1 Acc: 0.8575 Top 5 Acc: 0.9591 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8617 Top 1 Acc: 0.6337 Top 5 Acc: 0.8173 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 192/199\n","----------\n","train Loss: 0.6026 Top 1 Acc: 0.8523 Top 5 Acc: 0.9593 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8616 Top 1 Acc: 0.6281 Top 5 Acc: 0.8215 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 193/199\n","----------\n","train Loss: 0.5950 Top 1 Acc: 0.8555 Top 5 Acc: 0.9591 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8468 Top 1 Acc: 0.6370 Top 5 Acc: 0.8255 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 194/199\n","----------\n","train Loss: 0.5898 Top 1 Acc: 0.8548 Top 5 Acc: 0.9609 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.8622 Top 1 Acc: 0.6239 Top 5 Acc: 0.8215 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 195/199\n","----------\n","train Loss: 0.5976 Top 1 Acc: 0.8555 Top 5 Acc: 0.9598 Acc Quest: 1.0010 Acc Ans: 1.0010\n","valid Loss: 1.8713 Top 1 Acc: 0.6298 Top 5 Acc: 0.8194 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 196/199\n","----------\n","train Loss: 0.5934 Top 1 Acc: 0.8580 Top 5 Acc: 0.9619 Acc Quest: 1.0009 Acc Ans: 1.0011\n","valid Loss: 1.8672 Top 1 Acc: 0.6215 Top 5 Acc: 0.8209 Acc Quest: 1.0089 Acc Ans: 1.0095\n","Epoch 197/199\n","----------\n","train Loss: 0.5869 Top 1 Acc: 0.8553 Top 5 Acc: 0.9613 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8805 Top 1 Acc: 0.6312 Top 5 Acc: 0.8215 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 198/199\n","----------\n","train Loss: 0.5837 Top 1 Acc: 0.8580 Top 5 Acc: 0.9604 Acc Quest: 1.0009 Acc Ans: 1.0010\n","valid Loss: 1.8328 Top 1 Acc: 0.6274 Top 5 Acc: 0.8220 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Epoch 199/199\n","----------\n","train Loss: 0.5839 Top 1 Acc: 0.8582 Top 5 Acc: 0.9618 Acc Quest: 1.0007 Acc Ans: 1.0011\n","valid Loss: 1.8417 Top 1 Acc: 0.6275 Top 5 Acc: 0.8237 Acc Quest: 1.0095 Acc Ans: 1.0095\n","Training complete in 136m 2s\n","Best val Top 1 Acc: 0.636999, Top 5 Acc: 0.825522\n"]}],"source":["seed_value = 97\n","np.random.seed(seed_value)\n","random.seed(seed_value)\n","torch.manual_seed(seed_value)\n","torch.cuda.manual_seed(seed_value)\n","torch.cuda.manual_seed_all(seed_value)\n","torch.backends.cudnn.enabled = False\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","def train_model():\n","    since = time.time()\n","\n","    best_acc1 = 0.0\n","    best_acc5 = 0.0\n","\n","    best_acc_q = 0.0\n","    best_acc_a = 0.0\n","\n","    #best_acc_val = 0.0\n","    best_epoch = 0\n","    list_train_loss_per_epoch = []\n","    list_valid_loss_per_epoch = []\n","\n","    list_train_acc1_per_epoch = []\n","    list_valid_acc1_per_epoch = []\n","\n","    model = VqaClassifierModel(opt=opt).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0001)\n","\n","\n","    saved_dir = \"/content/drive/MyDrive\"\n","    #saved_dir = \"/content\"\n","\n","\n","    num_epochs = 200\n","    image_size = 224\n","    num_workers = 0\n","    batch_size = 32\n","\n","\n","    # Create the DataLoader for our dataset\n","\n","    data_loader = get_loader(batch_size = batch_size,\n","            num_workers = num_workers,\n","            size = image_size )\n","\n","    #alpha1 = 0.4\n","    #alpha2 = 0.3\n","    #alpha3 = 0.3\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'valid']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            #accuracy = 0\n","            top1_acc = 0\n","            top5_acc = 0\n","            acc_test_f = 0\n","\n","            acc_q = 0\n","            acc_a = 0\n","\n","            bleu = 0\n","            batch_step_size = len(data_loader[phase].dataset) / batch_size\n","\n","            # Iterate over data.\n","            for batch_idx, batch_sample in enumerate(data_loader[phase]):\n","\n","                #image = batch_sample['image'].to(device)\n","                image = batch_sample['image'].to(device)\n","                #print(image.shape)\n","                questions = batch_sample['question']#.to(device)\n","                labels_answer = batch_sample['answer_label'].to(device)\n","                labels_q_type = batch_sample['question_type_label'].to(device)\n","                labels_a_type = batch_sample['answer_type_label'].to(device)\n","                label_answer_text = batch_sample['answer_text']#.to(device)\n","                label_organ_type = batch_sample['image_organ_label'].to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    output= model(image, questions)\n","\n","                    #_, preds = torch.max(output, 1)\n","                    \"\"\"\n","                    print(labels_q_type.shape)\n","                    print(labels_a_type.shape)\n","\n","                    print(labels_answer.shape)\n","                    print(output[0].shape)\n","                    print(output[1].shape)\n","                    print(output[2].shape)\n","                    \"\"\"\n","                    labels_answer = labels_answer.squeeze(1)\n","                    labels_answer = labels_answer.squeeze(1).float()\n","\n","\n","                    labels_q_type = labels_q_type.squeeze(1)\n","                    labels_q_type = labels_q_type.squeeze(1).float()\n","\n","                    labels_a_type = labels_a_type.squeeze(1)\n","                    labels_a_type = labels_a_type.squeeze(1).float()\n","\n","                    label_organ_type = label_organ_type.squeeze(1)\n","                    label_organ_type = label_organ_type.squeeze(1).float()\n","\n","                    #print(labels_answer.shape)\n","\n","                    loss_0 = criterion(output[0], labels_answer)\n","                    loss_1 = criterion(output[1], labels_q_type)\n","                    loss_2 = criterion(output[2], labels_a_type)\n","                    loss_3 = criterion(output[3], label_organ_type)\n","                    #print(loss_0, loss_1, loss_2)\n","                    #loss = loss_0 * alpha1 + loss_1 * alpha2 + loss_2 * alpha3\n","                    loss = loss_0 + loss_1 + loss_2 + loss_3\n","\n","                    #loss = criterion(output, labels_answer)\n","                    #print(loss)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item()\n","\n","                #exact match score\n","                acc1, acc5 = accuracy(output[0].data, labels_answer.data, topk=(1, 5))\n","                #print(\"first\")\n","                #print(output[0].shape)\n","                #print(labels_answer.shape)\n","                #print(output[0])\n","                #print(labels_answer)\n","                top1_acc += acc1\n","                top5_acc += acc5\n","\n","                acc_quest, _ = accuracy(output[1].data, labels_q_type.data, topk=(1, 5))\n","                #print(\"second\")\n","                #print(output[1].shape)\n","                #print(labels_q_type.shape)\n","                #print(output[1])\n","                #print(labels_q_type)\n","                acc_q += acc_quest\n","\n","\n","                acc_ans, _ = accuracy(output[2].data, labels_a_type.data, topk=(1, 2))\n","                acc_a += acc_ans\n","\n","                #bleu score\n","                #b = get_bleu_score(preds, label_answer_text)\n","                #bleu += b\n","\n","\n","                if batch_idx % 10 == 0:\n","                    pass\n","                    # print('| {} SET | Epoch [{:02d}/{:02d}], Step[{:04d}/{:04d}], Loss: {:.4f}, Top 1 Acc: {:.4f}, Top 5 Acc: {:.4f}, Quest Acc: {:.4f} Ans Acc: {:.47}'.format(phase.upper(), epoch+1, num_epochs, batch_idx, int(batch_step_size), loss.item(), acc1, acc5, acc_quest, acc_ans))#Acc: {:.4f},Bleu: {:.4f},acc, b\n","                    #print('| {} SET | Epoch [{:02d}/{:02d}], Step[{:04d}/{:04d}], Loss: {:.4f}, Top 1 Acc: {:.4f}, Top 5 Acc: {:.4f}'.format(phase.upper(), epoch+1, num_epochs, batch_idx, int(batch_step_size), loss.item(), acc1, acc5))#Acc: {:.4f},Bleu: {:.4f},acc, b\n","\n","\n","            epoch_loss = running_loss/batch_step_size\n","            epoch_acc1 = top1_acc/batch_step_size\n","            epoch_acc5 = top5_acc/batch_step_size\n","            epoch_acc_q = acc_q/batch_step_size\n","            epoch_acc_a = acc_a/batch_step_size\n","\n","            #epoch_blue = bleu/batch_step_size\n","\n","            #save the loss and accuracy for train and valid\n","            if phase =='train':\n","\n","                list_train_loss_per_epoch.append(epoch_loss)\n","                list_train_acc1_per_epoch.append(epoch_acc1)\n","\n","            else:\n","\n","                list_valid_loss_per_epoch.append(epoch_loss)\n","                list_valid_acc1_per_epoch.append(epoch_acc1)\n","                \"\"\"\n","                alpha1 += 0.02\n","                total_weight = alpha1 + alpha2 + alpha3\n","                alpha1 /= total_weight\n","                alpha2 /= total_weight\n","                alpha3 /= total_weight\n","                \"\"\"\n","\n","            print('{} Loss: {:.4f} Top 1 Acc: {:.4f} Top 5 Acc: {:.4f} Acc Quest: {:.4f} Acc Ans: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc1, epoch_acc5, epoch_acc_q, epoch_acc_a))\n","\n","\n","            # deep copy the model\n","            if phase == 'valid' and epoch_acc1 > best_acc1: #or epoch_acc5 > best_acc5 ):\n","                best_acc1 = epoch_acc1\n","                best_acc5 = epoch_acc5\n","                best_epoch = epoch\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","\n","\n","    history_loss = {'train':list_train_loss_per_epoch, 'valid':list_valid_loss_per_epoch}\n","    history_acc1 = {'train':list_train_acc1_per_epoch, 'valid':list_valid_acc1_per_epoch}\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Top 1 Acc: {:4f}, Top 5 Acc: {:4f}'.format(best_acc1,best_acc5))\n","\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    model.load_state_dict(best_model_wts)\n","    state = {'epoch': best_epoch,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","                'loss':epoch_loss,'valid_accuracy': best_acc1}\n","\n","    #full_model_path =saved_dir+'/ovqa_2_tasks_mainandquest_model_state_seed_97.tar'\n","    full_model_path =saved_dir+'/ovqa_multitask_cascade_200epc_1024mfb_out_batch32_swin_model_state_seed_97.tar'\n","\n","    torch.save(state, full_model_path)\n","    return model\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","\n","\n","\n","    if target.dim() == 2: # multians option\n","        _, target = torch.max(target, 1)\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].reshape(-1).float().sum(0)\n","        res.append((correct_k / batch_size))\n","\n","    return res\n","\n","\n","def get_bleu_score(predicted, true_ans_text):\n","    path_output_change = config.path_output_chd\n","    with open(path_output_change+'/answer_classes.json', 'r') as j:\n","        answer_classes_dict = json.load(j)\n","    score = 0.0\n","    assert (len(predicted) == len(true_ans_text))\n","    ans_keys = list(answer_classes_dict.keys())\n","    ans_values = list(answer_classes_dict.values())\n","\n","\n","    for pred, true_ans in zip(predicted, true_ans_text):\n","        index_ans = ans_values.index(pred)\n","\n","        score += sentence_bleu([true_ans.split(' ')], ans_keys[index_ans].split(' '), smoothing_function=bleu_score.SmoothingFunction().method2)\n","\n","    return score/len(true_ans_text)\n","\n","\n","def load_checkpoint(model, optimizer, filename=None):\n","    # Note: Input model & optimizer should be pre-defined. This routine only updates their states.\n","    start_epoch = 0\n","    if os.path.isfile(filename):\n","        print(\"=> loading checkpoint '{}'\".format(filename))\n","        checkpoint = torch.load(filename)\n","        start_epoch = checkpoint['epoch']\n","        model.load_state_dict(checkpoint['state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","        print(\"=> loaded checkpoint '{}' (epoch {})\" .format(filename,\n","                                                            checkpoint['epoch']))\n","    else: print(\"=> no checkpoint found at '{}'\".format(filename))\n","    return model, optimizer, start_epoch\n","\n","\n","\n","def make_plot(history, epoch_max, path_output_chd, type_plot='loss'):\n","    train = history['train']\n","    valid = history['valid']\n","    fig, ax = plt.subplots()\n","    epochs = range(epoch_max)\n","\n","\n","    if type_plot=='loss':\n","        plt.plot(epochs, train, '-r', lw=2, label='Training loss')\n","        plt.plot(epochs, valid, '-b',lw=2, label='validation loss')\n","        plt.legend(borderaxespad=0.)\n","        plt.title('Training and Validation loss')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Loss')\n","        plt.savefig(path_output_chd+'/imgs/loss.png')\n","\n","    elif type_plot == 'acc1':\n","\n","        plt.plot(epochs, train, '-r', lw = 2, label='Training Top 1 Accuracy')\n","        plt.plot(epochs, valid, '-b', lw = 2, label='validation Top 1 Accuracy')\n","        plt.legend(borderaxespad=0.)\n","        plt.title('Training and Validation Top 1 Accuracy')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Top 1 Accuracy')\n","        plt.savefig(path_output_chd+'/imgs/acc1.png')\n","\n","    elif type_plot == 'acc5':\n","\n","        plt.plot(epochs, train, '-r', lw = 2, label='Training Top 5 Accuracy')\n","        plt.plot(epochs, valid, '-b', lw = 2, label='validation Top 5 Accuracy')\n","        plt.legend(borderaxespad=0.)\n","        plt.title('Training and Validation Top 5 Accuracy')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Top 5 Accuracy')\n","        plt.savefig(path_output_chd+'/imgs/acc5.png')\n","    else:\n","        plt.plot(epochs, train, '-r', lw = 2, label='Training blue')\n","        plt.plot(epochs, valid, '-b', lw = 2, label='validation blue')\n","        plt.legend(borderaxespad=0.)\n","        plt.title('Training and Validation blue')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Blue')\n","        plt.savefig(path_output_chd+'/imgs/blue.png')\n","\n","\n","\n","    plt.show()\n","\n","\n","def main():\n","    train_model()\n","\n","\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711923145726,"user":{"displayName":"Teodora Toader","userId":"08245025863721384794"},"user_tz":-180},"id":"gQqT4BNkxJjy","outputId":"bab12363-e730-4b91-c534-5fb56ce44172"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_dd601179-3650-41da-bb89-984e88e809f1\", \"model_state_seed_97.tar\", 1052240734)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","files.download('/content/model_state_seed_97.tar')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250,"referenced_widgets":["ef8826f05cb74446a95b90fb402e95ce","7e82722988c5494f9ef12528289a7773","65504b90431b41cf98c7a7a0dcb55beb","5d66cf30d3c74c73954ba345d8ae7335","889894fe201d4bfab6fb297e952a96b9","1c0ebe267eeb4a7a8108ae4877acb5aa","d55af36a5260443ebfa6b5cc7446a42e","1110d495e7624cd988374dd5f4934980","3666906cd96f4a21bb9cc99d8c113835","1441a916ae104f20b7aca5d76a05ded7","27d7c05e9b2c452eb73b546bef3a555c","7c56a774d1d9413bba17b3753accb368","781d3eb170404166b69894c9d600d570","9438eec545174ffb84e489ebc4ff582c","76760d7adb5444f3bce0a9d7ab9a1901","d92d56adca244b78b0d5dfcac9512f78","03b1fbca7af74c1a9795a9fedb20bcc1","cd54b75b09b640ea99b08315deaae56a","0d206ed9b2324bc19fe90ede6e75eb03","f3fe962ff3f24658a4ca6a86815b7ab5","3977174e9fbc4832984b27e49e952c89","16d0746f72204d4590c24528179d54e1","d188a5740db64435b5db133f1a4a755d","8cbc8934924a470989f4caa9bbddef28","72c46c938c614180a88f132ccc221a6f","8436ae77733b407f9771e8a325eabe29","86c4fb9f64d2496f82287f4f46208b5f","d1c197d25a3646998ce9f49c199d91d1","e2e4d7375705463da53b78bf9cfacf51","6eb6a74fbe19433ca9b6b739f4ea4339","242785828666406c83d2f0f1503ecb2f","a8b1576b99534a11801169ad0679d7e2","f8c20dec1580464faf73513d0e83a75b","10eee68a2945473f83848056749cd35b","b940e619acf94610a4660e53459a20fe","f80b062c871940e78c4c155603d448a7","17b32b7aa5324e2392f95f10a4674d15","d8d72b37b780414e99d9e816c53ec192","fd91ecb2b2be4e17a8815a05b23ddcae","cea8650e9059492f874b2e717c932743","960305d762644822a57cefbeb7019bc7","f2068efe9dd94696a27ee52bff524a54","421089145edd46099a3115fd3f56de31","8b1c26f875eb4526b73018ffb4b58395","7d1a1092a0ad4fc0aa47df596737882d","4de5c9d644034072b63ebf6bbc15bc15","f07fb62848584e5994cba26d432dbf4a","5d4eeb0169e24a51a1b57980b6fe41bf","a52094253e0f4fd98eb55719224c0864","04f0c8ca70df4a02937b152f47fd661f","4b22593b584e41f799bd71e561b26b8d","2b2d577da8b849188cb3a7746bb4d668","675a1a993486464a93d4b9f0f24346d5","e765bb08ad124f22a475f5d01766c156","91861fd56418408da74fda12d0400fea"]},"executionInfo":{"elapsed":22320,"status":"ok","timestamp":1721105315159,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"},"user_tz":-180},"id":"XyK1ejLbir3n","outputId":"9f0d0316-45b1-4633-a5c0-24221e3f1bf6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef8826f05cb74446a95b90fb402e95ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c56a774d1d9413bba17b3753accb368"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d188a5740db64435b5db133f1a4a755d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10eee68a2945473f83848056749cd35b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d1a1092a0ad4fc0aa47df596737882d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=> loading checkpoint '/content/drive/MyDrive/ovqa_multitask_cascade_200epc_1024mfb_out_batch32_swin_model_state_seed_97.tar'\n","=> loaded checkpoint '/content/drive/MyDrive/ovqa_multitask_cascade_200epc_1024mfb_out_batch32_swin_model_state_seed_97.tar' (epoch 193)\n","Inferencing ...\n","Evaluation complete in 0m 4s\n"]}],"source":["# Testing\n","\n","import os\n","import argparse\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import json\n","import copy\n","import random\n","import math\n","import time\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","transform = transforms.Compose([transforms.Pad((0, 85), fill=0, padding_mode='constant'),\n","                                transforms.Resize((224, 224)),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","                                ])\n","\n","def get_test_loader(batch_size, num_workers):\n","    test_vqa_dataset = OVQADataset(\n","            json_file=f\"{ROOT_PATH}testset.json\",\n","            root_dir=f\"{ROOT_PATH}img\",\n","            phase = 'test',\n","            transform=transform)\n","\n","\n","    data_loader = torch.utils.data.DataLoader(dataset=test_vqa_dataset,\n","                                                batch_size=batch_size,\n","                                                shuffle=False,\n","                                                num_workers=num_workers)\n","    return data_loader\n","\n","\n","def inference(model, test_loader, answer_classes_dict, path_change):\n","    since = time.time()\n","    model.eval()\n","    results = []\n","    print('Inferencing ...')\n","    # Iterate over data.\n","    for batch_idx, batch_sample in enumerate(test_loader):\n","        image = batch_sample['image'].to(device)\n","        qid = batch_sample['qid']\n","        questions = batch_sample['question']\n","\n","        output = model(image, questions)\n","        preds = torch.argmax(output[0], dim=-1)\n","        preds = preds.cpu().detach().numpy()\n","\n","        assert (len(preds) == len(qid))\n","\n","        ans_keys = list(answer_classes_dict.keys())\n","        ans_values = list(answer_classes_dict.values())\n","\n","\n","        for pred, image_name in zip(preds, qid):\n","            index_ans = ans_values.index(pred)\n","            results.append({image_name+'|'+ans_keys[index_ans]})\n","\n","    df = pd.DataFrame(results)\n","\n","    df.columns =['qid-answer']\n","    df.to_csv(path_change+'/submission.csv', index=False)\n","\n","    time_elapsed = time.time() - since\n","    print('Evaluation complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","\n","\n","def main():\n","\n","    batch_size = opt.BATCH_SIZE\n","    num_workers = 0\n","    image_size = opt.IMG_INPUT_SIZE\n","\n","    # Create the DataLoader for our dataset\n","    test_data_loader = get_test_loader(\n","        batch_size = batch_size,\n","        num_workers = num_workers)\n","\n","    model = VqaClassifierModel( opt=opt ).to(device)\n","    saved_dir = \"/content\"\n","    filename =saved_dir+'/drive/MyDrive/ovqa_multitask_cascade_200epc_1024mfb_out_batch32_swin_model_state_seed_97.tar'\n","    print(\"=> loading checkpoint '{}'\".format(filename))\n","    checkpoint = torch.load(filename)\n","    start_epoch = checkpoint['epoch']\n","    model.load_state_dict(checkpoint['state_dict'])\n","\n","    print(\"=> loaded checkpoint '{}' (epoch {})\" .format(filename, checkpoint['epoch']))\n","    inference(model=model, test_loader=test_data_loader, answer_classes_dict=answer_classes, path_change=\"/content\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"markdown","metadata":{"id":"k0QvXltKuj8n"},"source":["#0.5478443743427971 multitask v1\n","#0.555205047318612 (80 epochs)fara multitask 0.5636172450052577 cu 150 epochs\n","#0.5368033648790747 multitask weighted\n","#0.5494216614090431 multitask 2 taskuri\n","#0.5399579390115667 with changing weights\n","#0.5509989484752892 cu input de la taskurile de question date la taskul principal concatenate cu outputul de la fusion\n","#0.5720294426919033 ca mai sus da 150 epoci\n","#0.5736067297581493 200 epoci"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_GBMHjTpu7vX","executionInfo":{"status":"ok","timestamp":1721105325837,"user_tz":-180,"elapsed":294,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"outputs":[],"source":["test_answers_dict = {}\n","for elem in data_test:\n","  test_answers_dict[elem[\"qid\"]] = elem[\"answer\"]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1721105327707,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"},"user_tz":-180},"id":"1t7C1KthoLJ3","outputId":"1f9f0304-6258-4091-cd93-2a51f113e712"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.5988433228180863\n"]}],"source":["def get_test_accuracy(test_answers, predictions_csv_file):\n","  df = pd.read_csv(predictions_csv_file)\n","  acc = 0\n","  for index, row in df.iterrows():\n","    qid, ans = row[\"qid-answer\"].split(\"|\")[0], row[\"qid-answer\"].split(\"|\")[1]\n","    if test_answers[qid] == ans:\n","      acc += 1\n","  print(acc/len(df))\n","\n","get_test_accuracy(test_answers_dict, \"/content/submission.csv\")"]},{"cell_type":"markdown","source":["0.5215562565720294 first resnet 1024\n","0.5141 second resnet 20148\n"],"metadata":{"id":"rOw2fsXxd81b"}},{"cell_type":"markdown","source":["0.5804 vit 1024 32\n","0.5778 vit 1024 64"],"metadata":{"id":"UJcwh84FTJ5c"}},{"cell_type":"markdown","source":["0.5930 swin 32 (trb reantrenat overwritten)\n","0.5830 swin 64"],"metadata":{"id":"l5zl1ND9_5gH"}},{"cell_type":"code","source":[],"metadata":{"id":"s_3UMGDnsPGt"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1G4eFXOEFpzAr13LO8-oaoT3LW8rYiaR2","timestamp":1721025635127},{"file_id":"1rtZJjbFWtmsPKVgG8k1fLRcpBNlR_scg","timestamp":1720115355936},{"file_id":"17Wz585v07I1BW-0OuJ7SY8x92kr0W70p","timestamp":1711869816329}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ef8826f05cb74446a95b90fb402e95ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e82722988c5494f9ef12528289a7773","IPY_MODEL_65504b90431b41cf98c7a7a0dcb55beb","IPY_MODEL_5d66cf30d3c74c73954ba345d8ae7335"],"layout":"IPY_MODEL_889894fe201d4bfab6fb297e952a96b9"}},"7e82722988c5494f9ef12528289a7773":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c0ebe267eeb4a7a8108ae4877acb5aa","placeholder":"","style":"IPY_MODEL_d55af36a5260443ebfa6b5cc7446a42e","value":"tokenizer_config.json:100%"}},"65504b90431b41cf98c7a7a0dcb55beb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1110d495e7624cd988374dd5f4934980","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3666906cd96f4a21bb9cc99d8c113835","value":48}},"5d66cf30d3c74c73954ba345d8ae7335":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1441a916ae104f20b7aca5d76a05ded7","placeholder":"","style":"IPY_MODEL_27d7c05e9b2c452eb73b546bef3a555c","value":"48.0/48.0[00:00&lt;00:00,3.21kB/s]"}},"889894fe201d4bfab6fb297e952a96b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c0ebe267eeb4a7a8108ae4877acb5aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55af36a5260443ebfa6b5cc7446a42e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1110d495e7624cd988374dd5f4934980":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3666906cd96f4a21bb9cc99d8c113835":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1441a916ae104f20b7aca5d76a05ded7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d7c05e9b2c452eb73b546bef3a555c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c56a774d1d9413bba17b3753accb368":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_781d3eb170404166b69894c9d600d570","IPY_MODEL_9438eec545174ffb84e489ebc4ff582c","IPY_MODEL_76760d7adb5444f3bce0a9d7ab9a1901"],"layout":"IPY_MODEL_d92d56adca244b78b0d5dfcac9512f78"}},"781d3eb170404166b69894c9d600d570":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03b1fbca7af74c1a9795a9fedb20bcc1","placeholder":"","style":"IPY_MODEL_cd54b75b09b640ea99b08315deaae56a","value":"vocab.txt:100%"}},"9438eec545174ffb84e489ebc4ff582c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d206ed9b2324bc19fe90ede6e75eb03","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3fe962ff3f24658a4ca6a86815b7ab5","value":231508}},"76760d7adb5444f3bce0a9d7ab9a1901":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3977174e9fbc4832984b27e49e952c89","placeholder":"","style":"IPY_MODEL_16d0746f72204d4590c24528179d54e1","value":"232k/232k[00:00&lt;00:00,1.73MB/s]"}},"d92d56adca244b78b0d5dfcac9512f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03b1fbca7af74c1a9795a9fedb20bcc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd54b75b09b640ea99b08315deaae56a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d206ed9b2324bc19fe90ede6e75eb03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3fe962ff3f24658a4ca6a86815b7ab5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3977174e9fbc4832984b27e49e952c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16d0746f72204d4590c24528179d54e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d188a5740db64435b5db133f1a4a755d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8cbc8934924a470989f4caa9bbddef28","IPY_MODEL_72c46c938c614180a88f132ccc221a6f","IPY_MODEL_8436ae77733b407f9771e8a325eabe29"],"layout":"IPY_MODEL_86c4fb9f64d2496f82287f4f46208b5f"}},"8cbc8934924a470989f4caa9bbddef28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c197d25a3646998ce9f49c199d91d1","placeholder":"","style":"IPY_MODEL_e2e4d7375705463da53b78bf9cfacf51","value":"tokenizer.json:100%"}},"72c46c938c614180a88f132ccc221a6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eb6a74fbe19433ca9b6b739f4ea4339","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_242785828666406c83d2f0f1503ecb2f","value":466062}},"8436ae77733b407f9771e8a325eabe29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b1576b99534a11801169ad0679d7e2","placeholder":"","style":"IPY_MODEL_f8c20dec1580464faf73513d0e83a75b","value":"466k/466k[00:00&lt;00:00,2.41MB/s]"}},"86c4fb9f64d2496f82287f4f46208b5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1c197d25a3646998ce9f49c199d91d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e4d7375705463da53b78bf9cfacf51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6eb6a74fbe19433ca9b6b739f4ea4339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"242785828666406c83d2f0f1503ecb2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8b1576b99534a11801169ad0679d7e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8c20dec1580464faf73513d0e83a75b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10eee68a2945473f83848056749cd35b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b940e619acf94610a4660e53459a20fe","IPY_MODEL_f80b062c871940e78c4c155603d448a7","IPY_MODEL_17b32b7aa5324e2392f95f10a4674d15"],"layout":"IPY_MODEL_d8d72b37b780414e99d9e816c53ec192"}},"b940e619acf94610a4660e53459a20fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd91ecb2b2be4e17a8815a05b23ddcae","placeholder":"","style":"IPY_MODEL_cea8650e9059492f874b2e717c932743","value":"config.json:100%"}},"f80b062c871940e78c4c155603d448a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_960305d762644822a57cefbeb7019bc7","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2068efe9dd94696a27ee52bff524a54","value":570}},"17b32b7aa5324e2392f95f10a4674d15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_421089145edd46099a3115fd3f56de31","placeholder":"","style":"IPY_MODEL_8b1c26f875eb4526b73018ffb4b58395","value":"570/570[00:00&lt;00:00,26.5kB/s]"}},"d8d72b37b780414e99d9e816c53ec192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd91ecb2b2be4e17a8815a05b23ddcae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cea8650e9059492f874b2e717c932743":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"960305d762644822a57cefbeb7019bc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2068efe9dd94696a27ee52bff524a54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"421089145edd46099a3115fd3f56de31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1c26f875eb4526b73018ffb4b58395":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d1a1092a0ad4fc0aa47df596737882d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4de5c9d644034072b63ebf6bbc15bc15","IPY_MODEL_f07fb62848584e5994cba26d432dbf4a","IPY_MODEL_5d4eeb0169e24a51a1b57980b6fe41bf"],"layout":"IPY_MODEL_a52094253e0f4fd98eb55719224c0864"}},"4de5c9d644034072b63ebf6bbc15bc15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04f0c8ca70df4a02937b152f47fd661f","placeholder":"","style":"IPY_MODEL_4b22593b584e41f799bd71e561b26b8d","value":"model.safetensors:100%"}},"f07fb62848584e5994cba26d432dbf4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b2d577da8b849188cb3a7746bb4d668","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_675a1a993486464a93d4b9f0f24346d5","value":440449768}},"5d4eeb0169e24a51a1b57980b6fe41bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e765bb08ad124f22a475f5d01766c156","placeholder":"","style":"IPY_MODEL_91861fd56418408da74fda12d0400fea","value":"440M/440M[00:01&lt;00:00,279MB/s]"}},"a52094253e0f4fd98eb55719224c0864":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04f0c8ca70df4a02937b152f47fd661f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b22593b584e41f799bd71e561b26b8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2d577da8b849188cb3a7746bb4d668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675a1a993486464a93d4b9f0f24346d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e765bb08ad124f22a475f5d01766c156":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91861fd56418408da74fda12d0400fea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}