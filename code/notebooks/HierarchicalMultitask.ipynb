{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["1060liaPlDo5","meCJ4YYGmYQt","iUiXZv9ZpGl5","2k9go_SQs3lz"],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOIpUTYHNsMhjs1uij5u75k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"bfsmS71HsnkM"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"kX3-7LyzqkbS","executionInfo":{"status":"ok","timestamp":1724610096893,"user_tz":-180,"elapsed":6057,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"outputs":[],"source":["import torchvision\n","import os\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import math\n","import pickle\n","from torch.utils.data import random_split, DataLoader\n","import torch.optim as optim\n","import torch"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"zdqPwTbIvJa4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"1060liaPlDo5"}},{"cell_type":"code","source":["transform2 = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((224, 224)),  # Resize to 224x224 to match MobileNet's input size\n","    torchvision.transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n","    # torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","transform = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((28, 28)),  # Resize to 224x224 to match MobileNet's input size\n","    torchvision.transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n","    # torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])"],"metadata":{"id":"S6SqXB5w2K7w","executionInfo":{"status":"ok","timestamp":1724608914604,"user_tz":-180,"elapsed":319,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.mkdir('/content/dataset/')\n","os.mkdir('/content/dataset/train/')\n","os.mkdir('/content/dataset/test/')\n","train_dataset = torchvision.datasets.CIFAR100(root='/content/dataset/train/', download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR100(root='/content/dataset/test/', download=True, transform=transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCvkQvh7rrR8","executionInfo":{"status":"ok","timestamp":1724608930803,"user_tz":-180,"elapsed":15881,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"8a439097-4b57-4c86-966b-187ce8abf545"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /content/dataset/train/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169001437/169001437 [00:03<00:00, 42617253.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/dataset/train/cifar-100-python.tar.gz to /content/dataset/train/\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /content/dataset/test/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169001437/169001437 [00:05<00:00, 31857184.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/dataset/test/cifar-100-python.tar.gz to /content/dataset/test/\n"]}]},{"cell_type":"code","source":["#@title CIFAR100 Classes & Superclasses\n","\n","import json\n","\n","# Define the classes and superclasses\n","cifar100_classes = [\n","    # Superclass: Aquatic Mammals\n","    {\"class\": \"beaver\", \"superclass\": \"aquatic mammals\"},\n","    {\"class\": \"dolphin\", \"superclass\": \"aquatic mammals\"},\n","    {\"class\": \"otter\", \"superclass\": \"aquatic mammals\"},\n","    {\"class\": \"seal\", \"superclass\": \"aquatic mammals\"},\n","    {\"class\": \"whale\", \"superclass\": \"aquatic mammals\"},\n","\n","    # Superclass: Fish\n","    {\"class\": \"aquarium fish\", \"superclass\": \"fish\"},\n","    {\"class\": \"flatfish\", \"superclass\": \"fish\"},\n","    {\"class\": \"ray\", \"superclass\": \"fish\"},\n","    {\"class\": \"shark\", \"superclass\": \"fish\"},\n","    {\"class\": \"trout\", \"superclass\": \"fish\"},\n","\n","    # Superclass: Flowers\n","    {\"class\": \"orchid\", \"superclass\": \"flowers\"},\n","    {\"class\": \"poppy\", \"superclass\": \"flowers\"},\n","    {\"class\": \"rose\", \"superclass\": \"flowers\"},\n","    {\"class\": \"sunflower\", \"superclass\": \"flowers\"},\n","    {\"class\": \"tulip\", \"superclass\": \"flowers\"},\n","\n","    # Superclass: Food Containers\n","    {\"class\": \"bottle\", \"superclass\": \"food containers\"},\n","    {\"class\": \"bowl\", \"superclass\": \"food containers\"},\n","    {\"class\": \"can\", \"superclass\": \"food containers\"},\n","    {\"class\": \"cup\", \"superclass\": \"food containers\"},\n","    {\"class\": \"plate\", \"superclass\": \"food containers\"},\n","\n","    # Superclass: Fruits and Vegetables\n","    {\"class\": \"apple\", \"superclass\": \"fruits and vegetables\"},\n","    {\"class\": \"mushroom\", \"superclass\": \"fruits and vegetables\"},\n","    {\"class\": \"orange\", \"superclass\": \"fruits and vegetables\"},\n","    {\"class\": \"pear\", \"superclass\": \"fruits and vegetables\"},\n","    {\"class\": \"sweet pepper\", \"superclass\": \"fruits and vegetables\"},\n","\n","    # Superclass: Household Electrical Devices\n","    {\"class\": \"clock\", \"superclass\": \"household electrical devices\"},\n","    {\"class\": \"keyboard\", \"superclass\": \"household electrical devices\"},\n","    {\"class\": \"lamp\", \"superclass\": \"household electrical devices\"},\n","    {\"class\": \"telephone\", \"superclass\": \"household electrical devices\"},\n","    {\"class\": \"television\", \"superclass\": \"household electrical devices\"},\n","\n","    # Superclass: Household Furniture\n","    {\"class\": \"bed\", \"superclass\": \"household furniture\"},\n","    {\"class\": \"chair\", \"superclass\": \"household furniture\"},\n","    {\"class\": \"couch\", \"superclass\": \"household furniture\"},\n","    {\"class\": \"table\", \"superclass\": \"household furniture\"},\n","    {\"class\": \"wardrobe\", \"superclass\": \"household furniture\"},\n","\n","    # Superclass: Insects\n","    {\"class\": \"bee\", \"superclass\": \"insects\"},\n","    {\"class\": \"beetle\", \"superclass\": \"insects\"},\n","    {\"class\": \"butterfly\", \"superclass\": \"insects\"},\n","    {\"class\": \"caterpillar\", \"superclass\": \"insects\"},\n","    {\"class\": \"cockroach\", \"superclass\": \"insects\"},\n","\n","    # Superclass: Large Carnivores\n","    {\"class\": \"bear\", \"superclass\": \"large carnivores\"},\n","    {\"class\": \"leopard\", \"superclass\": \"large carnivores\"},\n","    {\"class\": \"lion\", \"superclass\": \"large carnivores\"},\n","    {\"class\": \"tiger\", \"superclass\": \"large carnivores\"},\n","    {\"class\": \"wolf\", \"superclass\": \"large carnivores\"},\n","\n","    # Superclass: Large Man-made Outdoor Things\n","    {\"class\": \"bridge\", \"superclass\": \"large man-made outdoor things\"},\n","    {\"class\": \"castle\", \"superclass\": \"large man-made outdoor things\"},\n","    {\"class\": \"house\", \"superclass\": \"large man-made outdoor things\"},\n","    {\"class\": \"road\", \"superclass\": \"large man-made outdoor things\"},\n","    {\"class\": \"skyscraper\", \"superclass\": \"large man-made outdoor things\"},\n","\n","    # Superclass: Large Natural Outdoor Scenes\n","    {\"class\": \"cloud\", \"superclass\": \"large natural outdoor scenes\"},\n","    {\"class\": \"forest\", \"superclass\": \"large natural outdoor scenes\"},\n","    {\"class\": \"mountain\", \"superclass\": \"large natural outdoor scenes\"},\n","    {\"class\": \"plain\", \"superclass\": \"large natural outdoor scenes\"},\n","    {\"class\": \"sea\", \"superclass\": \"large natural outdoor scenes\"},\n","\n","    # Superclass: Large Omnivores and Herbivores\n","    {\"class\": \"camel\", \"superclass\": \"large omnivores and herbivores\"},\n","    {\"class\": \"cattle\", \"superclass\": \"large omnivores and herbivores\"},\n","    {\"class\": \"chimpanzee\", \"superclass\": \"large omnivores and herbivores\"},\n","    {\"class\": \"elephant\", \"superclass\": \"large omnivores and herbivores\"},\n","    {\"class\": \"kangaroo\", \"superclass\": \"large omnivores and herbivores\"},\n","\n","    # Superclass: Medium-sized Mammals\n","    {\"class\": \"fox\", \"superclass\": \"medium-sized mammals\"},\n","    {\"class\": \"porcupine\", \"superclass\": \"medium-sized mammals\"},\n","    {\"class\": \"possum\", \"superclass\": \"medium-sized mammals\"},\n","    {\"class\": \"raccoon\", \"superclass\": \"medium-sized mammals\"},\n","    {\"class\": \"skunk\", \"superclass\": \"medium-sized mammals\"},\n","\n","    # Superclass: Non-insect Invertebrates\n","    {\"class\": \"crab\", \"superclass\": \"non-insect invertebrates\"},\n","    {\"class\": \"lobster\", \"superclass\": \"non-insect invertebrates\"},\n","    {\"class\": \"snail\", \"superclass\": \"non-insect invertebrates\"},\n","    {\"class\": \"spider\", \"superclass\": \"non-insect invertebrates\"},\n","    {\"class\": \"worm\", \"superclass\": \"non-insect invertebrates\"},\n","\n","    # Superclass: People\n","    {\"class\": \"baby\", \"superclass\": \"people\"},\n","    {\"class\": \"boy\", \"superclass\": \"people\"},\n","    {\"class\": \"girl\", \"superclass\": \"people\"},\n","    {\"class\": \"man\", \"superclass\": \"people\"},\n","    {\"class\": \"woman\", \"superclass\": \"people\"},\n","\n","    # Superclass: Reptiles\n","    {\"class\": \"crocodile\", \"superclass\": \"reptiles\"},\n","    {\"class\": \"dinosaur\", \"superclass\": \"reptiles\"},\n","    {\"class\": \"lizard\", \"superclass\": \"reptiles\"},\n","    {\"class\": \"snake\", \"superclass\": \"reptiles\"},\n","    {\"class\": \"turtle\", \"superclass\": \"reptiles\"},\n","\n","    # Superclass: Small Mammals\n","    {\"class\": \"hamster\", \"superclass\": \"small mammals\"},\n","    {\"class\": \"mouse\", \"superclass\": \"small mammals\"},\n","    {\"class\": \"rabbit\", \"superclass\": \"small mammals\"},\n","    {\"class\": \"shrew\", \"superclass\": \"small mammals\"},\n","    {\"class\": \"squirrel\", \"superclass\": \"small mammals\"},\n","\n","    # Superclass: Trees\n","    {\"class\": \"maple tree\", \"superclass\": \"trees\"},\n","    {\"class\": \"oak tree\", \"superclass\": \"trees\"},\n","    {\"class\": \"palm tree\", \"superclass\": \"trees\"},\n","    {\"class\": \"pine tree\", \"superclass\": \"trees\"},\n","    {\"class\": \"willow tree\", \"superclass\": \"trees\"},\n","\n","    # Superclass: Vehicles 1\n","    {\"class\": \"bicycle\", \"superclass\": \"vehicles 1\"},\n","    {\"class\": \"bus\", \"superclass\": \"vehicles 1\"},\n","    {\"class\": \"motorcycle\", \"superclass\": \"vehicles 1\"},\n","    {\"class\": \"pickup truck\", \"superclass\": \"vehicles 1\"},\n","    {\"class\": \"train\", \"superclass\": \"vehicles 1\"},\n","\n","    # Superclass: Vehicles 2\n","    {\"class\": \"lawn mower\", \"superclass\": \"vehicles 2\"},\n","    {\"class\": \"rocket\", \"superclass\": \"vehicles 2\"},\n","    {\"class\": \"streetcar\", \"superclass\": \"vehicles 2\"},\n","    {\"class\": \"tank\", \"superclass\": \"vehicles 2\"},\n","    {\"class\": \"tractor\", \"superclass\": \"vehicles 2\"},\n","]\n","\n","# Write to JSON file\n","with open('cifar100_classes.json', 'w') as json_file:\n","    json.dump(cifar100_classes, json_file, indent=4)\n","\n","superclasses = [\n","    \"aquatic mammals\",          # 1-5\n","    \"fish\",                     # 6-10\n","    \"flowers\",                  # 11-15\n","    \"food containers\",          # 16-20\n","    \"fruits and vegetables\",    # 21-25\n","    \"household electrical devices\",  # 26-30\n","    \"household furniture\",      # 31-35\n","    \"insects\",                  # 36-40\n","    \"large carnivores\",         # 41-45\n","    \"large man-made outdoor things\", # 46-50\n","    \"large natural outdoor scenes\",  # 51-55\n","    \"large omnivores and herbivores\",# 56-60\n","    \"medium-sized mammals\",     # 61-65\n","    \"non-insect invertebrates\", # 66-70\n","    \"people\",                   # 71-75\n","    \"reptiles\",                 # 76-80\n","    \"small mammals\",            # 81-85\n","    \"trees\",                    # 86-90\n","    \"vehicles 1\",               # 91-95\n","    \"vehicles 2\"                # 96-100\n","]\n","\n","classes = [\n","    # Aquatic Mammals\n","    \"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\",\n","\n","    # Fish\n","    \"aquarium fish\", \"flatfish\", \"ray\", \"shark\", \"trout\",\n","\n","    # Flowers\n","    \"orchid\", \"poppy\", \"rose\", \"sunflower\", \"tulip\",\n","\n","    # Food Containers\n","    \"bottle\", \"bowl\", \"can\", \"cup\", \"plate\",\n","\n","    # Fruits and Vegetables\n","    \"apple\", \"mushroom\", \"orange\", \"pear\", \"sweet pepper\",\n","\n","    # Household Electrical Devices\n","    \"clock\", \"keyboard\", \"lamp\", \"telephone\", \"television\",\n","\n","    # Household Furniture\n","    \"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\",\n","\n","    # Insects\n","    \"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\",\n","\n","    # Large Carnivores\n","    \"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\",\n","\n","    # Large Man-made Outdoor Things\n","    \"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\",\n","\n","    # Large Natural Outdoor Scenes\n","    \"cloud\", \"forest\", \"mountain\", \"plain\", \"sea\",\n","\n","    # Large Omnivores and Herbivores\n","    \"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\",\n","\n","    # Medium-sized Mammals\n","    \"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\",\n","\n","    # Non-insect Invertebrates\n","    \"crab\", \"lobster\", \"snail\", \"spider\", \"worm\",\n","\n","    # People\n","    \"baby\", \"boy\", \"girl\", \"man\", \"woman\",\n","\n","    # Reptiles\n","    \"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\",\n","\n","    # Small Mammals\n","    \"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\",\n","\n","    # Trees\n","    \"maple tree\", \"oak tree\", \"palm tree\", \"pine tree\", \"willow tree\",\n","\n","    # Vehicles 1\n","    \"bicycle\", \"bus\", \"motorcycle\", \"pickup truck\", \"train\",\n","\n","    # Vehicles 2\n","    \"lawn mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\"\n","]"],"metadata":{"id":"_Nh7BCsk4TIU","executionInfo":{"status":"ok","timestamp":1724608930803,"user_tz":-180,"elapsed":17,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"cellView":"form"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/dataset/test/cifar-100-python/meta'\n","\n","# Unpickle the file\n","with open(file_path, 'rb') as file:\n","    data = pickle.load(file)\n","\n","alphabetical_to_original_label = {}\n","\n","for label_id, label in enumerate(data['fine_label_names']):\n","  label = label.replace('_', ' ')\n","  new_index = classes.index(label)\n","  superclass = cifar100_classes[new_index]['superclass']\n","  new_superclass_index = superclasses.index(superclass)\n","  # print(label, new_index, new_superclass_index)\n","  alphabetical_to_original_label[label_id] = {'index': new_index, 'class':classes[new_index], 'super_index':new_superclass_index, 'superclass': superclass}\n","\n","print(alphabetical_to_original_label)\n","\n","superclass_and_class_to_hierarchic_label = {}\n","\n","for key in alphabetical_to_original_label:\n","  info = alphabetical_to_original_label[key]\n","  superclass = info['superclass']\n","  if superclass not in superclass_and_class_to_hierarchic_label:\n","    hierarchic_label = 0\n","    superclass_and_class_to_hierarchic_label[superclass] = 0\n","  else:\n","    hierarchic_label = superclass_and_class_to_hierarchic_label[superclass] + 1\n","    superclass_and_class_to_hierarchic_label[superclass] = hierarchic_label\n","  info['hierarchic_index'] = hierarchic_label\n","  alphabetical_to_original_label[key] = info\n","\n","print(alphabetical_to_original_label)"],"metadata":{"id":"5gnDFCE4BZK5","executionInfo":{"status":"ok","timestamp":1724608930803,"user_tz":-180,"elapsed":16,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6752821e-6bb6-4cb6-ae03-ec393b120077"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: {'index': 20, 'class': 'apple', 'super_index': 4, 'superclass': 'fruits and vegetables'}, 1: {'index': 5, 'class': 'aquarium fish', 'super_index': 1, 'superclass': 'fish'}, 2: {'index': 70, 'class': 'baby', 'super_index': 14, 'superclass': 'people'}, 3: {'index': 40, 'class': 'bear', 'super_index': 8, 'superclass': 'large carnivores'}, 4: {'index': 0, 'class': 'beaver', 'super_index': 0, 'superclass': 'aquatic mammals'}, 5: {'index': 30, 'class': 'bed', 'super_index': 6, 'superclass': 'household furniture'}, 6: {'index': 35, 'class': 'bee', 'super_index': 7, 'superclass': 'insects'}, 7: {'index': 36, 'class': 'beetle', 'super_index': 7, 'superclass': 'insects'}, 8: {'index': 90, 'class': 'bicycle', 'super_index': 18, 'superclass': 'vehicles 1'}, 9: {'index': 15, 'class': 'bottle', 'super_index': 3, 'superclass': 'food containers'}, 10: {'index': 16, 'class': 'bowl', 'super_index': 3, 'superclass': 'food containers'}, 11: {'index': 71, 'class': 'boy', 'super_index': 14, 'superclass': 'people'}, 12: {'index': 45, 'class': 'bridge', 'super_index': 9, 'superclass': 'large man-made outdoor things'}, 13: {'index': 91, 'class': 'bus', 'super_index': 18, 'superclass': 'vehicles 1'}, 14: {'index': 37, 'class': 'butterfly', 'super_index': 7, 'superclass': 'insects'}, 15: {'index': 55, 'class': 'camel', 'super_index': 11, 'superclass': 'large omnivores and herbivores'}, 16: {'index': 17, 'class': 'can', 'super_index': 3, 'superclass': 'food containers'}, 17: {'index': 46, 'class': 'castle', 'super_index': 9, 'superclass': 'large man-made outdoor things'}, 18: {'index': 38, 'class': 'caterpillar', 'super_index': 7, 'superclass': 'insects'}, 19: {'index': 56, 'class': 'cattle', 'super_index': 11, 'superclass': 'large omnivores and herbivores'}, 20: {'index': 31, 'class': 'chair', 'super_index': 6, 'superclass': 'household furniture'}, 21: {'index': 57, 'class': 'chimpanzee', 'super_index': 11, 'superclass': 'large omnivores and herbivores'}, 22: {'index': 25, 'class': 'clock', 'super_index': 5, 'superclass': 'household electrical devices'}, 23: {'index': 50, 'class': 'cloud', 'super_index': 10, 'superclass': 'large natural outdoor scenes'}, 24: {'index': 39, 'class': 'cockroach', 'super_index': 7, 'superclass': 'insects'}, 25: {'index': 32, 'class': 'couch', 'super_index': 6, 'superclass': 'household furniture'}, 26: {'index': 65, 'class': 'crab', 'super_index': 13, 'superclass': 'non-insect invertebrates'}, 27: {'index': 75, 'class': 'crocodile', 'super_index': 15, 'superclass': 'reptiles'}, 28: {'index': 18, 'class': 'cup', 'super_index': 3, 'superclass': 'food containers'}, 29: {'index': 76, 'class': 'dinosaur', 'super_index': 15, 'superclass': 'reptiles'}, 30: {'index': 1, 'class': 'dolphin', 'super_index': 0, 'superclass': 'aquatic mammals'}, 31: {'index': 58, 'class': 'elephant', 'super_index': 11, 'superclass': 'large omnivores and herbivores'}, 32: {'index': 6, 'class': 'flatfish', 'super_index': 1, 'superclass': 'fish'}, 33: {'index': 51, 'class': 'forest', 'super_index': 10, 'superclass': 'large natural outdoor scenes'}, 34: {'index': 60, 'class': 'fox', 'super_index': 12, 'superclass': 'medium-sized mammals'}, 35: {'index': 72, 'class': 'girl', 'super_index': 14, 'superclass': 'people'}, 36: {'index': 80, 'class': 'hamster', 'super_index': 16, 'superclass': 'small mammals'}, 37: {'index': 47, 'class': 'house', 'super_index': 9, 'superclass': 'large man-made outdoor things'}, 38: {'index': 59, 'class': 'kangaroo', 'super_index': 11, 'superclass': 'large omnivores and herbivores'}, 39: {'index': 26, 'class': 'keyboard', 'super_index': 5, 'superclass': 'household electrical devices'}, 40: {'index': 27, 'class': 'lamp', 'super_index': 5, 'superclass': 'household electrical devices'}, 41: {'index': 95, 'class': 'lawn mower', 'super_index': 19, 'superclass': 'vehicles 2'}, 42: {'index': 41, 'class': 'leopard', 'super_index': 8, 'superclass': 'large carnivores'}, 43: {'index': 42, 'class': 'lion', 'super_index': 8, 'superclass': 'large carnivores'}, 44: {'index': 77, 'class': 'lizard', 'super_index': 15, 'superclass': 'reptiles'}, 45: {'index': 66, 'class': 'lobster', 'super_index': 13, 'superclass': 'non-insect invertebrates'}, 46: {'index': 73, 'class': 'man', 'super_index': 14, 'superclass': 'people'}, 47: {'index': 85, 'class': 'maple tree', 'super_index': 17, 'superclass': 'trees'}, 48: {'index': 92, 'class': 'motorcycle', 'super_index': 18, 'superclass': 'vehicles 1'}, 49: {'index': 52, 'class': 'mountain', 'super_index': 10, 'superclass': 'large natural outdoor scenes'}, 50: {'index': 81, 'class': 'mouse', 'super_index': 16, 'superclass': 'small mammals'}, 51: {'index': 21, 'class': 'mushroom', 'super_index': 4, 'superclass': 'fruits and vegetables'}, 52: {'index': 86, 'class': 'oak tree', 'super_index': 17, 'superclass': 'trees'}, 53: {'index': 22, 'class': 'orange', 'super_index': 4, 'superclass': 'fruits and vegetables'}, 54: {'index': 10, 'class': 'orchid', 'super_index': 2, 'superclass': 'flowers'}, 55: {'index': 2, 'class': 'otter', 'super_index': 0, 'superclass': 'aquatic mammals'}, 56: {'index': 87, 'class': 'palm tree', 'super_index': 17, 'superclass': 'trees'}, 57: {'index': 23, 'class': 'pear', 'super_index': 4, 'superclass': 'fruits and vegetables'}, 58: {'index': 93, 'class': 'pickup truck', 'super_index': 18, 'superclass': 'vehicles 1'}, 59: {'index': 88, 'class': 'pine tree', 'super_index': 17, 'superclass': 'trees'}, 60: {'index': 53, 'class': 'plain', 'super_index': 10, 'superclass': 'large natural outdoor scenes'}, 61: {'index': 19, 'class': 'plate', 'super_index': 3, 'superclass': 'food containers'}, 62: {'index': 11, 'class': 'poppy', 'super_index': 2, 'superclass': 'flowers'}, 63: {'index': 61, 'class': 'porcupine', 'super_index': 12, 'superclass': 'medium-sized mammals'}, 64: {'index': 62, 'class': 'possum', 'super_index': 12, 'superclass': 'medium-sized mammals'}, 65: {'index': 82, 'class': 'rabbit', 'super_index': 16, 'superclass': 'small mammals'}, 66: {'index': 63, 'class': 'raccoon', 'super_index': 12, 'superclass': 'medium-sized mammals'}, 67: {'index': 7, 'class': 'ray', 'super_index': 1, 'superclass': 'fish'}, 68: {'index': 48, 'class': 'road', 'super_index': 9, 'superclass': 'large man-made outdoor things'}, 69: {'index': 96, 'class': 'rocket', 'super_index': 19, 'superclass': 'vehicles 2'}, 70: {'index': 12, 'class': 'rose', 'super_index': 2, 'superclass': 'flowers'}, 71: {'index': 54, 'class': 'sea', 'super_index': 10, 'superclass': 'large natural outdoor scenes'}, 72: {'index': 3, 'class': 'seal', 'super_index': 0, 'superclass': 'aquatic mammals'}, 73: {'index': 8, 'class': 'shark', 'super_index': 1, 'superclass': 'fish'}, 74: {'index': 83, 'class': 'shrew', 'super_index': 16, 'superclass': 'small mammals'}, 75: {'index': 64, 'class': 'skunk', 'super_index': 12, 'superclass': 'medium-sized mammals'}, 76: {'index': 49, 'class': 'skyscraper', 'super_index': 9, 'superclass': 'large man-made outdoor things'}, 77: {'index': 67, 'class': 'snail', 'super_index': 13, 'superclass': 'non-insect invertebrates'}, 78: {'index': 78, 'class': 'snake', 'super_index': 15, 'superclass': 'reptiles'}, 79: {'index': 68, 'class': 'spider', 'super_index': 13, 'superclass': 'non-insect invertebrates'}, 80: {'index': 84, 'class': 'squirrel', 'super_index': 16, 'superclass': 'small mammals'}, 81: {'index': 97, 'class': 'streetcar', 'super_index': 19, 'superclass': 'vehicles 2'}, 82: {'index': 13, 'class': 'sunflower', 'super_index': 2, 'superclass': 'flowers'}, 83: {'index': 24, 'class': 'sweet pepper', 'super_index': 4, 'superclass': 'fruits and vegetables'}, 84: {'index': 33, 'class': 'table', 'super_index': 6, 'superclass': 'household furniture'}, 85: {'index': 98, 'class': 'tank', 'super_index': 19, 'superclass': 'vehicles 2'}, 86: {'index': 28, 'class': 'telephone', 'super_index': 5, 'superclass': 'household electrical devices'}, 87: {'index': 29, 'class': 'television', 'super_index': 5, 'superclass': 'household electrical devices'}, 88: {'index': 43, 'class': 'tiger', 'super_index': 8, 'superclass': 'large carnivores'}, 89: {'index': 99, 'class': 'tractor', 'super_index': 19, 'superclass': 'vehicles 2'}, 90: {'index': 94, 'class': 'train', 'super_index': 18, 'superclass': 'vehicles 1'}, 91: {'index': 9, 'class': 'trout', 'super_index': 1, 'superclass': 'fish'}, 92: {'index': 14, 'class': 'tulip', 'super_index': 2, 'superclass': 'flowers'}, 93: {'index': 79, 'class': 'turtle', 'super_index': 15, 'superclass': 'reptiles'}, 94: {'index': 34, 'class': 'wardrobe', 'super_index': 6, 'superclass': 'household furniture'}, 95: {'index': 4, 'class': 'whale', 'super_index': 0, 'superclass': 'aquatic mammals'}, 96: {'index': 89, 'class': 'willow tree', 'super_index': 17, 'superclass': 'trees'}, 97: {'index': 44, 'class': 'wolf', 'super_index': 8, 'superclass': 'large carnivores'}, 98: {'index': 74, 'class': 'woman', 'super_index': 14, 'superclass': 'people'}, 99: {'index': 69, 'class': 'worm', 'super_index': 13, 'superclass': 'non-insect invertebrates'}}\n","{0: {'index': 20, 'class': 'apple', 'super_index': 4, 'superclass': 'fruits and vegetables', 'hierarchic_index': 0}, 1: {'index': 5, 'class': 'aquarium fish', 'super_index': 1, 'superclass': 'fish', 'hierarchic_index': 0}, 2: {'index': 70, 'class': 'baby', 'super_index': 14, 'superclass': 'people', 'hierarchic_index': 0}, 3: {'index': 40, 'class': 'bear', 'super_index': 8, 'superclass': 'large carnivores', 'hierarchic_index': 0}, 4: {'index': 0, 'class': 'beaver', 'super_index': 0, 'superclass': 'aquatic mammals', 'hierarchic_index': 0}, 5: {'index': 30, 'class': 'bed', 'super_index': 6, 'superclass': 'household furniture', 'hierarchic_index': 0}, 6: {'index': 35, 'class': 'bee', 'super_index': 7, 'superclass': 'insects', 'hierarchic_index': 0}, 7: {'index': 36, 'class': 'beetle', 'super_index': 7, 'superclass': 'insects', 'hierarchic_index': 1}, 8: {'index': 90, 'class': 'bicycle', 'super_index': 18, 'superclass': 'vehicles 1', 'hierarchic_index': 0}, 9: {'index': 15, 'class': 'bottle', 'super_index': 3, 'superclass': 'food containers', 'hierarchic_index': 0}, 10: {'index': 16, 'class': 'bowl', 'super_index': 3, 'superclass': 'food containers', 'hierarchic_index': 1}, 11: {'index': 71, 'class': 'boy', 'super_index': 14, 'superclass': 'people', 'hierarchic_index': 1}, 12: {'index': 45, 'class': 'bridge', 'super_index': 9, 'superclass': 'large man-made outdoor things', 'hierarchic_index': 0}, 13: {'index': 91, 'class': 'bus', 'super_index': 18, 'superclass': 'vehicles 1', 'hierarchic_index': 1}, 14: {'index': 37, 'class': 'butterfly', 'super_index': 7, 'superclass': 'insects', 'hierarchic_index': 2}, 15: {'index': 55, 'class': 'camel', 'super_index': 11, 'superclass': 'large omnivores and herbivores', 'hierarchic_index': 0}, 16: {'index': 17, 'class': 'can', 'super_index': 3, 'superclass': 'food containers', 'hierarchic_index': 2}, 17: {'index': 46, 'class': 'castle', 'super_index': 9, 'superclass': 'large man-made outdoor things', 'hierarchic_index': 1}, 18: {'index': 38, 'class': 'caterpillar', 'super_index': 7, 'superclass': 'insects', 'hierarchic_index': 3}, 19: {'index': 56, 'class': 'cattle', 'super_index': 11, 'superclass': 'large omnivores and herbivores', 'hierarchic_index': 1}, 20: {'index': 31, 'class': 'chair', 'super_index': 6, 'superclass': 'household furniture', 'hierarchic_index': 1}, 21: {'index': 57, 'class': 'chimpanzee', 'super_index': 11, 'superclass': 'large omnivores and herbivores', 'hierarchic_index': 2}, 22: {'index': 25, 'class': 'clock', 'super_index': 5, 'superclass': 'household electrical devices', 'hierarchic_index': 0}, 23: {'index': 50, 'class': 'cloud', 'super_index': 10, 'superclass': 'large natural outdoor scenes', 'hierarchic_index': 0}, 24: {'index': 39, 'class': 'cockroach', 'super_index': 7, 'superclass': 'insects', 'hierarchic_index': 4}, 25: {'index': 32, 'class': 'couch', 'super_index': 6, 'superclass': 'household furniture', 'hierarchic_index': 2}, 26: {'index': 65, 'class': 'crab', 'super_index': 13, 'superclass': 'non-insect invertebrates', 'hierarchic_index': 0}, 27: {'index': 75, 'class': 'crocodile', 'super_index': 15, 'superclass': 'reptiles', 'hierarchic_index': 0}, 28: {'index': 18, 'class': 'cup', 'super_index': 3, 'superclass': 'food containers', 'hierarchic_index': 3}, 29: {'index': 76, 'class': 'dinosaur', 'super_index': 15, 'superclass': 'reptiles', 'hierarchic_index': 1}, 30: {'index': 1, 'class': 'dolphin', 'super_index': 0, 'superclass': 'aquatic mammals', 'hierarchic_index': 1}, 31: {'index': 58, 'class': 'elephant', 'super_index': 11, 'superclass': 'large omnivores and herbivores', 'hierarchic_index': 3}, 32: {'index': 6, 'class': 'flatfish', 'super_index': 1, 'superclass': 'fish', 'hierarchic_index': 1}, 33: {'index': 51, 'class': 'forest', 'super_index': 10, 'superclass': 'large natural outdoor scenes', 'hierarchic_index': 1}, 34: {'index': 60, 'class': 'fox', 'super_index': 12, 'superclass': 'medium-sized mammals', 'hierarchic_index': 0}, 35: {'index': 72, 'class': 'girl', 'super_index': 14, 'superclass': 'people', 'hierarchic_index': 2}, 36: {'index': 80, 'class': 'hamster', 'super_index': 16, 'superclass': 'small mammals', 'hierarchic_index': 0}, 37: {'index': 47, 'class': 'house', 'super_index': 9, 'superclass': 'large man-made outdoor things', 'hierarchic_index': 2}, 38: {'index': 59, 'class': 'kangaroo', 'super_index': 11, 'superclass': 'large omnivores and herbivores', 'hierarchic_index': 4}, 39: {'index': 26, 'class': 'keyboard', 'super_index': 5, 'superclass': 'household electrical devices', 'hierarchic_index': 1}, 40: {'index': 27, 'class': 'lamp', 'super_index': 5, 'superclass': 'household electrical devices', 'hierarchic_index': 2}, 41: {'index': 95, 'class': 'lawn mower', 'super_index': 19, 'superclass': 'vehicles 2', 'hierarchic_index': 0}, 42: {'index': 41, 'class': 'leopard', 'super_index': 8, 'superclass': 'large carnivores', 'hierarchic_index': 1}, 43: {'index': 42, 'class': 'lion', 'super_index': 8, 'superclass': 'large carnivores', 'hierarchic_index': 2}, 44: {'index': 77, 'class': 'lizard', 'super_index': 15, 'superclass': 'reptiles', 'hierarchic_index': 2}, 45: {'index': 66, 'class': 'lobster', 'super_index': 13, 'superclass': 'non-insect invertebrates', 'hierarchic_index': 1}, 46: {'index': 73, 'class': 'man', 'super_index': 14, 'superclass': 'people', 'hierarchic_index': 3}, 47: {'index': 85, 'class': 'maple tree', 'super_index': 17, 'superclass': 'trees', 'hierarchic_index': 0}, 48: {'index': 92, 'class': 'motorcycle', 'super_index': 18, 'superclass': 'vehicles 1', 'hierarchic_index': 2}, 49: {'index': 52, 'class': 'mountain', 'super_index': 10, 'superclass': 'large natural outdoor scenes', 'hierarchic_index': 2}, 50: {'index': 81, 'class': 'mouse', 'super_index': 16, 'superclass': 'small mammals', 'hierarchic_index': 1}, 51: {'index': 21, 'class': 'mushroom', 'super_index': 4, 'superclass': 'fruits and vegetables', 'hierarchic_index': 1}, 52: {'index': 86, 'class': 'oak tree', 'super_index': 17, 'superclass': 'trees', 'hierarchic_index': 1}, 53: {'index': 22, 'class': 'orange', 'super_index': 4, 'superclass': 'fruits and vegetables', 'hierarchic_index': 2}, 54: {'index': 10, 'class': 'orchid', 'super_index': 2, 'superclass': 'flowers', 'hierarchic_index': 0}, 55: {'index': 2, 'class': 'otter', 'super_index': 0, 'superclass': 'aquatic mammals', 'hierarchic_index': 2}, 56: {'index': 87, 'class': 'palm tree', 'super_index': 17, 'superclass': 'trees', 'hierarchic_index': 2}, 57: {'index': 23, 'class': 'pear', 'super_index': 4, 'superclass': 'fruits and vegetables', 'hierarchic_index': 3}, 58: {'index': 93, 'class': 'pickup truck', 'super_index': 18, 'superclass': 'vehicles 1', 'hierarchic_index': 3}, 59: {'index': 88, 'class': 'pine tree', 'super_index': 17, 'superclass': 'trees', 'hierarchic_index': 3}, 60: {'index': 53, 'class': 'plain', 'super_index': 10, 'superclass': 'large natural outdoor scenes', 'hierarchic_index': 3}, 61: {'index': 19, 'class': 'plate', 'super_index': 3, 'superclass': 'food containers', 'hierarchic_index': 4}, 62: {'index': 11, 'class': 'poppy', 'super_index': 2, 'superclass': 'flowers', 'hierarchic_index': 1}, 63: {'index': 61, 'class': 'porcupine', 'super_index': 12, 'superclass': 'medium-sized mammals', 'hierarchic_index': 1}, 64: {'index': 62, 'class': 'possum', 'super_index': 12, 'superclass': 'medium-sized mammals', 'hierarchic_index': 2}, 65: {'index': 82, 'class': 'rabbit', 'super_index': 16, 'superclass': 'small mammals', 'hierarchic_index': 2}, 66: {'index': 63, 'class': 'raccoon', 'super_index': 12, 'superclass': 'medium-sized mammals', 'hierarchic_index': 3}, 67: {'index': 7, 'class': 'ray', 'super_index': 1, 'superclass': 'fish', 'hierarchic_index': 2}, 68: {'index': 48, 'class': 'road', 'super_index': 9, 'superclass': 'large man-made outdoor things', 'hierarchic_index': 3}, 69: {'index': 96, 'class': 'rocket', 'super_index': 19, 'superclass': 'vehicles 2', 'hierarchic_index': 1}, 70: {'index': 12, 'class': 'rose', 'super_index': 2, 'superclass': 'flowers', 'hierarchic_index': 2}, 71: {'index': 54, 'class': 'sea', 'super_index': 10, 'superclass': 'large natural outdoor scenes', 'hierarchic_index': 4}, 72: {'index': 3, 'class': 'seal', 'super_index': 0, 'superclass': 'aquatic mammals', 'hierarchic_index': 3}, 73: {'index': 8, 'class': 'shark', 'super_index': 1, 'superclass': 'fish', 'hierarchic_index': 3}, 74: {'index': 83, 'class': 'shrew', 'super_index': 16, 'superclass': 'small mammals', 'hierarchic_index': 3}, 75: {'index': 64, 'class': 'skunk', 'super_index': 12, 'superclass': 'medium-sized mammals', 'hierarchic_index': 4}, 76: {'index': 49, 'class': 'skyscraper', 'super_index': 9, 'superclass': 'large man-made outdoor things', 'hierarchic_index': 4}, 77: {'index': 67, 'class': 'snail', 'super_index': 13, 'superclass': 'non-insect invertebrates', 'hierarchic_index': 2}, 78: {'index': 78, 'class': 'snake', 'super_index': 15, 'superclass': 'reptiles', 'hierarchic_index': 3}, 79: {'index': 68, 'class': 'spider', 'super_index': 13, 'superclass': 'non-insect invertebrates', 'hierarchic_index': 3}, 80: {'index': 84, 'class': 'squirrel', 'super_index': 16, 'superclass': 'small mammals', 'hierarchic_index': 4}, 81: {'index': 97, 'class': 'streetcar', 'super_index': 19, 'superclass': 'vehicles 2', 'hierarchic_index': 2}, 82: {'index': 13, 'class': 'sunflower', 'super_index': 2, 'superclass': 'flowers', 'hierarchic_index': 3}, 83: {'index': 24, 'class': 'sweet pepper', 'super_index': 4, 'superclass': 'fruits and vegetables', 'hierarchic_index': 4}, 84: {'index': 33, 'class': 'table', 'super_index': 6, 'superclass': 'household furniture', 'hierarchic_index': 3}, 85: {'index': 98, 'class': 'tank', 'super_index': 19, 'superclass': 'vehicles 2', 'hierarchic_index': 3}, 86: {'index': 28, 'class': 'telephone', 'super_index': 5, 'superclass': 'household electrical devices', 'hierarchic_index': 3}, 87: {'index': 29, 'class': 'television', 'super_index': 5, 'superclass': 'household electrical devices', 'hierarchic_index': 4}, 88: {'index': 43, 'class': 'tiger', 'super_index': 8, 'superclass': 'large carnivores', 'hierarchic_index': 3}, 89: {'index': 99, 'class': 'tractor', 'super_index': 19, 'superclass': 'vehicles 2', 'hierarchic_index': 4}, 90: {'index': 94, 'class': 'train', 'super_index': 18, 'superclass': 'vehicles 1', 'hierarchic_index': 4}, 91: {'index': 9, 'class': 'trout', 'super_index': 1, 'superclass': 'fish', 'hierarchic_index': 4}, 92: {'index': 14, 'class': 'tulip', 'super_index': 2, 'superclass': 'flowers', 'hierarchic_index': 4}, 93: {'index': 79, 'class': 'turtle', 'super_index': 15, 'superclass': 'reptiles', 'hierarchic_index': 4}, 94: {'index': 34, 'class': 'wardrobe', 'super_index': 6, 'superclass': 'household furniture', 'hierarchic_index': 4}, 95: {'index': 4, 'class': 'whale', 'super_index': 0, 'superclass': 'aquatic mammals', 'hierarchic_index': 4}, 96: {'index': 89, 'class': 'willow tree', 'super_index': 17, 'superclass': 'trees', 'hierarchic_index': 4}, 97: {'index': 44, 'class': 'wolf', 'super_index': 8, 'superclass': 'large carnivores', 'hierarchic_index': 4}, 98: {'index': 74, 'class': 'woman', 'super_index': 14, 'superclass': 'people', 'hierarchic_index': 4}, 99: {'index': 69, 'class': 'worm', 'super_index': 13, 'superclass': 'non-insect invertebrates', 'hierarchic_index': 4}}\n"]}]},{"cell_type":"code","source":["for td_id, td in enumerate(train_dataset):\n","  pil_img = td[0]\n","  numpy_img = np.clip(pil_img.permute(1, 2, 0).numpy()[:, :, ::-1] * 255, 0, 255)\n","  class_label = td[1]\n","  print(numpy_img.shape)\n","  # cv2_imshow(numpy_img)\n","  # print(alphabetical_to_original_label[class_label]['class'], alphabetical_to_original_label[class_label]['superclass'])\n","  if td_id % 10 == 9:\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvHLhzMhr7F5","executionInfo":{"status":"ok","timestamp":1724608930803,"user_tz":-180,"elapsed":10,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"ede93c8f-48f2-4822-d554-e54eb5613dca"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n","(28, 28, 3)\n"]}]},{"cell_type":"code","source":["train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","\n","# Split the dataset into training and validation\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# Create data loaders for each\n","train_loader_classic  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader_clasic = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader_clasic = DataLoader(test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"LjvB2M8-l-ls","executionInfo":{"status":"ok","timestamp":1724608930803,"user_tz":-180,"elapsed":8,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"meCJ4YYGmYQt"}},{"cell_type":"code","source":["#@title Flat MobileNetv3\n","\n","MODEL = torchvision.models.mobilenet_v3_small\n","\n","import torch.nn as nn\n","\n","class ClassicMobileNetV3(nn.Module):\n","    def __init__(self, num_classes=100, pretrained=True, dropout_p=0.5):\n","        super(ClassicMobileNetV3, self).__init__()\n","\n","        # Load the pre-trained MobileNetV3 model from torchvision\n","        self.mobilenet = MODEL(pretrained=pretrained)\n","\n","        # Modify the first convolutional layer to accept (28, 28) input size\n","        self.mobilenet.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n","\n","        # Extract the number of features from the original classifier\n","        in_features = self.mobilenet.classifier[-1].in_features\n","\n","        # Replace the classifier with a new sequence including Dropout\n","        self.mobilenet.classifier[-1] = nn.Sequential(\n","            # nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","            nn.Linear(in_features, num_classes)  # Final fully connected layer\n","        )\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)"],"metadata":{"id":"U9NX50yRmajX","executionInfo":{"status":"ok","timestamp":1724608930804,"user_tz":-180,"elapsed":8,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"cellView":"form"},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#@title Local Classifier at each hierarchic granularity\n","\n","class HierarchicMobileNetV3(nn.Module):\n","    def __init__(self, num_superclasses=20, num_subclasses = [5 for _ in range(20)], pretrained=True, device=\"cuda\"):\n","\n","      super(HierarchicMobileNetV3, self).__init__()\n","\n","      self.num_superclasses = num_superclasses\n","      self.num_subclasses = num_subclasses\n","\n","      self.superclass_clasifier = ClassicMobileNetV3(num_superclasses, pretrained)\n","\n","      # self.class_classifiers = [ClassicMobileNetV3(num_subclasses[i], pretrained) for i in range(num_superclasses)]\n","      self.class_classifiers = nn.ModuleList(\n","            [ClassicMobileNetV3(num_subclasses[i], pretrained).to(device) for i in range(num_superclasses)]\n","        )\n","\n","\n","    def forward(self, x):\n","        # Predict the superclass\n","        # x = x.to(next(self.parameters()).device)\n","        superclass_prediction = self.superclass_clasifier(x)\n","\n","        # Determine the predicted superclass for each item in the batch\n","        chosen_superclass = torch.argmax(superclass_prediction, dim=1)\n","\n","        # Prepare an empty tensor to store the subclass predictions\n","        batch_size = x.size(0)\n","        class_predictions = torch.zeros(batch_size, max(self.num_subclasses), device=x.device)\n","\n","        for i in range(batch_size):\n","            # For each item in the batch, select the corresponding subclass classifier\n","            class_predictions[i] = self.class_classifiers[chosen_superclass[i]](x[i].unsqueeze(0))\n","\n","        return class_predictions, superclass_prediction\n"],"metadata":{"id":"4i4tVU2N67sE","cellView":"form","executionInfo":{"status":"ok","timestamp":1724608930804,"user_tz":-180,"elapsed":8,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#@title Global Classifier\n","\n","class GlobalMobileNetV3(nn.Module):\n","  def __init__(self, num_superclasses=20, num_subclasses = 100, pretrained=True):\n","\n","      self.num_superclasses = num_superclasses\n","      self.num_subclasses = num_subclasses\n","\n","      self.mobilenet = ClassicMobileNetV3(num_superclasses + num_subclasses)\n","\n","  def forward(self, x):\n","      return self.mobilenet(x)"],"metadata":{"id":"bpTGULUJwlKw","cellView":"form","executionInfo":{"status":"ok","timestamp":1724608930804,"user_tz":-180,"elapsed":8,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#@title Parallel MT Hierarchical\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, x):\n","        return x\n","\n","\n","class ParallelMultiTaskMobileNetV3(nn.Module):\n","    def __init__(self, num_superclasses=20, num_subclasses=100, pretrained=True, dropout_p=0.5):\n","        super(ParallelMultiTaskMobileNetV3, self).__init__()\n","\n","        # Load the pre-trained MobileNetV3 model from torchvision\n","        self.mobilenet = MODEL(pretrained=pretrained)\n","\n","        # Modify the first convolutional layer to accept (28, 28) input size\n","        self.mobilenet.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n","\n","        # Extract the number of features from the original classifier\n","        in_features = self.mobilenet.classifier[-1].in_features\n","\n","        # Replace the original classifier with an identity layer\n","        self.mobilenet.classifier[-1] = Identity()\n","\n","        # Define Dropout layer\n","        self.dropout = nn.Dropout(p=dropout_p)\n","\n","        # Define the parallel classifiers for superclass and subclass predictions\n","        self.superclass_classifier = nn.Linear(in_features, num_superclasses)\n","        self.subclass_classifier = nn.Linear(in_features, num_subclasses)\n","\n","    def forward(self, x):\n","        # Pass input through the feature extractor\n","        features = self.mobilenet(x)\n","        features = torch.flatten(features, 1)  # Flatten the output for the classifier\n","\n","        # Apply Dropout to the features\n","        # features = self.dropout(features)\n","\n","        # Compute superclass and subclass predictions\n","        superclass_output = self.superclass_classifier(features)\n","        subclass_output = self.subclass_classifier(features)\n","\n","        return subclass_output, superclass_output"],"metadata":{"cellView":"form","id":"AOqY7iZ3k1h7","executionInfo":{"status":"ok","timestamp":1724608930804,"user_tz":-180,"elapsed":7,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#@title Cascaded MT Hierarchical\n","\n","class CascadedMultiTaskMobileNetV3(nn.Module):\n","    def __init__(self, num_superclasses=20, num_subclasses=100, pretrained=True, dropout_p=0.5):\n","        super(CascadedMultiTaskMobileNetV3, self).__init__()\n","\n","        # Load the pre-trained MobileNetV3 model from torchvision\n","        self.mobilenet = MODEL(pretrained=pretrained)\n","\n","        # Modify the first convolutional layer to accept (28, 28) input size\n","        self.mobilenet.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n","\n","        # Adjust the classifier input size if needed (e.g., due to smaller input size)\n","        in_features = self.mobilenet.classifier[-1].in_features\n","\n","        # Replace the original classifier with an identity layer\n","        self.mobilenet.classifier[-1] = Identity()\n","\n","        # Define Dropout layer\n","        self.dropout = nn.Dropout(p=dropout_p)\n","\n","        # Superclass classifier\n","        self.superclass_classifier = nn.Linear(in_features, num_superclasses)\n","\n","        # Subclass classifier with additional input for superclass prediction\n","        self.subclass_classifier = nn.Linear(in_features + num_superclasses, num_subclasses)\n","\n","    def forward(self, x):\n","        # Pass input through the feature extractor (all layers except the classifier)\n","        features = self.mobilenet(x)\n","        features = torch.flatten(features, 1)\n","\n","        # Apply Dropout to the features\n","        # features = self.dropout(features)\n","\n","        # Compute superclass prediction\n","        superclass_output = self.superclass_classifier(features)\n","\n","        # Concatenate the superclass prediction with the features\n","        combined_input = torch.cat((features, superclass_output), dim=1)\n","\n","        # Apply Dropout to the combined input before subclass classification\n","        # combined_input = self.dropout(combined_input)\n","\n","        # Compute subclass prediction using combined input\n","        subclass_output = self.subclass_classifier(combined_input)\n","\n","        return subclass_output, superclass_output"],"metadata":{"id":"SkfLF6oDlNS9","executionInfo":{"status":"ok","timestamp":1724608930804,"user_tz":-180,"elapsed":7,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"cellView":"form"},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Implement Deep Supervised MT"],"metadata":{"id":"9v2OjPrSL490","executionInfo":{"status":"ok","timestamp":1724608930804,"user_tz":-180,"elapsed":7,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Extra Dataloaders"],"metadata":{"id":"iUiXZv9ZpGl5"}},{"cell_type":"code","source":["def get_hierarchic_labels(target):\n","    superclass_label = alphabetical_to_original_label[target]['super_index']\n","    return superclass_label, target\n","\n","# Modify the dataset to return hierarchical labels\n","train_dataset_hierarchic = torchvision.datasets.CIFAR100(root='/content/dataset/train/', train=True, download=False, transform=transform, target_transform=get_hierarchic_labels)\n","train_dataset_hierarchic, val_dataset_hierarchic = random_split(train_dataset_hierarchic, [train_size, val_size])\n","test_dataset_hierarchic = torchvision.datasets.CIFAR100(root='/content/dataset/test/', train=False, download=False, transform=transform, target_transform=get_hierarchic_labels)\n","\n","# DataLoader for HierarchicMobileNetV3\n","train_loader_hierarchic = DataLoader(train_dataset_hierarchic, batch_size=32, shuffle=True, num_workers=4)\n","val_loader_hierarchic = DataLoader(val_dataset_hierarchic, batch_size=32, shuffle=False, num_workers=4)\n","test_loader_hierarchic = DataLoader(test_dataset_hierarchic, batch_size=32, shuffle=False, num_workers=4)"],"metadata":{"id":"hkm0Xz4jpKF2","executionInfo":{"status":"ok","timestamp":1724608932146,"user_tz":-180,"elapsed":1348,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def get_global_labels(target):\n","    superclass_label = alphabetical_to_original_label[target]['super_index']\n","    global_label = superclass_label * 100 + v\n","    return global_label\n","\n","# Load and split the dataset for GlobalMobileNetV3\n","full_global_dataset = torchvision.datasets. CIFAR100(root='/content/dataset/train/', train=True, download=False, transform=transform, target_transform=get_global_labels)\n","train_dataset_global, val_dataset_global = random_split(full_global_dataset, [train_size, val_size])\n","\n","test_dataset_global = torchvision.datasets.CIFAR100(root='/content/dataset/test/', train=False, download=False, transform=transform, target_transform=get_global_labels)\n","\n","# DataLoader for GlobalMobileNetV3\n","train_loader_global = DataLoader(train_dataset_global, batch_size=32, shuffle=True, num_workers=4)\n","val_loader_global = DataLoader(val_dataset_global, batch_size=32, shuffle=False, num_workers=4)\n","test_loader_global = DataLoader(test_dataset_global, batch_size=32, shuffle=False, num_workers=4)"],"metadata":{"id":"qOzpi4Zlpi6o","executionInfo":{"status":"ok","timestamp":1724608933026,"user_tz":-180,"elapsed":886,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# DataLoader for ParallelMultiTaskMobileNetV3 (superclass and subclass)\n","train_loader_parallel = DataLoader(train_dataset_hierarchic, batch_size=32, shuffle=True, num_workers=4)\n","val_loader_parallel = DataLoader(val_dataset_hierarchic, batch_size=32, shuffle=False, num_workers=4)\n","test_loader_parallel = DataLoader(test_dataset_hierarchic, batch_size=32, shuffle=False, num_workers=4)"],"metadata":{"id":"q5w7KUsepvVl","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":11,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# DataLoader for CascadedMultiTaskMobileNetV3 (superclass and subclass)\n","train_loader_cascaded = DataLoader(train_dataset_hierarchic, batch_size=32, shuffle=True, num_workers=4)\n","val_loader_cascaded = DataLoader(val_dataset_hierarchic, batch_size=32, shuffle=False, num_workers=4)\n","test_loader_cascaded = DataLoader(test_dataset_hierarchic, batch_size=32, shuffle=False, num_workers=4)"],"metadata":{"id":"L34ORMskpvw8","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":10,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# Training Procedures"],"metadata":{"id":"JKchuzsxlIZ8"}},{"cell_type":"code","source":["import torch\n","import copy\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","def train_classic_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', max_lr=0.001, phases=['train', 'val']):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss':[], 'test_acc':[]}\n","\n","    # Calculate total steps for 1CycleLR (total number of batches in training phase)\n","    total_steps = len(dataloaders['train']) * num_epochs\n","\n","    # Initialize the 1CycleLR scheduler\n","    scheduler = OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()  # Update the learning rate according to the 1Cycle policy\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data).item()\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # Save the model if validation loss has decreased\n","            if phase == 'val' and epoch_loss < best_val_loss:\n","                best_val_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                model_save_path = BASE_DIR + f'classic_model_epoch_{epoch+1}.pt'\n","                torch.save(model.state_dict(), model_save_path)\n","                print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history"],"metadata":{"id":"XocNIHBLlHos","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":10,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def train_hierarchic_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss':[], 'test_acc':[]}\n","\n","\n","    device2 = next(model.class_classifiers[0].mobilenet.parameters()).device\n","    print(f\"The first classifier's MobileNetV3 model is on: {device2}\")\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","                    hierarchic_labels = torch.zeros(subclass_labels.shape[0], device=device)\n","                    for idx, subclass_label in enumerate(subclass_labels):\n","                      hierarchic_label = alphabetical_to_original_label[subclass_label.item()]['hierarchic_index']\n","                      hierarchic_labels[idx] = hierarchic_label\n","                    hierarchic_labels = hierarchic_labels.long()\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels)\n","                    subclass_loss = criterion(subclass_outputs, hierarchic_labels)\n","                    loss = superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum((subclass_preds == hierarchic_labels.data) * (superclass_preds == superclass_labels.data)).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase])\n","            epoch_acc = running_corrects / len(dataloaders[phase])\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase])\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model, history"],"metadata":{"id":"9f0XKibnoHEi","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":9,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def train_hierarchic_mobilenet_fast(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss':[], 'test_acc':[]}\n","\n","    # Precompute hierarchic label mapping on CPU for faster indexing\n","    original_to_hierarchic = torch.tensor(\n","        [alphabetical_to_original_label[i]['hierarchic_index'] for i in range(len(alphabetical_to_original_label))],\n","        dtype=torch.long, device=device\n","    )\n","\n","    for epoch in range(num_epochs):\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","\n","                    # Vectorized label conversion\n","                    hierarchic_labels = original_to_hierarchic[subclass_labels]\n","\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels)\n","                    subclass_loss = criterion(subclass_outputs, hierarchic_labels)\n","                    loss = superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum((subclass_preds == hierarchic_labels) & (superclass_preds == superclass_labels)).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            # Correct the calculation of loss and accuracy\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model, history"],"metadata":{"id":"-M6_Bf9s1jg_","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":9,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["'''\n","def train_global_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data).item()\n","\n","            epoch_loss = running_loss / len(dataloaders[phase])\n","            epoch_acc = running_corrects / len(dataloaders[phase])\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model, history\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"gZ6NF_lJoMvw","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":8,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"daf9ef5d-0bb5-4583-e0f7-bc244278d1fd"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndef train_global_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\\n    model = model.to(device)\\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\\n\\n    for epoch in range(num_epochs):\\n        print(f'Epoch {epoch+1}/{num_epochs}')\\n        print('-' * 10)\\n\\n        for phase in ['train', 'val']:\\n            if phase == 'train':\\n                model.train()\\n            else:\\n                model.eval()\\n\\n            running_loss = 0.0\\n            running_corrects = 0\\n\\n            for inputs, labels in dataloaders[phase]:\\n                inputs, labels = inputs.to(device), labels.to(device)\\n\\n                optimizer.zero_grad()\\n\\n                with torch.set_grad_enabled(phase == 'train'):\\n                    outputs = model(inputs)\\n                    loss = criterion(outputs, labels)\\n                    _, preds = torch.max(outputs, 1)\\n\\n                    if phase == 'train':\\n                        loss.backward()\\n                        optimizer.step()\\n\\n                running_loss += loss.item() * inputs.size(0)\\n                running_corrects += torch.sum(preds == labels.data).item()\\n\\n            epoch_loss = running_loss / len(dataloaders[phase])\\n            epoch_acc = running_corrects / len(dataloaders[phase])\\n\\n            history[f'{phase}_loss'].append(epoch_loss)\\n            history[f'{phase}_acc'].append(epoch_acc)\\n\\n            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\\n\\n    return model, history\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import torch\n","import copy\n","\n","def train_parallel_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', max_lr=0.001, phases=['train', 'val']):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'train_acc_superclass': [], 'val_acc_superclass': [], 'test_loss':[], 'test_acc':[], 'test_acc_superclass':[]}\n","\n","    # Calculate total steps for 1CycleLR (total number of batches in training phase)\n","    total_steps = len(dataloaders['train']) * num_epochs\n","\n","    # Initialize the 1CycleLR scheduler\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels)\n","                    subclass_loss = criterion(subclass_outputs, subclass_labels)\n","                    loss = superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum(subclass_preds == subclass_labels.data).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        superclass_loss.backward(retain_graph=True)\n","                        subclass_loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()  # Update the learning rate according to the 1Cycle policy\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Superclass Acc: {epoch_acc_superclass:.4f}')\n","\n","            # Save the model if validation loss has decreased\n","            if phase == 'val' and epoch_loss < best_val_loss:\n","                best_val_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                model_save_path = BASE_DIR + f'parallel_model_epoch_{epoch+1}.pt'\n","                torch.save(model.state_dict(), model_save_path)\n","                print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history"],"metadata":{"id":"ApGq75xVoOeB","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import torch\n","import copy\n","\n","def train_cascaded_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', max_lr=0.001, phases=['train', 'val']):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'train_acc_superclass': [], 'val_acc_superclass': [], 'test_loss':[], 'test_acc':[], 'test_acc_superclass':[]}\n","\n","    # Calculate total steps for 1CycleLR (total number of batches in training phase)\n","    total_steps = len(dataloaders['train']) * num_epochs\n","\n","    # Initialize the 1CycleLR scheduler\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels)\n","                    subclass_loss = criterion(subclass_outputs, subclass_labels)\n","                    loss = superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum(subclass_preds == subclass_labels.data).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        superclass_loss.backward(retain_graph=True)\n","                        subclass_loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()  # Update the learning rate according to the 1Cycle policy\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Superclass Acc: {epoch_acc_superclass:.4f}')\n","\n","            # Save the model if validation loss has decreased\n","            if phase == 'val' and epoch_loss < best_val_loss:\n","                best_val_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                model_save_path = BASE_DIR + f'cascaded_model_epoch_{epoch+1}.pt'\n","                torch.save(model.state_dict(), model_save_path)\n","                print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history"],"metadata":{"id":"S4OmjaIqoSCE","executionInfo":{"status":"ok","timestamp":1724608933027,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"NsVrUNyqovo3"}},{"cell_type":"code","source":["EPOCHS = 100\n","DEVICE = 'cuda' # 'cpu'\n","EXP_NO = 6\n","LR = 1e-5\n","BASE_DIR = f'/content/drive/MyDrive/New Exps/SamplesH/{EXP_NO}/'\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","os.makedirs(os.path.dirname(BASE_DIR), exist_ok=True)"],"metadata":{"id":"sphQYlIktBgY","executionInfo":{"status":"ok","timestamp":1724608933333,"user_tz":-180,"elapsed":312,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Initialize the model\n","classic_model = ClassicMobileNetV3(num_classes=100, pretrained=True)\n","\n","# Define the loss function and optimizer\n","optimizer = optim.Adam(classic_model.parameters(), lr=LR)\n","\n","# Call the training function for ClassicMobileNetV3\n","trained_classic_model, classic_history = train_classic_mobilenet(\n","    model=classic_model,\n","    dataloaders={'train': train_loader_classic, 'val': val_loader_clasic, 'test':test_loader_clasic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rKQ6xm5uow4H","executionInfo":{"status":"error","timestamp":1724610023127,"user_tz":-180,"elapsed":1089802,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"b8d83c69-7605-492f-c33c-eaf99548b479"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n","100%|██████████| 9.83M/9.83M [00:00<00:00, 106MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","----------\n","Train Loss: 5.6533 Acc: 0.0110\n","Val Loss: 4.7510 Acc: 0.0162\n","New best model saved with validation loss: 4.7510\n","Epoch 2/100\n","----------\n","Train Loss: 4.9879 Acc: 0.0180\n","Val Loss: 4.5696 Acc: 0.0298\n","New best model saved with validation loss: 4.5696\n","Epoch 3/100\n","----------\n","Train Loss: 4.6744 Acc: 0.0278\n","Val Loss: 4.4029 Acc: 0.0474\n","New best model saved with validation loss: 4.4029\n","Epoch 4/100\n","----------\n","Train Loss: 4.4369 Acc: 0.0472\n","Val Loss: 4.2035 Acc: 0.0692\n","New best model saved with validation loss: 4.2035\n","Epoch 5/100\n","----------\n","Train Loss: 4.1871 Acc: 0.0717\n","Val Loss: 3.9818 Acc: 0.0980\n","New best model saved with validation loss: 3.9818\n","Epoch 6/100\n","----------\n","Train Loss: 3.9598 Acc: 0.0987\n","Val Loss: 3.7799 Acc: 0.1288\n","New best model saved with validation loss: 3.7799\n","Epoch 7/100\n","----------\n","Train Loss: 3.7577 Acc: 0.1280\n","Val Loss: 3.5897 Acc: 0.1527\n","New best model saved with validation loss: 3.5897\n","Epoch 8/100\n","----------\n","Train Loss: 3.5753 Acc: 0.1560\n","Val Loss: 3.4408 Acc: 0.1798\n","New best model saved with validation loss: 3.4408\n","Epoch 9/100\n","----------\n","Train Loss: 3.4053 Acc: 0.1827\n","Val Loss: 3.3060 Acc: 0.1972\n","New best model saved with validation loss: 3.3060\n","Epoch 10/100\n","----------\n","Train Loss: 3.2535 Acc: 0.2064\n","Val Loss: 3.1949 Acc: 0.2216\n","New best model saved with validation loss: 3.1949\n","Epoch 11/100\n","----------\n","Train Loss: 3.1169 Acc: 0.2344\n","Val Loss: 3.0800 Acc: 0.2428\n","New best model saved with validation loss: 3.0800\n","Epoch 12/100\n","----------\n","Train Loss: 2.9982 Acc: 0.2549\n","Val Loss: 3.0126 Acc: 0.2611\n","New best model saved with validation loss: 3.0126\n","Epoch 13/100\n","----------\n","Train Loss: 2.8836 Acc: 0.2763\n","Val Loss: 2.9315 Acc: 0.2765\n","New best model saved with validation loss: 2.9315\n","Epoch 14/100\n","----------\n","Train Loss: 2.7933 Acc: 0.2945\n","Val Loss: 2.8768 Acc: 0.2910\n","New best model saved with validation loss: 2.8768\n","Epoch 15/100\n","----------\n","Train Loss: 2.6969 Acc: 0.3138\n","Val Loss: 2.8293 Acc: 0.2994\n","New best model saved with validation loss: 2.8293\n","Epoch 16/100\n","----------\n","Train Loss: 2.6278 Acc: 0.3272\n","Val Loss: 2.8102 Acc: 0.3089\n","New best model saved with validation loss: 2.8102\n","Epoch 17/100\n","----------\n","Train Loss: 2.5519 Acc: 0.3420\n","Val Loss: 2.8137 Acc: 0.3048\n","Epoch 18/100\n","----------\n","Train Loss: 2.5324 Acc: 0.3498\n","Val Loss: 2.8387 Acc: 0.3016\n","Epoch 19/100\n","----------\n","Train Loss: 2.4578 Acc: 0.3608\n","Val Loss: 2.7245 Acc: 0.3216\n","New best model saved with validation loss: 2.7245\n","Epoch 20/100\n","----------\n","Train Loss: 2.4253 Acc: 0.3703\n","Val Loss: 2.8011 Acc: 0.3107\n","Epoch 21/100\n","----------\n","Train Loss: 2.5320 Acc: 0.3502\n","Val Loss: 2.7060 Acc: 0.3247\n","New best model saved with validation loss: 2.7060\n","Epoch 22/100\n","----------\n","Train Loss: 2.6223 Acc: 0.3332\n","Val Loss: 2.8928 Acc: 0.2944\n","Epoch 23/100\n","----------\n","Train Loss: 2.6179 Acc: 0.3301\n","Val Loss: 2.9067 Acc: 0.2848\n","Epoch 24/100\n","----------\n","Train Loss: 2.7965 Acc: 0.2977\n","Val Loss: 2.7315 Acc: 0.3180\n","Epoch 25/100\n","----------\n","Train Loss: 2.7559 Acc: 0.3063\n","Val Loss: 3.0119 Acc: 0.2648\n","Epoch 26/100\n","----------\n","Train Loss: 2.6945 Acc: 0.3155\n","Val Loss: 2.7161 Acc: 0.3215\n","Epoch 27/100\n","----------\n","Train Loss: 2.6413 Acc: 0.3295\n","Val Loss: 2.9486 Acc: 0.2771\n","Epoch 28/100\n","----------\n","Train Loss: 2.6826 Acc: 0.3199\n","Val Loss: 2.7743 Acc: 0.3051\n","Epoch 29/100\n","----------\n","Train Loss: 2.8903 Acc: 0.2825\n","Val Loss: 2.8528 Acc: 0.2944\n","Epoch 30/100\n","----------\n","Train Loss: 2.7208 Acc: 0.3101\n","Val Loss: 2.8058 Acc: 0.3054\n","Epoch 31/100\n","----------\n","Train Loss: 2.6479 Acc: 0.3268\n","Val Loss: 2.7821 Acc: 0.3034\n","Epoch 32/100\n","----------\n","Train Loss: 2.8209 Acc: 0.2970\n","Val Loss: 2.7263 Acc: 0.3212\n","Epoch 33/100\n","----------\n","Train Loss: 2.6181 Acc: 0.3326\n","Val Loss: 2.7899 Acc: 0.3029\n","Epoch 34/100\n","----------\n","Train Loss: 2.6104 Acc: 0.3339\n","Val Loss: 2.6972 Acc: 0.3260\n","New best model saved with validation loss: 2.6972\n","Epoch 35/100\n","----------\n","Train Loss: 2.4652 Acc: 0.3639\n","Val Loss: 2.5856 Acc: 0.3522\n","New best model saved with validation loss: 2.5856\n","Epoch 36/100\n","----------\n","Train Loss: 2.5632 Acc: 0.3442\n","Val Loss: 2.7223 Acc: 0.3216\n","Epoch 37/100\n","----------\n","Train Loss: 2.9096 Acc: 0.2840\n","Val Loss: 2.6959 Acc: 0.3259\n","Epoch 38/100\n","----------\n","Train Loss: 2.7882 Acc: 0.3019\n","Val Loss: 2.8602 Acc: 0.2951\n","Epoch 39/100\n","----------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-9f9df4a8dfe3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Call the training function for ClassicMobileNetV3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m trained_classic_model, classic_history = train_classic_mobilenet(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassic_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loader_classic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loader_clasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_loader_clasic\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-45cdc731837f>\u001b[0m in \u001b[0;36mtrain_classic_mobilenet\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, device, max_lr, phases)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update the learning rate according to the 1Cycle policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["hierarchic_model = HierarchicMobileNetV3(num_superclasses=20, num_subclasses=[5 for _ in range(20)], pretrained=True, device=DEVICE)\n","optimizer = optim.Adam(hierarchic_model.parameters(), lr=LR)\n","\n","'''\n","trained_hierarchic_model, hierarchic_history = train_hierarchic_mobilenet_fast(\n","    model=hierarchic_model,\n","    dataloaders={'train': train_loader_hierarchic, 'val': val_loader_hierarchic, 'test':test_loader_hierarchic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")\n","'''"],"metadata":{"id":"eFb0zMptss6G","executionInfo":{"status":"aborted","timestamp":1724610023127,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parallel_model = ParallelMultiTaskMobileNetV3(num_superclasses=20, num_subclasses=100, pretrained=True)\n","optimizer = optim.Adam(parallel_model.parameters(), lr=LR)\n","\n","# Call the training function for ParallelMultiTaskMobileNetV3\n","trained_parallel_model, parallel_history = train_parallel_mobilenet(\n","    model=parallel_model,\n","    dataloaders={'train': train_loader_parallel, 'val': val_loader_parallel, 'test':test_loader_parallel},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")"],"metadata":{"id":"_y9DKPP9s89E","executionInfo":{"status":"aborted","timestamp":1724610023127,"user_tz":-180,"elapsed":5,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cascaded_model = CascadedMultiTaskMobileNetV3(num_superclasses=20, num_subclasses=100, pretrained=True)\n","optimizer = optim.Adam(cascaded_model.parameters(), lr=LR)\n","\n","trained_cascaded_model, cascaded_history = train_cascaded_mobilenet(\n","    model=cascaded_model,\n","    dataloaders={'train': train_loader_cascaded, 'val': val_loader_cascaded, 'test':test_loader_cascaded},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")"],"metadata":{"id":"cCRtAp-0tNsK","executionInfo":{"status":"aborted","timestamp":1724610023127,"user_tz":-180,"elapsed":5,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plot"],"metadata":{"id":"2k9go_SQs3lz"}},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt\n","\n","# Assuming you have these history dictionaries from your training sessions\n","# Each dictionary should contain lists like 'train_acc', 'val_acc', 'train_loss', 'val_loss'\n","# Example:\n","# classic_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# hierarchic_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# global_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# parallel_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# cascaded_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","\n","# List of histories and labels for the plot\n","histories = [\n","    ('Classic', classic_history),\n","    # ('Hierarchic', hierarchic_history),\n","    ('Parallel', parallel_history),\n","    ('Cascaded', cascaded_history)\n","]\n","\n","# Function to create a folder and save the plot\n","def save_plot(history_key, title, ylabel, save_path):\n","    # Create the directory if it doesn't exist\n","\n","    # Plot the metric for each model\n","    plt.figure(figsize=(12, 8))\n","    for label, history in histories:\n","      if history_key in history:\n","        plt.plot(history[history_key], label=f'{label} {title}')\n","\n","    plt.title(title)\n","    plt.xlabel('Epoch')\n","    plt.ylabel(ylabel)\n","    plt.legend(loc='best')\n","    plt.grid(True)\n","\n","    # Save the plot to the specified path\n","    plt.savefig(save_path)\n","\n","    # Optionally, show the plot (you can comment this out if you don't want to display it)\n","    plt.show()\n","\n","# Define the base directory where you want to save the plots\n","base_dir = BASE_DIR\n","\n","# Save plots for each metric\n","save_plot('train_acc', 'Training Accuracy', 'Accuracy', os.path.join(base_dir, 'training_accuracy.png'))\n","save_plot('val_acc', 'Validation Accuracy', 'Accuracy', os.path.join(base_dir, 'validation_accuracy.png'))\n","save_plot('train_acc_superclass', 'Training Superclass Accuracy', 'Accuracy', os.path.join(base_dir, 'training_accuracy_superclass.png'))\n","save_plot('val_acc_superclass', 'Validation Superclass Accuracy', 'Accuracy', os.path.join(base_dir, 'validation_accuracy_superclass.png'))\n","save_plot('train_loss', 'Training Loss', 'Loss', os.path.join(base_dir, 'training_loss.png'))\n","save_plot('val_loss', 'Validation Loss', 'Loss', os.path.join(base_dir, 'validation_loss.png'))"],"metadata":{"id":"Jkg1Wew8ue7g","executionInfo":{"status":"aborted","timestamp":1724610023128,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"rvETUyNhiHQ7"}},{"cell_type":"code","source":["optimizer = optim.Adam(trained_classic_model.parameters(), lr=LR)\n","\n","_, classic_history = train_classic_mobilenet(\n","    model=trained_classic_model,\n","    dataloaders={'train': train_loader_classic, 'val': val_loader_clasic, 'test':test_loader_clasic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n",")\n","\n","classic_accuracy = classic_history['test_acc']\n","\n","optimizer = optim.Adam(trained_parallel_model.parameters(), lr=LR)\n","\n","_, parallel_history = train_parallel_mobilenet(\n","    model=trained_parallel_model,\n","    dataloaders={'train': train_loader_parallel, 'val': val_loader_parallel, 'test':test_loader_parallel},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n",")\n","\n","parallel_accuracy = parallel_history['test_acc']\n","\n","optimizer = optim.Adam(trained_cascaded_model.parameters(), lr=LR)\n","\n","_, cascaded_history = train_cascaded_mobilenet(\n","    model=trained_cascaded_model,\n","    dataloaders={'train': train_loader_cascaded, 'val': val_loader_cascaded, 'test':test_loader_cascaded},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n",")\n","\n","cascaded_accuracy = cascaded_history['test_acc']"],"metadata":{"id":"dYWq6LsEiI2O","executionInfo":{"status":"aborted","timestamp":1724610023128,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Sample data\n","categories = ['Classic Accuracy', 'Parallel Accuracy', 'Cascaded Accuracy']\n","\n","values = [classic_accuracy[0], parallel_accuracy[0], cascaded_accuracy[0]]\n","\n","# Create a bar plot\n","plt.bar(categories, values)\n","\n","# Add titles and labels\n","plt.title('Test Accyract')\n","plt.xlabel('Method')\n","plt.ylabel('Accuracy')\n","\n","plt.savefig(os.path.join(base_dir, 'test_accuracy.png'))\n","\n","plt.show()\n","\n"],"metadata":{"id":"o6Kqx226jNlq","executionInfo":{"status":"aborted","timestamp":1724610023128,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"BL6t1LcOZ1I3","executionInfo":{"status":"aborted","timestamp":1724610023128,"user_tz":-180,"elapsed":6,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}}},"execution_count":null,"outputs":[]}]}