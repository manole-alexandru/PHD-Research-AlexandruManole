{"cells":[{"cell_type":"markdown","metadata":{"id":"bfsmS71HsnkM"},"source":["# Import"]},{"cell_type":"code","source":["#@title Install missing libraries\n","!pip install thop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQwHT-weINA7","executionInfo":{"status":"ok","timestamp":1739176582552,"user_tz":-120,"elapsed":68864,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"}},"outputId":"d679405b-5a9a-4c90-e40d-3db7649e1351","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6SqXB5w2K7w","cellView":"form"},"outputs":[],"source":["#@title Augementations\n","\n","transform2 = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((224, 224)),  # Resize to 224x224 to match MobileNet's input size\n","    torchvision.transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n","    # torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","transform = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((28, 28)),  # Resize to 224x224 to match MobileNet's input size\n","    torchvision.transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n","    # torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","train_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((224, 224)),\n","    torchvision.transforms.RandomHorizontalFlip(),\n","    # torchvision.transforms.RandomCrop(32, padding=4),\n","    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    # torchvision.transforms.RandomRotation(15),\n","    torchvision.transforms.ToTensor(),\n","   #  torchvision.transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]),  # CIFAR-100 normalization values\n","    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","\n","test_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((224, 224)),\n","    torchvision.transforms.ToTensor(),\n","    # torchvision.transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]),\n","    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# train_transforms = test_transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kX3-7LyzqkbS"},"outputs":[],"source":["import torchvision\n","import json\n","import os\n","import shutil\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import math\n","import pickle\n","from torch.utils.data import random_split, DataLoader\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","from thop import profile"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"elapsed":121199,"status":"error","timestamp":1739176711863,"user":{"displayName":"Alexandru Manole","userId":"16000231996200139655"},"user_tz":-120},"id":"zdqPwTbIvJa4","outputId":"08a3d9e2-a405-427d-ddf5-10527ad515d2"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sphQYlIktBgY"},"outputs":[],"source":["EPOCHS = 25\n","DEVICE = 'cuda' # 'cpu'\n","EXP_NO = 71\n","LR = 3e-4\n","DROPOUT = 0.25\n","MAX_LR = 1e-3\n","LOSS_WEIGHTS = [1, 0.2] # [0.9, 0.1] # [0.2, 0.8] [0.5, 0.5]\n","BASE_DIR = f'/content/drive/MyDrive/New Exps/SamplesH/{EXP_NO}/'\n","\n","MODEL_NAME = 'convnext_base'\n","\n","DATASET = 'CompCars' # 'CompCars' # cifar100, INaturalist, Places365, ImageNet, StandfordCars\n","AUGMENTATION = False\n","TRAIN_TRANSFORMS = train_transforms\n","TEST_TRANSOFRMS = test_transforms\n","\n","BATCH_SIZE = 32\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","os.makedirs(os.path.dirname(BASE_DIR), exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7iWruNk2IF0"},"outputs":[],"source":["EXPERIMENT_DICTIONARY = {\n","    'EPOCHS': EPOCHS,\n","    'DEVICE': DEVICE,\n","    'EXP_NO': EXP_NO,\n","    'MODEL': MODEL_NAME,\n","    'LR': LR,\n","    'DROPOUT': DROPOUT,\n","    'LOSS_FUNCTION': str(criterion),\n","    'OPTIMIZER': str(optim.Adam),\n","    'MAX_LR': MAX_LR,\n","    'LOSS_WEIGHTS': LOSS_WEIGHTS,\n","    'DATASET': DATASET,\n","    'AUGMENTATION': AUGMENTATION\n","}\n","\n","with open(BASE_DIR + \"exp_info.json\", \"w\") as outfile:\n","    json.dump(EXPERIMENT_DICTIONARY, outfile)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3C7ipUwcF1U"},"outputs":[],"source":["if MODEL_NAME == 'mobilenet_v3_small':\n","  MODEL = torchvision.models.mobilenet_v3_small\n","elif MODEL_NAME == 'mobilenet_v3_large':\n","  MODEL = torchvision.models.mobilenet_v3_large\n","elif MODEL_NAME == 'resnet18':\n","  MODEL = torchvision.models.resnet18\n","elif MODEL_NAME == 'resnet50':\n","  MODEL = torchvision.models.resnet50\n","elif MODEL_NAME == 'swin_b':\n","  MODEL = torchvision.models.swin_s\n","elif MODEL_NAME == 'vgg16':\n","  MODEL = torchvision.models.vgg16\n","elif MODEL_NAME == 'vgg19':\n","  MODEL = torchvision.models.vgg19\n","elif MODEL_NAME == 'densenet121':\n","  MODEL = torchvision.models.densenet121\n","elif MODEL_NAME == 'vit_b_16':\n","  MODEL = torchvision.models.vit_b_16\n","elif MODEL_NAME == 'efficientnet_b0':\n","  MODEL = torchvision.models.efficientnet_b0\n","elif MODEL_NAME == 'maxvit_t':\n","  MODEL = torchvision.models.maxvit_t\n","elif MODEL_NAME == 'convnext_base':\n","  MODEL = torchvision.models.convnext_base"]},{"cell_type":"markdown","metadata":{"id":"1060liaPlDo5"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCvkQvh7rrR8"},"outputs":[],"source":["# os.mkdir('/content/dataset/')\n","# os.mkdir('/content/dataset/train/')\n","# os.mkdir('/content/dataset/test/')\n","\n","if not AUGMENTATION:\n","  TRAIN_TRANSFORMS = TEST_TRANSFORMS\n","\n","if DATASET == 'cifar100':\n","  # train parameter ???\n","  train_dataset = torchvision.datasets.CIFAR100(root='/content/dataset/train/', download=True, transform=TRAIN_TRANSFORMS)\n","  test_dataset = torchvision.datasets.CIFAR100(root='/content/dataset/test/', download=True, transform=TEST_TRANSFORMS)\n","\n","  NUM_CLASSES = 100\n","  NUM_SUPERCLASSES = 20\n","  NUM_SUBCLASSES = 100\n","elif DATASET == 'INaturalist':\n","  train_dataset = torchvision.datasets.INaturalist(root='/content/dataset/train/', download=True, transform=TRAIN_TRANSFORMS)\n","  test_dataset = torchvision.datasets.INaturalist(root='/content/dataset/test/', download=True, transform=TEST_TRANSFORMS)\n","elif DATASET == 'Places365':\n","  train_dataset = torchvision.datasets.Places365(root='/content/dataset/train/', download=True, transform=TRAIN_TRANSFORMS)\n","  test_dataset = torchvision.datasets.Places365(root='/content/dataset/test/', download=True, transform=TEST_TRANSFORMS)\n","elif DATASET == 'ImageNet': # ImageNet\n","  train_dataset = torchvision.datasets.ImageNet(root='/content/dataset/train/', download=True, transform=TRAIN_TRANSFORMS)\n","  test_dataset = torchvision.datasets.ImageNet(root='/content/dataset/test/', download=True, transform=TEST_TRANSFORMS)\n","elif DATASET == 'StandfordCars':\n","  !unzip /content/drive/MyDrive/New\\ Exps/Dataset/standford_cars.zip -d '/content/dataset/'\n","  shutil.copy(\"/content/drive/MyDrive/New Exps/Dataset/cardatasettrain.csv\", \"/content/dataset/cardatasettrain.csv\")\n","  shutil.copy(\"/content/drive/MyDrive/New Exps/Dataset/cardatasettest.csv\", \"/content/dataset/cardatasettest.csv\")\n","  NUM_CLASSES = 196\n","  NUM_SUPERCLASSES = 49\n","  NUM_SUBCLASSES = 196\n","elif DATASET == 'CompCars':\n","  !mkdir /content/dataset\n","  !unzip /content/drive/MyDrive/New\\ Exps/Dataset/CompCars.zip -d /content/dataset\n","  NUM_CLASSES = 4446\n","  NUM_SUPERCLASSES = 164\n","  NUM_SUBCLASSES = 4446\n","else:\n","  assert False"]},{"cell_type":"markdown","source":["# CIFAR 100"],"metadata":{"id":"f5ZwA-USLII4"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_Nh7BCsk4TIU"},"outputs":[],"source":["#@title CIFAR100 Classes & Superclasses\n","\n","if DATASET == 'cifar100':\n","\n","  # Define the classes and superclasses\n","  cifar100_classes = [\n","      # Superclass: Aquatic Mammals\n","      {\"class\": \"beaver\", \"superclass\": \"aquatic mammals\"},\n","      {\"class\": \"dolphin\", \"superclass\": \"aquatic mammals\"},\n","      {\"class\": \"otter\", \"superclass\": \"aquatic mammals\"},\n","      {\"class\": \"seal\", \"superclass\": \"aquatic mammals\"},\n","      {\"class\": \"whale\", \"superclass\": \"aquatic mammals\"},\n","\n","      # Superclass: Fish\n","      {\"class\": \"aquarium fish\", \"superclass\": \"fish\"},\n","      {\"class\": \"flatfish\", \"superclass\": \"fish\"},\n","      {\"class\": \"ray\", \"superclass\": \"fish\"},\n","      {\"class\": \"shark\", \"superclass\": \"fish\"},\n","      {\"class\": \"trout\", \"superclass\": \"fish\"},\n","\n","      # Superclass: Flowers\n","      {\"class\": \"orchid\", \"superclass\": \"flowers\"},\n","      {\"class\": \"poppy\", \"superclass\": \"flowers\"},\n","      {\"class\": \"rose\", \"superclass\": \"flowers\"},\n","      {\"class\": \"sunflower\", \"superclass\": \"flowers\"},\n","      {\"class\": \"tulip\", \"superclass\": \"flowers\"},\n","\n","      # Superclass: Food Containers\n","      {\"class\": \"bottle\", \"superclass\": \"food containers\"},\n","      {\"class\": \"bowl\", \"superclass\": \"food containers\"},\n","      {\"class\": \"can\", \"superclass\": \"food containers\"},\n","      {\"class\": \"cup\", \"superclass\": \"food containers\"},\n","      {\"class\": \"plate\", \"superclass\": \"food containers\"},\n","\n","      # Superclass: Fruits and Vegetables\n","      {\"class\": \"apple\", \"superclass\": \"fruits and vegetables\"},\n","      {\"class\": \"mushroom\", \"superclass\": \"fruits and vegetables\"},\n","      {\"class\": \"orange\", \"superclass\": \"fruits and vegetables\"},\n","      {\"class\": \"pear\", \"superclass\": \"fruits and vegetables\"},\n","      {\"class\": \"sweet pepper\", \"superclass\": \"fruits and vegetables\"},\n","\n","      # Superclass: Household Electrical Devices\n","      {\"class\": \"clock\", \"superclass\": \"household electrical devices\"},\n","      {\"class\": \"keyboard\", \"superclass\": \"household electrical devices\"},\n","      {\"class\": \"lamp\", \"superclass\": \"household electrical devices\"},\n","      {\"class\": \"telephone\", \"superclass\": \"household electrical devices\"},\n","      {\"class\": \"television\", \"superclass\": \"household electrical devices\"},\n","\n","      # Superclass: Household Furniture\n","      {\"class\": \"bed\", \"superclass\": \"household furniture\"},\n","      {\"class\": \"chair\", \"superclass\": \"household furniture\"},\n","      {\"class\": \"couch\", \"superclass\": \"household furniture\"},\n","      {\"class\": \"table\", \"superclass\": \"household furniture\"},\n","      {\"class\": \"wardrobe\", \"superclass\": \"household furniture\"},\n","\n","      # Superclass: Insects\n","      {\"class\": \"bee\", \"superclass\": \"insects\"},\n","      {\"class\": \"beetle\", \"superclass\": \"insects\"},\n","      {\"class\": \"butterfly\", \"superclass\": \"insects\"},\n","      {\"class\": \"caterpillar\", \"superclass\": \"insects\"},\n","      {\"class\": \"cockroach\", \"superclass\": \"insects\"},\n","\n","      # Superclass: Large Carnivores\n","      {\"class\": \"bear\", \"superclass\": \"large carnivores\"},\n","      {\"class\": \"leopard\", \"superclass\": \"large carnivores\"},\n","      {\"class\": \"lion\", \"superclass\": \"large carnivores\"},\n","      {\"class\": \"tiger\", \"superclass\": \"large carnivores\"},\n","      {\"class\": \"wolf\", \"superclass\": \"large carnivores\"},\n","\n","      # Superclass: Large Man-made Outdoor Things\n","      {\"class\": \"bridge\", \"superclass\": \"large man-made outdoor things\"},\n","      {\"class\": \"castle\", \"superclass\": \"large man-made outdoor things\"},\n","      {\"class\": \"house\", \"superclass\": \"large man-made outdoor things\"},\n","      {\"class\": \"road\", \"superclass\": \"large man-made outdoor things\"},\n","      {\"class\": \"skyscraper\", \"superclass\": \"large man-made outdoor things\"},\n","\n","      # Superclass: Large Natural Outdoor Scenes\n","      {\"class\": \"cloud\", \"superclass\": \"large natural outdoor scenes\"},\n","      {\"class\": \"forest\", \"superclass\": \"large natural outdoor scenes\"},\n","      {\"class\": \"mountain\", \"superclass\": \"large natural outdoor scenes\"},\n","      {\"class\": \"plain\", \"superclass\": \"large natural outdoor scenes\"},\n","      {\"class\": \"sea\", \"superclass\": \"large natural outdoor scenes\"},\n","\n","      # Superclass: Large Omnivores and Herbivores\n","      {\"class\": \"camel\", \"superclass\": \"large omnivores and herbivores\"},\n","      {\"class\": \"cattle\", \"superclass\": \"large omnivores and herbivores\"},\n","      {\"class\": \"chimpanzee\", \"superclass\": \"large omnivores and herbivores\"},\n","      {\"class\": \"elephant\", \"superclass\": \"large omnivores and herbivores\"},\n","      {\"class\": \"kangaroo\", \"superclass\": \"large omnivores and herbivores\"},\n","\n","      # Superclass: Medium-sized Mammals\n","      {\"class\": \"fox\", \"superclass\": \"medium-sized mammals\"},\n","      {\"class\": \"porcupine\", \"superclass\": \"medium-sized mammals\"},\n","      {\"class\": \"possum\", \"superclass\": \"medium-sized mammals\"},\n","      {\"class\": \"raccoon\", \"superclass\": \"medium-sized mammals\"},\n","      {\"class\": \"skunk\", \"superclass\": \"medium-sized mammals\"},\n","\n","      # Superclass: Non-insect Invertebrates\n","      {\"class\": \"crab\", \"superclass\": \"non-insect invertebrates\"},\n","      {\"class\": \"lobster\", \"superclass\": \"non-insect invertebrates\"},\n","      {\"class\": \"snail\", \"superclass\": \"non-insect invertebrates\"},\n","      {\"class\": \"spider\", \"superclass\": \"non-insect invertebrates\"},\n","      {\"class\": \"worm\", \"superclass\": \"non-insect invertebrates\"},\n","\n","      # Superclass: People\n","      {\"class\": \"baby\", \"superclass\": \"people\"},\n","      {\"class\": \"boy\", \"superclass\": \"people\"},\n","      {\"class\": \"girl\", \"superclass\": \"people\"},\n","      {\"class\": \"man\", \"superclass\": \"people\"},\n","      {\"class\": \"woman\", \"superclass\": \"people\"},\n","\n","      # Superclass: Reptiles\n","      {\"class\": \"crocodile\", \"superclass\": \"reptiles\"},\n","      {\"class\": \"dinosaur\", \"superclass\": \"reptiles\"},\n","      {\"class\": \"lizard\", \"superclass\": \"reptiles\"},\n","      {\"class\": \"snake\", \"superclass\": \"reptiles\"},\n","      {\"class\": \"turtle\", \"superclass\": \"reptiles\"},\n","\n","      # Superclass: Small Mammals\n","      {\"class\": \"hamster\", \"superclass\": \"small mammals\"},\n","      {\"class\": \"mouse\", \"superclass\": \"small mammals\"},\n","      {\"class\": \"rabbit\", \"superclass\": \"small mammals\"},\n","      {\"class\": \"shrew\", \"superclass\": \"small mammals\"},\n","      {\"class\": \"squirrel\", \"superclass\": \"small mammals\"},\n","\n","      # Superclass: Trees\n","      {\"class\": \"maple tree\", \"superclass\": \"trees\"},\n","      {\"class\": \"oak tree\", \"superclass\": \"trees\"},\n","      {\"class\": \"palm tree\", \"superclass\": \"trees\"},\n","      {\"class\": \"pine tree\", \"superclass\": \"trees\"},\n","      {\"class\": \"willow tree\", \"superclass\": \"trees\"},\n","\n","      # Superclass: Vehicles 1\n","      {\"class\": \"bicycle\", \"superclass\": \"vehicles 1\"},\n","      {\"class\": \"bus\", \"superclass\": \"vehicles 1\"},\n","      {\"class\": \"motorcycle\", \"superclass\": \"vehicles 1\"},\n","      {\"class\": \"pickup truck\", \"superclass\": \"vehicles 1\"},\n","      {\"class\": \"train\", \"superclass\": \"vehicles 1\"},\n","\n","      # Superclass: Vehicles 2\n","      {\"class\": \"lawn mower\", \"superclass\": \"vehicles 2\"},\n","      {\"class\": \"rocket\", \"superclass\": \"vehicles 2\"},\n","      {\"class\": \"streetcar\", \"superclass\": \"vehicles 2\"},\n","      {\"class\": \"tank\", \"superclass\": \"vehicles 2\"},\n","      {\"class\": \"tractor\", \"superclass\": \"vehicles 2\"},\n","  ]\n","\n","  # Write to JSON file\n","  with open('cifar100_classes.json', 'w') as json_file:\n","      json.dump(cifar100_classes, json_file, indent=4)\n","\n","  superclasses = [\n","      \"aquatic mammals\",          # 1-5\n","      \"fish\",                     # 6-10\n","      \"flowers\",                  # 11-15\n","      \"food containers\",          # 16-20\n","      \"fruits and vegetables\",    # 21-25\n","      \"household electrical devices\",  # 26-30\n","      \"household furniture\",      # 31-35\n","      \"insects\",                  # 36-40\n","      \"large carnivores\",         # 41-45\n","      \"large man-made outdoor things\", # 46-50\n","      \"large natural outdoor scenes\",  # 51-55\n","      \"large omnivores and herbivores\",# 56-60\n","      \"medium-sized mammals\",     # 61-65\n","      \"non-insect invertebrates\", # 66-70\n","      \"people\",                   # 71-75\n","      \"reptiles\",                 # 76-80\n","      \"small mammals\",            # 81-85\n","      \"trees\",                    # 86-90\n","      \"vehicles 1\",               # 91-95\n","      \"vehicles 2\"                # 96-100\n","  ]\n","\n","  classes = [\n","      # Aquatic Mammals\n","      \"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\",\n","\n","      # Fish\n","      \"aquarium fish\", \"flatfish\", \"ray\", \"shark\", \"trout\",\n","\n","      # Flowers\n","      \"orchid\", \"poppy\", \"rose\", \"sunflower\", \"tulip\",\n","\n","      # Food Containers\n","      \"bottle\", \"bowl\", \"can\", \"cup\", \"plate\",\n","\n","      # Fruits and Vegetables\n","      \"apple\", \"mushroom\", \"orange\", \"pear\", \"sweet pepper\",\n","\n","      # Household Electrical Devices\n","      \"clock\", \"keyboard\", \"lamp\", \"telephone\", \"television\",\n","\n","      # Household Furniture\n","      \"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\",\n","\n","      # Insects\n","      \"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\",\n","\n","      # Large Carnivores\n","      \"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\",\n","\n","      # Large Man-made Outdoor Things\n","      \"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\",\n","\n","      # Large Natural Outdoor Scenes\n","      \"cloud\", \"forest\", \"mountain\", \"plain\", \"sea\",\n","\n","      # Large Omnivores and Herbivores\n","      \"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\",\n","\n","      # Medium-sized Mammals\n","      \"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\",\n","\n","      # Non-insect Invertebrates\n","      \"crab\", \"lobster\", \"snail\", \"spider\", \"worm\",\n","\n","      # People\n","      \"baby\", \"boy\", \"girl\", \"man\", \"woman\",\n","\n","      # Reptiles\n","      \"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\",\n","\n","      # Small Mammals\n","      \"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\",\n","\n","      # Trees\n","      \"maple tree\", \"oak tree\", \"palm tree\", \"pine tree\", \"willow tree\",\n","\n","      # Vehicles 1\n","      \"bicycle\", \"bus\", \"motorcycle\", \"pickup truck\", \"train\",\n","\n","      # Vehicles 2\n","      \"lawn mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\"\n","  ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5gnDFCE4BZK5"},"outputs":[],"source":["if DATASET == 'cifar100':\n","\n","  file_path = '/content/dataset/test/cifar-100-python/meta'\n","\n","  # Unpickle the file\n","  with open(file_path, 'rb') as file:\n","      data = pickle.load(file)\n","\n","  alphabetical_to_original_label = {}\n","\n","  for label_id, label in enumerate(data['fine_label_names']):\n","    label = label.replace('_', ' ')\n","    new_index = classes.index(label)\n","    superclass = cifar100_classes[new_index]['superclass']\n","    new_superclass_index = superclasses.index(superclass)\n","    # print(label, new_index, new_superclass_index)\n","    alphabetical_to_original_label[label_id] = {'index': new_index, 'class':classes[new_index], 'super_index':new_superclass_index, 'superclass': superclass}\n","\n","  print(alphabetical_to_original_label)\n","\n","  superclass_and_class_to_hierarchic_label = {}\n","\n","  for key in alphabetical_to_original_label:\n","    info = alphabetical_to_original_label[key]\n","    superclass = info['superclass']\n","    if superclass not in superclass_and_class_to_hierarchic_label:\n","      hierarchic_label = 0\n","      superclass_and_class_to_hierarchic_label[superclass] = 0\n","    else:\n","      hierarchic_label = superclass_and_class_to_hierarchic_label[superclass] + 1\n","      superclass_and_class_to_hierarchic_label[superclass] = hierarchic_label\n","    info['hierarchic_index'] = hierarchic_label\n","    alphabetical_to_original_label[key] = info\n","\n","  print(alphabetical_to_original_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvHLhzMhr7F5"},"outputs":[],"source":["if DATASET == 'cifar100':\n","  for td_id, td in enumerate(train_dataset):\n","    pil_img = td[0]\n","    numpy_img = np.clip(pil_img.permute(1, 2, 0).numpy()[:, :, ::-1] * 255, 0, 255)\n","    class_label = td[1]\n","    print(numpy_img.shape)\n","    # cv2_imshow(numpy_img)\n","    # print(alphabetical_to_original_label[class_label]['class'], alphabetical_to_original_label[class_label]['superclass'])\n","    if td_id % 10 == 9:\n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjvB2M8-l-ls"},"outputs":[],"source":["if DATASET == 'cifar100':\n","  train_size = int(0.8 * len(train_dataset))\n","  val_size = len(train_dataset) - train_size\n","\n","  # Split the dataset into training and validation\n","  train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","  # Create data loaders for each\n","  train_loader_classic  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","  val_loader_clasic = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","  test_loader_clasic = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"drZMhGHV45xz"},"source":["# INaturalist Classes and Superclasses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvtebueI5HIr"},"outputs":[],"source":["if DATASET == 'INaturalist':\n","  pass"]},{"cell_type":"markdown","metadata":{"id":"lvNQQCdvJKk6"},"source":["# Places365"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNPUr01rJO7O"},"outputs":[],"source":["if DATASET == 'Places365':\n","  pass"]},{"cell_type":"markdown","metadata":{"id":"nSdCN_c7GryH"},"source":["# Standford Cars"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"814v0cs4Gu9M"},"outputs":[],"source":["from torch.utils.data import Dataset\n","from PIL import Image\n","from scipy.io import loadmat\n","import pandas as pd\n","\n","class StandfordCarsDataset(Dataset):\n","    def __init__(self, root, split, transform=None, target_transform=None):\n","        \"\"\"\n","        Args:\n","            data (any format): The data (e.g., list of file paths, array of images).\n","            labels (any format): The labels associated with the data.\n","            transform (callable, optional): Optional transform to apply to a sample.\n","        \"\"\"\n","        self.root = root\n","        self.split = split\n","        if self.split == 'train' or self.split == 'val':\n","          self.path = 'cars_train'\n","        else:\n","          self.path = 'cars_train'\n","\n","        self.image_paths = self.root + '/' + self.path + '/' + self.path + '/'\n","        self.label_path = self.root + '/cars_annos.mat'\n","        annotation_path = '/content/dataset/cardatasettrain.csv' # if self.split == 'train' else '/content/dataset/cardatasettest.csv'\n","        self.annotation_df = pd.read_csv(annotation_path)\n","        self.data = []\n","        self.labels = []\n","        self.classes = []\n","        self.alphabetical_to_original_label = {}\n","        self.load_data()\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def load_data(self):\n","      data = loadmat(self.label_path)\n","      self.classes = data['class_names'][0]\n","      self.hierarchic_classes = list(set([cls[0].split(' ')[0] for cls in self.classes]))\n","      # no_samples = 8144 if self.split =='train' else 8041 # len(data['annotations'][0])\n","      no_samples = len(self.annotation_df)\n","      # for ids, sample in enumerate(data['annotations'][0]):\n","      for ids, sample in self.annotation_df.iterrows():\n","        # if (self.split == 'train' and ids < no_samples * 0.7) or (self.split == 'val' and (ids >= no_samples * 0.7 and ids < no_samples * 0.9)) or (self.split == 'test' and ids >= no_samples * 0.9):\n","        image_name =  sample['image']  # sample[0][0].split('/')[-1]\n","        image_no = int(image_name.split('.')[0])\n","        # if (self.split == 'train' and image_no < no_samples) or (self.split == 'val' and image_no > 8144 and image_no < 8144 + no_samples *0.8) or (self.split == 'test' and image_no > 8144 and image_no >= 8144 + no_samples *0.8):\n","        #  if self.split in ['val', 'test']:\n","        if (self.split == 'train' and ids <= no_samples * 0.7) or (self.split == 'val' and ids > no_samples * 0.7 and ids < no_samples * 0.8) or (self.split == 'test' and ids >= no_samples * 0.8):\n","            image_name = str(image_no).zfill(5) + '.jpg'\n","            self.data.append(self.image_paths + image_name)\n","            class_id = sample['Class'] - 1 # sample[5][0][0] - 1\n","            if class_id not in self.alphabetical_to_original_label:\n","              superclass = self.classes[class_id][0].split(' ')[0]\n","              self.alphabetical_to_original_label[class_id] = {'index': class_id, 'class': self.classes[class_id], 'super_index': self.hierarchic_classes.index(superclass), 'superclass':superclass}\n","            self.labels.append(class_id)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # Load the sample data and label\n","        sample = Image.open(self.data[idx]).convert(\"RGB\") # torchvision.io.read_image(self.data[idx])\n","        label = self.labels[idx]\n","\n","        # Apply any transformation if provided\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        if self.target_transform:\n","          label = self.target_transform(label)\n","\n","        return sample, label\n","\n","if DATASET == 'StandfordCars':\n","    train_dataset = StandfordCarsDataset(root='/content/dataset', split='train', transform=TRAIN_TRANSFORMS)\n","    alphabetical_to_original_label = train_dataset.alphabetical_to_original_label\n","    val_dataset = StandfordCarsDataset(root='/content/dataset', split='val', transform=TEST_TRANSFORMS)\n","    test_dataset = StandfordCarsDataset(root='/content/dataset', split='test', transform=TEST_TRANSFORMS)\n","    train_loader_classic  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","    val_loader_clasic = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","    test_loader_clasic = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","    # print(alphabetical_to_original_label)"]},{"cell_type":"markdown","source":["# Comp Cars"],"metadata":{"id":"OubfuJ3BLN0-"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import scipy.io\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","import random\n","\n","class CompCarsDataset(Dataset):\n","    def __init__(self, root_dir='/content/dataset/', split='train', transform=None, target_transform=None):\n","        \"\"\"\n","        Args:\n","            root_dir (str): Path to dataset (train or test folder).\n","            mat_file (str): Path to .mat file containing class names.\n","            transform (callable, optional): Transformations to apply.\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.image_dir = root_dir + 'image/'\n","        self.label_dir = root_dir + 'label/'\n","        self.split_dir = root_dir + 'train_test_split/'\n","        self.misc_dir = root_dir + 'misc/'\n","        self.train_test_split = root_dir + 'train_test_split/classification/'\n","        self.train_images = [filename for filename in [line.strip() for line in open(self.train_test_split + 'train.txt')]]\n","        random.shuffle(self.train_images)\n","        self.test_images = [filename for filename in [line.strip() for line in open(self.train_test_split + 'test.txt')]]\n","        self.transform = transform\n","        self.split = split\n","        self.target_transform = target_transform\n","        self.makes, self.models = self._load_class_names(root_dir + '/misc/make_model_name.mat')\n","        # print(len(self.makes))\n","        # print(len(self.models))\n","\n","        self.image_paths = []\n","        self.labels = []\n","\n","        self.alphabetical_to_original_label = {}\n","\n","        # Collect all image paths and their corresponding labels\n","        self.no_classlabels = -1\n","        self.no_makes = -1\n","        self.no_models = -1\n","        for make in os.listdir(self.image_dir):\n","            make_path = os.path.join(self.image_dir, make)\n","            self.no_makes += 1\n","            for model in os.listdir(make_path):\n","                model_path = os.path.join(make_path, model)\n","                self.no_models += 1\n","                for year in os.listdir(model_path):\n","                    year_path = os.path.join(model_path, year)\n","                    self.no_classlabels += 1\n","                    self.alphabetical_to_original_label[self.no_classlabels] = {'index': self.no_classlabels, 'class': self.models[self.no_models], \\\n","                                                                                'super_index': self.no_makes, 'superclass': self.makes[self.no_makes]}\n","                    for img_name in os.listdir(year_path):\n","                      img_path = os.path.join(year_path, img_name)\n","                      img_local_path = make + '/' + model + '/' + year + '/' + img_name\n","                      if self.split == 'train' or self.split == 'val':\n","                        if img_local_path in self.train_images:\n","                          img_index = self.train_images.index(img_local_path)\n","                          if img_index <= 0.8 * len(self.train_images) and self.split == 'train':\n","                            self.image_paths.append(img_path)\n","                            self.labels.append(self.no_classlabels)\n","                          if img_index > 0.8 * len(self.train_images) and self.split == 'val':\n","                            self.image_paths.append(img_path)\n","                            self.labels.append(self.no_classlabels)\n","                      elif img_local_path in self.test_images and self.split == 'test':\n","                        self.image_paths.append(img_path)\n","                        self.labels.append(self.no_classlabels)\n","\n","        combined = list(zip(self.image_paths, self.labels))\n","        random.shuffle(combined)\n","        self.image_paths, self.labels = zip(*combined)\n","\n","    def _load_class_names(self, mat_file):\n","        data = scipy.io.loadmat(mat_file)\n","        makes_names = data.get('make_names')\n","        if makes_names is not None:\n","            makes =  [name[0] for name in makes_names.flatten()]\n","        else:\n","            raise ValueError(\"Could not find 'make_names' key in .mat file\")\n","        model_names = data.get('model_names')\n","        # print(model_names.flatten())\n","        if model_names is not None:\n","            models =  [name for name in model_names.flatten()]\n","        else:\n","            raise ValueError(\"Could not find 'model_names' key in .mat file\")\n","        # print(models)\n","        return makes, models\n","\n","    def get_alphabetical_to_original_label(self):\n","        return self.alphabetical_to_original_label\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        label = self.labels[idx]\n","\n","        image = Image.open(img_path).convert(\"RGB\")  # Open image\n","\n","        if self.transform:\n","            image = self.transform(image)  # Apply transformations\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        return image, label\n","\n","if DATASET == 'CompCars':\n","    train_dataset = CompCarsDataset(transform=TRAIN_TRANSFORMS, split='train')\n","    alphabetical_to_original_label = train_dataset.alphabetical_to_original_label\n","    val_dataset = CompCarsDataset(transform=TEST_TRANSFORMS, split='val')\n","    test_dataset = CompCarsDataset(transform=TEST_TRANSFORMS, split='test')\n","    print(len(train_dataset), len(val_dataset), len(test_dataset))\n","    train_loader_classic  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader_clasic = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    test_loader_clasic = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"],"metadata":{"id":"eQh9PftYLVgQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"meCJ4YYGmYQt"},"source":["# Model"]},{"cell_type":"code","source":["def print_number_of_parameters(model):\n","\n","  total_params = sum(p.numel() for p in model.parameters())\n","\n","  # Print the total number of parameters\n","  print(f\"Total number of parameters: {total_params}\")"],"metadata":{"id":"cjRl1dFrMIFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9NX50yRmajX"},"outputs":[],"source":["#@title Flat MobileNetv3\n","\n","class ClassicMobileNetV3(nn.Module):\n","    def __init__(self, num_classes=100, pretrained=True, dropout_p=0.5):\n","        super(ClassicMobileNetV3, self).__init__()\n","\n","        # Load the pre-trained MobileNetV3 model from torchvision\n","        self.mobilenet = MODEL(pretrained=pretrained)\n","\n","        if 'mobilenet_v3' in MODEL_NAME:\n","\n","          # Modify the first convolutional layer to accept (28, 28) input size\n","          # self.mobilenet.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n","\n","          # Extract the number of features from the original classifier\n","          in_features = self.mobilenet.classifier[-1].in_features\n","\n","          # Replace the classifier with a new sequence including Dropout\n","          '''\n","          self.mobilenet.classifier[-1] = nn.Sequential(\n","              # nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","          '''\n","          model_head = nn.Sequential(\n","              nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","\n","          self.mobilenet.classifier[-1] = model_head\n","\n","        elif 'resnet' in MODEL_NAME:\n","          in_features = self.mobilenet.fc.in_features\n","          model_head = nn.Sequential(\n","              nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","          self.mobilenet.fc = model_head\n","        elif 'swin' in MODEL_NAME:\n","          self.mobilenet.head = nn.Linear(self.mobilenet.head.in_features, num_classes)\n","        elif 'vit_b_16' in MODEL_NAME:\n","          self.mobilenet.heads.head = nn.Linear(self.mobilenet.heads.head.in_features, num_classes)\n","        elif 'vgg' in MODEL_NAME:\n","          # ? Redundant path\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Linear(in_features, num_classes)\n","        elif 'densenet' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier.in_features\n","          model_head = nn.Sequential(\n","              nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","          self.mobilenet.classifier = model_head\n","        elif 'efficientnet' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          model_head = nn.Sequential(\n","              nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","          self.mobilenet.classifier[-1] = model_head\n","        elif 'maxvit' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          model_head = nn.Sequential(\n","              nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","          self.mobilenet.classifier[-1] = model_head\n","        elif 'convnext' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          model_head = nn.Sequential(\n","              nn.Dropout(p=dropout_p),  # Dropout layer with probability p\n","              nn.Linear(in_features, num_classes)  # Final fully connected layer\n","          )\n","          self.mobilenet.classifier[-1] = model_head\n","        else:\n","          assert False\n","\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","\n","classic_model = ClassicMobileNetV3(num_classes=NUM_CLASSES, pretrained=True, dropout_p = DROPOUT)\n","print_number_of_parameters(classic_model)\n","\n","input = torch.randn(1, 3, 224, 224)  # Example input\n","flops, params = profile(classic_model, inputs=(input,))\n","print(f\"FLOPs: {flops}, Parameters: {params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4i4tVU2N67sE"},"outputs":[],"source":["#@title Local Classifier at each hierarchic granularity\n","\n","class HierarchicMobileNetV3(nn.Module):\n","    def __init__(self, num_superclasses=20, num_subclasses = [5 for _ in range(20)], pretrained=True, device=\"cuda\"):\n","\n","      super(HierarchicMobileNetV3, self).__init__()\n","\n","      self.num_superclasses = num_superclasses\n","      self.num_subclasses = num_subclasses\n","\n","      self.superclass_clasifier = ClassicMobileNetV3(num_superclasses, pretrained)\n","\n","      # self.class_classifiers = [ClassicMobileNetV3(num_subclasses[i], pretrained) for i in range(num_superclasses)]\n","      self.class_classifiers = nn.ModuleList(\n","            [ClassicMobileNetV3(num_subclasses[i], pretrained).to(device) for i in range(num_superclasses)]\n","        )\n","\n","\n","    def forward(self, x):\n","        # Predict the superclass\n","        # x = x.to(next(self.parameters()).device)\n","        superclass_prediction = self.superclass_clasifier(x)\n","\n","        # Determine the predicted superclass for each item in the batch\n","        chosen_superclass = torch.argmax(superclass_prediction, dim=1)\n","\n","        # Prepare an empty tensor to store the subclass predictions\n","        batch_size = x.size(0)\n","        class_predictions = torch.zeros(batch_size, max(self.num_subclasses), device=x.device)\n","\n","        for i in range(batch_size):\n","            # For each item in the batch, select the corresponding subclass classifier\n","            class_predictions[i] = self.class_classifiers[chosen_superclass[i]](x[i].unsqueeze(0))\n","\n","        return class_predictions, superclass_prediction\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpTGULUJwlKw"},"outputs":[],"source":["#@title Global Classifier\n","\n","class GlobalMobileNetV3(nn.Module):\n","  def __init__(self, num_superclasses=20, num_subclasses = 100, pretrained=True):\n","\n","      self.num_superclasses = num_superclasses\n","      self.num_subclasses = num_subclasses\n","\n","      self.mobilenet = ClassicMobileNetV3(num_superclasses + num_subclasses)\n","\n","  def forward(self, x):\n","      return self.mobilenet(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"AOqY7iZ3k1h7"},"outputs":[],"source":["#@title Parallel MT Hierarchical\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, x):\n","        return x\n","\n","\n","class ParallelMultiTaskMobileNetV3(nn.Module):\n","    def __init__(self, num_superclasses=20, num_subclasses=100, pretrained=True, dropout_p=0.5):\n","        super(ParallelMultiTaskMobileNetV3, self).__init__()\n","\n","        # Load the pre-trained MobileNetV3 model from torchvision\n","        self.mobilenet = MODEL(pretrained=pretrained)\n","        # Define Dropout layer\n","\n","        if 'mobilenet_v3' in MODEL_NAME:\n","          # Modify the first convolutional layer to accept (28, 28) input size\n","          # self.mobilenet.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n","\n","          # Extract the number of features from the original classifier\n","          in_features = self.mobilenet.classifier[-1].in_features\n","\n","          # Replace the original classifier with an identity layer\n","          self.mobilenet.classifier[-1] = Identity()\n","\n","        elif 'resnet' in MODEL_NAME:\n","          in_features = self.mobilenet.fc.in_features\n","          self.mobilenet.fc = nn.Dropout(p=dropout_p)\n","\n","        elif 'swin' in MODEL_NAME:\n","          in_features = self.mobilenet.head.in_features\n","          self.mobilenet.head = nn.Dropout(p=dropout_p)\n","\n","        elif 'vit_b_16' in MODEL_NAME:\n","          in_features = self.mobilenet.heads.head.in_features\n","          self.mobilenet.heads.head = nn.Dropout(p=dropout_p)\n","\n","        elif 'vgg' in MODEL_NAME:\n","          # ? Redundant path\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'densenet' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier.in_features\n","          self.mobilenet.classifier = nn.Dropout(p=dropout_p)\n","\n","        elif 'efficientnet' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'maxvit' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'convnext' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        self.superclass_classifier = nn.Linear(in_features, num_superclasses)\n","        self.subclass_classifier = nn.Linear(in_features, num_subclasses)\n","\n","    def forward(self, x):\n","        # Pass input through the feature extractor\n","        features = self.mobilenet(x)\n","        features = torch.flatten(features, 1)  # Flatten the output for the classifier\n","\n","        # Apply Dropout to the features\n","        # features = self.dropout(features)\n","\n","        # Compute superclass and subclass predictions\n","        superclass_output = self.superclass_classifier(features)\n","        subclass_output = self.subclass_classifier(features)\n","\n","        return subclass_output, superclass_output\n","\n","parallel_model = ParallelMultiTaskMobileNetV3(num_superclasses=NUM_SUPERCLASSES, num_subclasses=NUM_SUBCLASSES, pretrained=True, dropout_p = DROPOUT)\n","print_number_of_parameters(parallel_model)\n","\n","input = torch.randn(1, 3, 224, 224)  # Example input\n","flops, params = profile(parallel_model, inputs=(input,))\n","print(f\"FLOPs: {flops}, Parameters: {params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"SkfLF6oDlNS9"},"outputs":[],"source":["#@title Cascaded MT Hierarchical\n","\n","class CascadedMultiTaskMobileNetV3(nn.Module):\n","    def __init__(self, num_superclasses=20, num_subclasses=100, pretrained=True, dropout_p=0.5):\n","        super(CascadedMultiTaskMobileNetV3, self).__init__()\n","\n","        # Load the pre-trained MobileNetV3 model from torchvision\n","        self.mobilenet = MODEL(pretrained=pretrained)\n","\n","        # Modify the first convolutional layer to accept (28, 28) input size\n","        # self.mobilenet.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n","        if 'mobilenet_v3' in MODEL_NAME:\n","        # Adjust the classifier input size if needed (e.g., due to smaller input size)\n","          in_features = self.mobilenet.classifier[-1].in_features\n","\n","          # Replace the original classifier with an identity layer\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'resnet' in MODEL_NAME:\n","          in_features = self.mobilenet.fc.in_features\n","          self.mobilenet.fc = nn.Dropout(p=dropout_p)\n","\n","        elif 'swin' in MODEL_NAME:\n","          in_features = self.mobilenet.head.in_features\n","          self.mobilenet.head = nn.Dropout(p=dropout_p)\n","\n","        elif 'vit_b_16' in MODEL_NAME:\n","          in_features = self.mobilenet.heads.head.in_features\n","          self.mobilenet.heads.head = nn.Dropout(p=dropout_p)\n","\n","        elif 'vgg' in MODEL_NAME:\n","          # ? Redundant path\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'densenet' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier.in_features\n","          self.mobilenet.classifier = nn.Dropout(p=dropout_p)\n","\n","        elif 'efficientnet' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'maxvit' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        elif 'convnext' in MODEL_NAME:\n","          in_features = self.mobilenet.classifier[-1].in_features\n","          self.mobilenet.classifier[-1] = nn.Dropout(p=dropout_p)\n","\n","        # Superclass classifier\n","        self.superclass_classifier = nn.Linear(in_features, num_superclasses)\n","\n","        # Subclass classifier with additional input for superclass prediction\n","        self.subclass_classifier = nn.Linear(in_features + num_superclasses, num_subclasses)\n","\n","    def forward(self, x):\n","        # Pass input through the feature extractor (all layers except the classifier)\n","        features = self.mobilenet(x)\n","        features = torch.flatten(features, 1)\n","\n","        # Apply Dropout to the features\n","        # features = self.dropout(features)\n","\n","        # Compute superclass prediction\n","        superclass_output = self.superclass_classifier(features)\n","\n","        # Concatenate the superclass prediction with the features\n","        combined_input = torch.cat((features, superclass_output), dim=1)\n","\n","        # Apply Dropout to the combined input before subclass classification\n","        # combined_input = self.dropout(combined_input)\n","\n","        # Compute subclass prediction using combined input\n","        subclass_output = self.subclass_classifier(combined_input)\n","\n","        return subclass_output, superclass_output\n","\n","cascaded_model = CascadedMultiTaskMobileNetV3(num_superclasses=NUM_SUPERCLASSES, num_subclasses=NUM_SUBCLASSES, pretrained=True, dropout_p = DROPOUT)\n","print_number_of_parameters(cascaded_model)\n","\n","input = torch.randn(1, 3, 224, 224)  # Example input\n","flops, params = profile(cascaded_model, inputs=(input,))\n","print(f\"FLOPs: {flops}, Parameters: {params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9v2OjPrSL490"},"outputs":[],"source":["# Implement Deep Supervised MT"]},{"cell_type":"markdown","metadata":{"id":"iUiXZv9ZpGl5"},"source":["# Extra Dataloaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkm0Xz4jpKF2"},"outputs":[],"source":["def get_hierarchic_labels(target):\n","    superclass_label = alphabetical_to_original_label[target]['super_index']\n","    target = alphabetical_to_original_label[target]['index']\n","    return superclass_label, target\n","\n","# Modify the dataset to return hierarchical labels\n","if DATASET == 'cifar100':\n","  train_dataset_hierarchic = torchvision.datasets.CIFAR100(root='/content/dataset/train/', train=True, download=False, transform=TRAIN_TRANSFORMS, target_transform=get_hierarchic_labels)\n","  train_dataset_hierarchic, val_dataset_hierarchic = random_split(train_dataset_hierarchic, [train_size, val_size])\n","  test_dataset_hierarchic = torchvision.datasets.CIFAR100(root='/content/dataset/test/', train=False, download=False, transform=TEST_TRANSFORMS, target_transform=get_hierarchic_labels)\n","elif DATASET == 'StandfordCars':\n","  train_dataset_hierarchic = StandfordCarsDataset(root='/content/dataset', split='train', transform=TRAIN_TRANSFORMS, target_transform=get_hierarchic_labels)\n","  val_dataset_hierarchic = StandfordCarsDataset(root='/content/dataset', split='val', transform=TEST_TRANSFORMS, target_transform=get_hierarchic_labels)\n","  test_dataset_hierarchic = StandfordCarsDataset(root='/content/dataset', split='test', transform=TEST_TRANSFORMS, target_transform=get_hierarchic_labels)\n","elif DATASET == 'CompCars':\n","  train_dataset_hierarchic = CompCarsDataset(transform=TRAIN_TRANSFORMS, split='train', target_transform=get_hierarchic_labels)\n","  val_dataset_hierarchic = CompCarsDataset(transform=TEST_TRANSFORMS, split='val', target_transform=get_hierarchic_labels)\n","  test_dataset_hierarchic = CompCarsDataset(transform=TEST_TRANSFORMS, split='test', target_transform=get_hierarchic_labels)\n","\n","# DataLoader for HierarchicMobileNetV3\n","train_loader_hierarchic = DataLoader(train_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n","val_loader_hierarchic = DataLoader(val_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n","test_loader_hierarchic = DataLoader(test_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOzpi4Zlpi6o"},"outputs":[],"source":["def get_global_labels(target):\n","    superclass_label = alphabetical_to_original_label[target]['super_index']\n","    global_label = superclass_label * 100 + v\n","    return global_label\n","\n","# Load and split the dataset for GlobalMobileNetV3\n","if DATASET == 'cifar100':\n","  full_global_dataset = torchvision.datasets. CIFAR100(root='/content/dataset/train/', train=True, download=False, transform=TRAIN_TRANSFORMS, target_transform=get_global_labels)\n","  train_dataset_global, val_dataset_global = random_split(full_global_dataset, [train_size, val_size])\n","  test_dataset_global = torchvision.datasets.CIFAR100(root='/content/dataset/test/', train=False, download=False, transform=TEST_TRANSFORMS, target_transform=get_global_labels)\n","elif DATASET == 'StandfordCars':\n","   train_dataset_global = StandfordCarsDataset(root='/content/dataset', split='train', transform=TRAIN_TRANSFORMS, target_transform=get_global_labels)\n","   val_dataset_global = StandfordCarsDataset(root='/content/dataset', split='val', transform=TEST_TRANSFORMS, target_transform=get_global_labels)\n","   test_dataset_global = StandfordCarsDataset(root='/content/dataset', split='test', transform=TEST_TRANSFORMS, target_transform=get_global_labels)\n","elif DATASET == 'CompCars':\n","  train_dataset_global = CompCarsDataset(transform=TRAIN_TRANSFORMS, split='train', target_transform=get_global_labels)\n","  val_dataset_global = CompCarsDataset(transform=TEST_TRANSFORMS, split='val', target_transform=get_global_labels)\n","  test_dataset_global = CompCarsDataset(transform=TEST_TRANSFORMS, split='test', target_transform=get_global_labels)\n","\n","# DataLoader for GlobalMobileNetV3\n","train_loader_global = DataLoader(train_dataset_global, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n","val_loader_global = DataLoader(val_dataset_global, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n","test_loader_global = DataLoader(test_dataset_global, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5w7KUsepvVl"},"outputs":[],"source":["# DataLoader for ParallelMultiTaskMobileNetV3 (superclass and subclass)\n","train_loader_parallel = DataLoader(train_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n","val_loader_parallel = DataLoader(val_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n","test_loader_parallel = DataLoader(test_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L34ORMskpvw8"},"outputs":[],"source":["# DataLoader for CascadedMultiTaskMobileNetV3 (superclass and subclass)\n","train_loader_cascaded = DataLoader(train_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n","val_loader_cascaded = DataLoader(val_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n","test_loader_cascaded = DataLoader(test_dataset_hierarchic, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"JKchuzsxlIZ8"},"source":["# Training Procedures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XocNIHBLlHos"},"outputs":[],"source":["import torch\n","import copy\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","def train_classic_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', max_lr=MAX_LR, phases=['train', 'val']):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss':[], 'test_acc':[],  'train_acc_superclass': [], 'val_acc_superclass': [], 'test_acc_superclass':[]}\n","\n","    # Calculate total steps for 1CycleLR (total number of batches in training phase)\n","    total_steps = len(dataloaders['train']) * num_epochs\n","\n","    # Initialize the 1CycleLR scheduler\n","    scheduler = OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()  # Update the learning rate according to the 1Cycle policy\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data).item()\n","\n","                superclass_labels, _ = zip(*[get_hierarchic_labels(int(element)) for element in labels.data])\n","                superclass_labels = torch.tensor(superclass_labels)\n","\n","                superclass_preds, _ = zip(*[get_hierarchic_labels(int(element)) for element in preds])\n","                superclass_preds = torch.tensor(superclass_preds)\n","\n","                running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # Save the model if validation loss has decreased\n","            if phase == 'val' and epoch_loss < best_val_loss:\n","                best_val_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                model_save_path = BASE_DIR + f'classic_model_epoch.pt'\n","                torch.save(model.state_dict(), model_save_path)\n","                print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f0XKibnoHEi"},"outputs":[],"source":["def train_hierarchic_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss':[], 'test_acc':[]}\n","\n","\n","    device2 = next(model.class_classifiers[0].mobilenet.parameters()).device\n","    print(f\"The first classifier's MobileNetV3 model is on: {device2}\")\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","                    hierarchic_labels = torch.zeros(subclass_labels.shape[0], device=device)\n","                    for idx, subclass_label in enumerate(subclass_labels):\n","                      hierarchic_label = alphabetical_to_original_label[subclass_label.item()]['hierarchic_index']\n","                      hierarchic_labels[idx] = hierarchic_label\n","                    hierarchic_labels = hierarchic_labels.long()\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels)\n","                    subclass_loss = criterion(subclass_outputs, hierarchic_labels)\n","                    loss = superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum((subclass_preds == hierarchic_labels.data) * (superclass_preds == superclass_labels.data)).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase])\n","            epoch_acc = running_corrects / len(dataloaders[phase])\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase])\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-M6_Bf9s1jg_"},"outputs":[],"source":["def train_hierarchic_mobilenet_fast(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss':[], 'test_acc':[]}\n","\n","    # Precompute hierarchic label mapping on CPU for faster indexing\n","    original_to_hierarchic = torch.tensor(\n","        [alphabetical_to_original_label[i]['hierarchic_index'] for i in range(len(alphabetical_to_original_label))],\n","        dtype=torch.long, device=device\n","    )\n","\n","    for epoch in range(num_epochs):\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","\n","                    # Vectorized label conversion\n","                    hierarchic_labels = original_to_hierarchic[subclass_labels]\n","\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels)\n","                    subclass_loss = criterion(subclass_outputs, hierarchic_labels)\n","                    loss = superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum((subclass_preds == hierarchic_labels) & (superclass_preds == superclass_labels)).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            # Correct the calculation of loss and accuracy\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ6NF_lJoMvw"},"outputs":[],"source":["'''\n","def train_global_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data).item()\n","\n","            epoch_loss = running_loss / len(dataloaders[phase])\n","            epoch_acc = running_corrects / len(dataloaders[phase])\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model, history\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApGq75xVoOeB"},"outputs":[],"source":["import torch\n","import copy\n","\n","def train_parallel_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', max_lr=MAX_LR, phases=['train', 'val']):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'train_acc_superclass': [], 'val_acc_superclass': [], 'test_loss':[], 'test_acc':[], 'test_acc_superclass':[]}\n","\n","    # Calculate total steps for 1CycleLR (total number of batches in training phase)\n","    total_steps = len(dataloaders['train']) * num_epochs\n","\n","    # Initialize the 1CycleLR scheduler\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels) * LOSS_WEIGHTS[1]\n","                    subclass_loss = criterion(subclass_outputs, subclass_labels) * LOSS_WEIGHTS[0]\n","                    loss = subclass_loss # superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum(subclass_preds == subclass_labels.data).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        superclass_loss.backward(retain_graph=True)\n","                        subclass_loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()  # Update the learning rate according to the 1Cycle policy\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Superclass Acc: {epoch_acc_superclass:.4f}')\n","\n","            # Save the model if validation loss has decreased\n","            if phase == 'val' and epoch_loss < best_val_loss:\n","                best_val_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                model_save_path = BASE_DIR + f'parallel_model_epoch.pt'\n","                torch.save(model.state_dict(), model_save_path)\n","                print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4OmjaIqoSCE"},"outputs":[],"source":["import torch\n","import copy\n","\n","def train_cascaded_mobilenet(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', max_lr=MAX_LR, phases=['train', 'val']):\n","    model = model.to(device)\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'train_acc_superclass': [], 'val_acc_superclass': [], 'test_loss':[], 'test_acc':[], 'test_acc_superclass':[]}\n","\n","    # Calculate total steps for 1CycleLR (total number of batches in training phase)\n","    total_steps = len(dataloaders['train']) * num_epochs\n","\n","    # Initialize the 1CycleLR scheduler\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            running_corrects_superclass = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                superclass_labels, subclass_labels = labels\n","                superclass_labels = superclass_labels.to(device)\n","                subclass_labels = subclass_labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    subclass_outputs, superclass_outputs = model(inputs)\n","                    superclass_loss = criterion(superclass_outputs, superclass_labels) * LOSS_WEIGHTS[1]\n","                    subclass_loss = criterion(subclass_outputs, subclass_labels) * LOSS_WEIGHTS[0]\n","                    loss = subclass_loss # superclass_loss + subclass_loss\n","\n","                    _, superclass_preds = torch.max(superclass_outputs, 1)\n","                    _, subclass_preds = torch.max(subclass_outputs, 1)\n","                    running_corrects += torch.sum(subclass_preds == subclass_labels.data).item()\n","                    running_corrects_superclass += torch.sum(superclass_preds == superclass_labels.data).item()\n","\n","                    if phase == 'train':\n","                        superclass_loss.backward(retain_graph=True)\n","                        subclass_loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()  # Update the learning rate according to the 1Cycle policy\n","\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n","            epoch_acc_superclass = running_corrects_superclass / len(dataloaders[phase].dataset)\n","\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc)\n","            history[f'{phase}_acc_superclass'].append(epoch_acc_superclass)\n","\n","            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Superclass Acc: {epoch_acc_superclass:.4f}')\n","\n","            # Save the model if validation loss has decreased\n","            if phase == 'val' and epoch_loss < best_val_loss:\n","                best_val_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                model_save_path = BASE_DIR + f'cascaded_model_epoch.pt'\n","                torch.save(model.state_dict(), model_save_path)\n","                print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history"]},{"cell_type":"markdown","metadata":{"id":"NsVrUNyqovo3"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKQ6xm5uow4H"},"outputs":[],"source":["# Initialize the model\n","classic_model = ClassicMobileNetV3(num_classes=NUM_CLASSES, pretrained=True)\n","\n","# Define the loss function and optimizer\n","optimizer = optim.Adam(classic_model.parameters(), lr=LR)\n","\n","# Call the training function for ClassicMobileNetV3\n","trained_classic_model, classic_history = train_classic_mobilenet(\n","    model=classic_model,\n","    dataloaders={'train': train_loader_classic, 'val': val_loader_clasic, 'test':test_loader_clasic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFb0zMptss6G"},"outputs":[],"source":["# hierarchic_model = HierarchicMobileNetV3(num_superclasses=20, num_subclasses=[5 for _ in range(20)], pretrained=True, device=DEVICE)\n","# optimizer = optim.Adam(hierarchic_model.parameters(), lr=LR)\n","\n","'''\n","trained_hierarchic_model, hierarchic_history = train_hierarchic_mobilenet_fast(\n","    model=hierarchic_model,\n","    dataloaders={'train': train_loader_hierarchic, 'val': val_loader_hierarchic, 'test':test_loader_hierarchic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_y9DKPP9s89E"},"outputs":[],"source":["parallel_model = ParallelMultiTaskMobileNetV3(num_superclasses=NUM_SUPERCLASSES, num_subclasses=NUM_SUBCLASSES, pretrained=True)\n","optimizer = optim.Adam(parallel_model.parameters(), lr=LR)\n","\n","# Call the training function for ParallelMultiTaskMobileNetV3\n","trained_parallel_model, parallel_history = train_parallel_mobilenet(\n","    model=parallel_model,\n","    dataloaders={'train': train_loader_parallel, 'val': val_loader_parallel, 'test':test_loader_parallel},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCRtAp-0tNsK"},"outputs":[],"source":["cascaded_model = CascadedMultiTaskMobileNetV3(num_superclasses=NUM_SUPERCLASSES, num_subclasses=NUM_SUBCLASSES, pretrained=True)\n","optimizer = optim.Adam(cascaded_model.parameters(), lr=LR)\n","\n","trained_cascaded_model, cascaded_history = train_cascaded_mobilenet(\n","    model=cascaded_model,\n","    dataloaders={'train': train_loader_cascaded, 'val': val_loader_cascaded, 'test':test_loader_cascaded},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=EPOCHS,\n","    device=DEVICE  # or 'cpu' if you don't have a GPU\n",")"]},{"cell_type":"markdown","metadata":{"id":"2k9go_SQs3lz"},"source":["# Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jkg1Wew8ue7g"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","\n","# Assuming you have these history dictionaries from your training sessions\n","# Each dictionary should contain lists like 'train_acc', 'val_acc', 'train_loss', 'val_loss'\n","# Example:\n","# classic_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# hierarchic_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# global_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# parallel_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","# cascaded_history = {'train_acc': [...], 'val_acc': [...], 'train_loss': [...], 'val_loss': [...]}\n","\n","# List of histories and labels for the plot\n","histories = [\n","    ('Classic', classic_history),\n","    # ('Hierarchic', hierarchic_history),\n","    ('Parallel', parallel_history),\n","    ('Cascaded', cascaded_history)\n","]\n","\n","# Function to create a folder and save the plot\n","def save_plot(history_key, title, ylabel, save_path):\n","    # Create the directory if it doesn't exist\n","\n","    # Plot the metric for each model\n","    plt.figure(figsize=(12, 8))\n","    for label, history in histories:\n","      if history_key in history:\n","        plt.plot(history[history_key], label=f'{label} {title}')\n","\n","    plt.title(title)\n","    plt.xlabel('Epoch')\n","    plt.ylabel(ylabel)\n","    plt.legend(loc='best')\n","    plt.grid(True)\n","\n","    # Save the plot to the specified path\n","    plt.savefig(save_path)\n","\n","    # Optionally, show the plot (you can comment this out if you don't want to display it)\n","    plt.show()\n","\n","# Define the base directory where you want to save the plots\n","base_dir = BASE_DIR\n","\n","# Save plots for each metric\n","save_plot('train_acc', 'Training Accuracy', 'Accuracy', os.path.join(base_dir, 'training_accuracy.png'))\n","save_plot('val_acc', 'Validation Accuracy', 'Accuracy', os.path.join(base_dir, 'validation_accuracy.png'))\n","save_plot('train_acc_superclass', 'Training Superclass Accuracy', 'Accuracy', os.path.join(base_dir, 'training_accuracy_superclass.png'))\n","save_plot('val_acc_superclass', 'Validation Superclass Accuracy', 'Accuracy', os.path.join(base_dir, 'validation_accuracy_superclass.png'))\n","save_plot('train_loss', 'Training Loss', 'Loss', os.path.join(base_dir, 'training_loss.png'))\n","save_plot('val_loss', 'Validation Loss', 'Loss', os.path.join(base_dir, 'validation_loss.png'))"]},{"cell_type":"code","source":["with open(os.path.join(base_dir, \"history_classic.json\"), \"w\") as f:\n","    json.dump(classic_history, f)\n","\n","with open(os.path.join(base_dir, \"history_parallel.json\"), \"w\") as f:\n","    json.dump(parallel_history, f)\n","\n","with open(os.path.join(base_dir, \"history_cascaded.json\"), \"w\") as f:\n","    json.dump(cascaded_history, f)"],"metadata":{"id":"37BDeQ-Ds0gJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rvETUyNhiHQ7"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYWq6LsEiI2O"},"outputs":[],"source":["optimizer = optim.Adam(trained_classic_model.parameters(), lr=LR)\n","\n","_, classic_history = train_classic_mobilenet(\n","    model=trained_classic_model,\n","    dataloaders={'train': train_loader_classic, 'val': val_loader_clasic, 'test':test_loader_clasic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=1,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n",")\n","\n","classic_accuracy = classic_history['test_acc']\n","classic_superclass_accuracy = classic_history['test_acc_superclass']\n","\n","optimizer = optim.Adam(trained_parallel_model.parameters(), lr=LR)\n","\n","_, parallel_history = train_parallel_mobilenet(\n","    model=trained_parallel_model,\n","    dataloaders={'train': train_loader_parallel, 'val': val_loader_parallel, 'test':test_loader_parallel},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=1,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n",")\n","\n","parallel_accuracy = parallel_history['test_acc']\n","parallel_superclass_accuracy = parallel_history['test_acc_superclass']\n","\n","optimizer = optim.Adam(trained_cascaded_model.parameters(), lr=LR)\n","\n","_, cascaded_history = train_cascaded_mobilenet(\n","    model=trained_cascaded_model,\n","    dataloaders={'train': train_loader_cascaded, 'val': val_loader_cascaded, 'test':test_loader_cascaded},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=1,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n",")\n","\n","cascaded_accuracy = cascaded_history['test_acc']\n","cascaded_superclass_accuracy = cascaded_history['test_acc_superclass']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6Kqx226jNlq"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Sample data\n","categories = ['Classic Accuracy', 'Parallel Accuracy', 'Cascaded Accuracy']\n","\n","values = [classic_accuracy[0], parallel_accuracy[0], cascaded_accuracy[0]]\n","\n","# Create a bar plot\n","plt.bar(categories, values)\n","\n","# Add titles and labels\n","plt.title('Test Accuracy')\n","plt.xlabel('Method')\n","plt.ylabel('Accuracy')\n","\n","for i, value in enumerate(values):\n","    plt.text(i, value + 0.01, f'{value:.3f}', ha='center', va='bottom')\n","\n","plt.savefig(os.path.join(base_dir, 'test_accuracy.png'))\n","\n","plt.show()"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Sample data\n","categories = ['Classic Acc.', 'Parallel Acc.', 'Cascaded Acc.']\n","\n","values = [classic_superclass_accuracy[0], parallel_superclass_accuracy[0], cascaded_superclass_accuracy[0]]\n","\n","# Create a bar plot\n","plt.bar(categories, values)\n","\n","# Add titles and labels\n","plt.title('Test Superclass Accuracy')\n","plt.xlabel('Method')\n","plt.ylabel('Accuracy')\n","\n","for i, value in enumerate(values):\n","    plt.text(i, value + 0.01, f'{value:.3f}', ha='center', va='bottom')\n","\n","plt.savefig(os.path.join(base_dir, 'test_superclass_accuracy.png'))\n","\n","plt.show()"],"metadata":{"id":"SdVcJkvUn7yj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BL6t1LcOZ1I3"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"markdown","source":["# Top 5 Accuracy"],"metadata":{"id":"ND0BrN5z8s8u"}},{"cell_type":"code","source":["dataloaders={'train': train_loader_classic, 'val': val_loader_clasic, 'test':test_loader_clasic}\n","device = 'cuda'\n","\n","def topn_accuracy(output, target, n = 5):\n","    # Get the top 5 predicted class indices\n","    top5_preds = torch.topk(output, n, dim=1).indices  # (batch_size, 5)\n","\n","    correct = top5_preds.eq(target.view(-1, 1)).sum().item()  # Count correct top-5 matches\n","\n","    # Compute accuracy\n","    return correct / target.size(0)  # Convert to percentage\n","\n","\n","def top5acc(RoootPath, exp_no, n = 5):\n","  exp_path = RootPath + str(exp_no) + '/'\n","  optimizer = optim.Adam(classic_model.parameters(), lr=LR)\n","  classic_state = torch.load(exp_path + 'classic_model_epoch.pt')\n","  # print(classic_state.keys())\n","  classic_model.load_state_dict(classic_state, strict=False)\n","  parallel_model.load_state_dict(torch.load(exp_path + 'parallel_model_epoch.pt'), strict=False)\n","  cascaded_model.load_state_dict(torch.load(exp_path + 'cascaded_model_epoch.pt'), strict=False)\n","\n","  phase = 'test'\n","  all_classic_outputs = torch.empty(0, device=device)\n","  all_parallel_outputs = torch.empty(0, device=device)\n","  all_cascaded_outputs = torch.empty(0, device=device)\n","  all_labels = torch.empty(0, dtype=torch.long, device=device)\n","  classic_model.to(device)\n","  parallel_model.to(device)\n","  cascaded_model.to(device)\n","  classic_model.eval()\n","  parallel_model.eval()\n","  cascaded_model.eval()\n","  for inputs, labels in dataloaders[phase]:\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    optimizer.zero_grad()\n","\n","    with torch.set_grad_enabled(phase == 'train'):\n","        classic_outputs = classic_model(inputs)\n","        parallel_outputs = parallel_model(inputs)[0]\n","        cascaded_outputs = cascaded_model(inputs)[0]\n","\n","    all_classic_outputs = torch.cat((all_classic_outputs, classic_outputs), dim=0)\n","    all_parallel_outputs = torch.cat((all_parallel_outputs, parallel_outputs), dim=0)\n","    all_cascaded_outputs = torch.cat((all_cascaded_outputs, cascaded_outputs), dim=0)\n","    all_labels = torch.cat((all_labels, labels), dim=0)\n","\n","  classic_top5_acc = topn_accuracy(all_classic_outputs, all_labels, n)\n","  parallel_top5_acc = topn_accuracy(all_parallel_outputs, all_labels, n)\n","  cascaded_top5_acc = topn_accuracy(all_cascaded_outputs, all_labels, n)\n","  print(n, round(classic_top5_acc, 3), round(parallel_top5_acc, 3), round(cascaded_top5_acc, 3))\n","\n","\n","RootPath = '/content/drive/MyDrive/New Exps/SamplesH/'\n","exp_no = 47\n","top5acc(RootPath, exp_no, 1)\n","top5acc(RootPath, exp_no, 2)\n","top5acc(RootPath, exp_no, 3)\n","top5acc(RootPath, exp_no, 4)\n","top5acc(RootPath, exp_no, 5)\n","top5acc(RootPath, exp_no, 6)\n","top5acc(RootPath, exp_no, 7)\n","top5acc(RootPath, exp_no, 8)\n","top5acc(RootPath, exp_no, 9)\n","top5acc(RootPath, exp_no, 10)"],"metadata":{"id":"oZ4G64kA8uwl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Test"],"metadata":{"id":"KUNR0xY4rWwv"}},{"cell_type":"code","source":["def re_evalutate_model(RoootPath, exp_no):\n","  exp_path = RootPath + str(exp_no) + '/'\n","  optimizer = optim.Adam(classic_model.parameters(), lr=LR)\n","  classic_model.load_state_dict(torch.load(exp_path + 'classic_model_epoch.pt'))\n","  # parallel_model.load_state_dict(torch.load(exp_path + 'parallel_model_epoch.pt'))\n","  # cascaded_model.load_state_dict(torch.load(exp_path + 'cascaded_model_epoch.pt'))\n","  _, classic_history = train_classic_mobilenet(\n","    model=classic_model,\n","    dataloaders={'train': train_loader_classic, 'val': val_loader_clasic, 'test':test_loader_clasic},\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=1,\n","    device=DEVICE,  # or 'cpu' if you don't have a GPU\n","    phases = ['test']\n","  )\n","\n","  classic_accuracy = classic_history['test_acc']\n","  classic_superclass_accuracy = classic_history['test_acc_superclass']\n","  print(exp_no, classic_accuracy, classic_superclass_accuracy)"],"metadata":{"id":"tLlvGUxUsmBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RootPath = '/content/drive/MyDrive/New Exps/SamplesH/'\n","\n","max_vit_list = [43, 48, 52, 55, 58, 61]\n","conv_next_list = [44, 47, 53, 56, 59, 62]\n","dense_list = [45, 46, 54, 57, 60, 63]\n","\n","for exp_no in dense_list:\n","  # exp_path = RootPath + str(exp_no) + '/'\n","  re_evalutate_model(RootPath, exp_no)"],"metadata":{"id":"r_8TkxDSrbEN"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["bfsmS71HsnkM","1060liaPlDo5","drZMhGHV45xz","lvNQQCdvJKk6","nSdCN_c7GryH","meCJ4YYGmYQt","iUiXZv9ZpGl5","JKchuzsxlIZ8","NsVrUNyqovo3","2k9go_SQs3lz","rvETUyNhiHQ7"],"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNsC6P/5S823QMW8JMntVHY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}